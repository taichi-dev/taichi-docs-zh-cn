# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018, Yuanming Hu
# This file is distributed under the same license as the taichi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: taichi 0.5.14\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-05-13 20:53-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../taichi/docs/acknowledgments.rst:2
msgid "Acknowledgments"
msgstr ""

#: ../../taichi/docs/acknowledgments.rst:4
msgid ""
"`Taichi` depends on other open-source projects, which are shipped with "
"taichi and users do not have to install manually: `pybind11 "
"<https://github.com/pybind/pybind11>`_, `fmt "
"<https://github.com/fmtlib/fmt>`_, `Catch2 "
"<https://github.com/catchorg/Catch2>`_, `spdlog "
"<https://github.com/gabime/spdlog>`_, `stb_image, stb_image_write, "
"stb_truetype <https://github.com/nothings/stb>`_, `tinyobjloader "
"<https://github.com/syoyo/tinyobjloader>`_, `ffmpeg "
"<https://www.ffmpeg.org/>`_, `miniz "
"<https://github.com/richgel999/miniz>`_."
msgstr ""

#: ../../taichi/docs/acknowledgments.rst:15
msgid ""
"`Halide <https://halide-lang.org/>`_ has been a great reference for us to"
" learn about the Apple Metal API and the LLVM NVPTX backend API."
msgstr ""

#: ../../taichi/docs/atomic.rst:4
msgid "Atomic operations"
msgstr ""

#: ../../taichi/docs/atomic.rst:6
msgid ""
"In Taichi, augmented assignments (e.g., ``x[i] += 1``) are automatically "
"`atomic <https://en.wikipedia.org/wiki/Fetch-and-add>`_."
msgstr ""

#: ../../taichi/docs/atomic.rst:11
msgid ""
"When accumulating to global variables in parallel, make sure you use "
"atomic operations. For example, to compute the sum of all elements in "
"``x``, ::"
msgstr ""

#: ../../taichi/docs/atomic.rst:14
msgid ""
"@ti.kernel\n"
"def sum():\n"
"    for i in x:\n"
"        # Approach 1: OK\n"
"        total[None] += x[i]\n"
"\n"
"        # Approach 2: OK\n"
"        ti.atomic_add(total[None], x[i])\n"
"\n"
"        # Approach 3: Wrong result since the operation is not atomic.\n"
"        total[None] = total[None] + x[i]"
msgstr ""

#: ../../taichi/docs/atomic.rst:28
msgid ""
"When atomic operations are applied to local values, the Taichi compiler "
"will try to demote these operations into their non-atomic correspondence."
msgstr ""

#: ../../taichi/docs/atomic.rst:30
msgid ""
"Apart from augmented assignments, explicit atomic operations such as "
"``ti.atomic_add`` also do read-modify-write atomically. These operations "
"additionally return the **old value** of the first argument. Below is the"
" full list of explicit atomic operations:"
msgstr ""

#: ../../taichi/docs/atomic.rst:36
msgid "Atomically compute ``x + y``/``x - y`` and store the result to ``x``."
msgstr ""

#: ../../taichi/docs/atomic.rst ../../taichi/docs/gui.rst
#: ../../taichi/docs/snode.rst ../../taichi/docs/vector.rst
msgid "Returns"
msgstr ""

#: ../../taichi/docs/atomic.rst:38 ../../taichi/docs/atomic.rst:55
msgid "The old value of ``x``."
msgstr ""

#: ../../taichi/docs/atomic.rst:40 ../../taichi/docs/vector.rst:112
msgid "For example, ::"
msgstr ""

#: ../../taichi/docs/atomic.rst:43
msgid ""
"x = 3\n"
"y = 4\n"
"z = ti.atomic_add(x, y)\n"
"# now x = 7, y = 4, z = 3"
msgstr ""

#: ../../taichi/docs/atomic.rst:53
msgid ""
"Atomically compute ``x & y`` (bitwise and), ``x | y`` (bitwise or), ``x ^"
" y`` (bitwise xor) and store the result to ``x``."
msgstr ""

#: ../../taichi/docs/atomic.rst:60
msgid "Supported atomic operations on each backend:"
msgstr ""

#: ../../taichi/docs/atomic.rst:63 ../../taichi/docs/type.rst:23
msgid "type"
msgstr ""

#: ../../taichi/docs/atomic.rst:63 ../../taichi/docs/type.rst:23
msgid "CPU/CUDA"
msgstr ""

#: ../../taichi/docs/atomic.rst:63 ../../taichi/docs/hello.rst:87
#: ../../taichi/docs/type.rst:23
msgid "OpenGL"
msgstr ""

#: ../../taichi/docs/atomic.rst:63 ../../taichi/docs/hello.rst:87
#: ../../taichi/docs/type.rst:23
msgid "Metal"
msgstr ""

#: ../../taichi/docs/atomic.rst:65
msgid "``i32``"
msgstr ""

#: ../../taichi/docs/atomic.rst:65 ../../taichi/docs/atomic.rst:67
#: ../../taichi/docs/atomic.rst:69 ../../taichi/docs/atomic.rst:71
#: ../../taichi/docs/hello.rst:89 ../../taichi/docs/hello.rst:91
#: ../../taichi/docs/hello.rst:93 ../../taichi/docs/type.rst:25
#: ../../taichi/docs/type.rst:27 ../../taichi/docs/type.rst:29
#: ../../taichi/docs/type.rst:31 ../../taichi/docs/type.rst:33
#: ../../taichi/docs/type.rst:35 ../../taichi/docs/type.rst:37
#: ../../taichi/docs/type.rst:39 ../../taichi/docs/type.rst:41
#: ../../taichi/docs/type.rst:43
msgid "OK"
msgstr ""

#: ../../taichi/docs/atomic.rst:67
msgid "``f32``"
msgstr ""

#: ../../taichi/docs/atomic.rst:69
msgid "``i64``"
msgstr ""

#: ../../taichi/docs/atomic.rst:69 ../../taichi/docs/atomic.rst:71
#: ../../taichi/docs/type.rst:31
msgid "EXT"
msgstr ""

#: ../../taichi/docs/atomic.rst:69 ../../taichi/docs/atomic.rst:71
#: ../../taichi/docs/type.rst:25 ../../taichi/docs/type.rst:27
#: ../../taichi/docs/type.rst:31 ../../taichi/docs/type.rst:33
#: ../../taichi/docs/type.rst:35 ../../taichi/docs/type.rst:37
#: ../../taichi/docs/type.rst:39 ../../taichi/docs/type.rst:43
msgid "MISS"
msgstr ""

#: ../../taichi/docs/atomic.rst:71
msgid "``f64``"
msgstr ""

#: ../../taichi/docs/atomic.rst:74
msgid "(OK: supported; EXT: require extension; MISS: not supported)"
msgstr ""

#: ../../taichi/docs/compilation.rst:4
msgid "The life of a Taichi kernel"
msgstr ""

#: ../../taichi/docs/compilation.rst:6
msgid ""
"Sometimes it is helpful to understand the life cycle of a Taichi kernel. "
"In short, compilation will only happen on the first invocation of an "
"instance of a kernel."
msgstr ""

#: ../../taichi/docs/compilation.rst:9
msgid "Life cycle of a Taichi kernel looks like this:"
msgstr ""

#: ../../taichi/docs/compilation.rst:11 ../../taichi/docs/compilation.rst:38
msgid "Kernel registration"
msgstr ""

#: ../../taichi/docs/compilation.rst:12 ../../taichi/docs/compilation.rst:45
msgid "Template instantiation and caching"
msgstr ""

#: ../../taichi/docs/compilation.rst:13
msgid "Python AST transforms"
msgstr ""

#: ../../taichi/docs/compilation.rst:14
msgid "Taichi IR compilation, optimization, and binary generation"
msgstr ""

#: ../../taichi/docs/compilation.rst:15
msgid "Launching"
msgstr ""

#: ../../taichi/docs/compilation.rst:19
msgid "Let's consider the following simple kernel:"
msgstr ""

#: ../../taichi/docs/compilation.rst:21
msgid ""
"@ti.kernel\n"
"def add(tensor: ti.template(), delta: ti.i32):\n"
"  for i in tensor:\n"
"    tensor[i] += delta"
msgstr ""

#: ../../taichi/docs/compilation.rst:29
msgid "We also allocate two 1D tensors to simplify discussion:"
msgstr ""

#: ../../taichi/docs/compilation.rst:31
msgid ""
"x = ti.var(dt=ti.f32, shape=128)\n"
"y = ti.var(dt=ti.f32, shape=16)"
msgstr ""

#: ../../taichi/docs/compilation.rst:39
msgid ""
"When the ``ti.kernel`` decorator is executed, a kernel named ``add`` is "
"registered. Specifically, the Python Abstract Syntax Tree (AST) of the "
"``add`` function will be memorized. No compilation will happen until the "
"first invocation of ``add``."
msgstr ""

#: ../../taichi/docs/compilation.rst:47
msgid "add(x, 42)"
msgstr ""

#: ../../taichi/docs/compilation.rst:51
msgid ""
"When ``add`` is called for the first time, the Taichi frontend compiler "
"will instantiate the kernel."
msgstr ""

#: ../../taichi/docs/compilation.rst:53
msgid ""
"When you have a second call with the same template signature (explained "
"later), e.g.,"
msgstr ""

#: ../../taichi/docs/compilation.rst:55
msgid "add(x, 1)"
msgstr ""

#: ../../taichi/docs/compilation.rst:59
msgid "Taichi will directly reuse the previously compiled binary."
msgstr ""

#: ../../taichi/docs/compilation.rst:61
msgid ""
"Arguments hinted with ``ti.template()`` are template arguments, and will "
"incur template instantiation. For example,"
msgstr ""

#: ../../taichi/docs/compilation.rst:63
msgid "add(y, 42)"
msgstr ""

#: ../../taichi/docs/compilation.rst:67
msgid "will lead to a new instantiation of **add**."
msgstr ""

#: ../../taichi/docs/compilation.rst:70
msgid ""
"**Template signatures** are what distinguish different instantiations of "
"a kernel template. The signature of ``add(x, 42)`` is ``(x, ti.i32)``, "
"which is the same as that of ``add(x, 1)``. Therefore, the latter can "
"reuse the previously compiled binary. The signature of ``add(y, 42)`` is "
"``(y, ti.i32)``, a different value from the previous signature, therefore"
" a new instantiation and compilation will happen."
msgstr ""

#: ../../taichi/docs/compilation.rst:76
msgid ""
"Many basic operations in the Taichi standard library is implemented using"
" Taichi kernels for performance, with more or less metaprogramming "
"tricks. Invoking them will incur **implicit kernel instantiations**"
msgstr ""

#: ../../taichi/docs/compilation.rst:79
msgid ""
"Examples include ``x.to_numpy()`` and ``y.from_torch(torch_tensor)``. "
"When you invoke these functions, you will see kernel instantiations, as "
"Taichi kernels will be generated to offload the hard work to multiple CPU"
" cores/GPUs."
msgstr ""

#: ../../taichi/docs/compilation.rst:82
msgid ""
"As mentioned before, the second time you call the same operation, the "
"cached compiled kernel will be reused and no further compilation is "
"needed."
msgstr ""

#: ../../taichi/docs/compilation.rst:85
msgid "Code transformation and optimizations"
msgstr ""

#: ../../taichi/docs/compilation.rst:87
msgid ""
"When a new instantiation happens, the Taichi frontend compiler will "
"transform the kernel body AST into a Python script, which, when executed,"
" emits a Taichi frontend AST. Basically, some patches are applied to the "
"Python AST so that the Taichi frontend can recognize it."
msgstr ""

#: ../../taichi/docs/compilation.rst:91
msgid ""
"The Taichi AST lowering pass translates Taichi frontend IR into "
"hierarchical static single assignment (SSA) IR, which allows a series of "
"further IR passes to happen, such as"
msgstr ""

#: ../../taichi/docs/compilation.rst:94
msgid "Loop vectorization"
msgstr ""

#: ../../taichi/docs/compilation.rst:95
msgid "Type inference and checking"
msgstr ""

#: ../../taichi/docs/compilation.rst:96
msgid ""
"General simplifications such as common subexpression elimination (CSE), "
"dead instruction elimination (DIE), constant folding, and store "
"forwarding"
msgstr ""

#: ../../taichi/docs/compilation.rst:97
msgid "Access lowering"
msgstr ""

#: ../../taichi/docs/compilation.rst:98
msgid "Data access optimizations"
msgstr ""

#: ../../taichi/docs/compilation.rst:99
msgid ""
"Reverse-mode automatic differentiation (if using differentiable "
"programming)"
msgstr ""

#: ../../taichi/docs/compilation.rst:100
msgid "Parallelization and offloading"
msgstr ""

#: ../../taichi/docs/compilation.rst:101
msgid "Atomic operation demotion"
msgstr ""

#: ../../taichi/docs/compilation.rst:104
msgid "The just-in-time (JIT) compilation engine"
msgstr ""

#: ../../taichi/docs/compilation.rst:106
msgid ""
"Finally, the optimized SSA IR is fed into the LLVM IR codegen, and LLVM "
"JIT generates high-performance executable CPU/GPU programs."
msgstr ""

#: ../../taichi/docs/compilation.rst:109
msgid "Kernel launching"
msgstr ""

#: ../../taichi/docs/compilation.rst:111
msgid ""
"Taichi kernels will be ultimately launched as multi-threaded CPU tasks or"
" CUDA kernels."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:2
msgid "Contribution guidelines"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:4
msgid ""
"First of all, thank you for contributing! We welcome contributions of all"
" forms, including but not limited to"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:7
msgid "Bug fixes"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:8
msgid "New features"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:9
#: ../../taichi/docs/contributor_guide.rst:179
msgid "Documentation"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:10
msgid "Improved error messages that are more user-friendly"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:11
msgid "New example programs"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:12
msgid "Compiler performance patches"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:13
msgid ""
"Minor typo fixes in the documentation, code, comments (please directly "
"make a pull request for minor issues like these)"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:16
msgid "How to contribute bug fixes and new features"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:18
msgid ""
"Issues marked with `\"welcome contribution\" <https://github.com/taichi-"
"dev/taichi/issues?q=is%3Aopen+is%3Aissue+label%3A%22welcome+contribution%22>`_"
" are easy ones to start with."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:20
msgid ""
"Please first leave a note (e.g. *I know how to fix this and would like to"
" help!*) on the issue, so that people know someone is already working on "
"it. This helps prevent redundant work;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:22
msgid ""
"If no core developer has commented and described a potential solution on "
"the issue, please briefly describe your plan, and wait for a core "
"developer to reply before you start. This helps keep implementations "
"simple and effective."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:26
msgid "High-level guidelines"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:28
msgid "Be pragmatic: practically solving problems is our ultimate goal."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:29
msgid ""
"No overkills: always use *easy* solutions to solve easy problems, so that"
" you have time and energy for real hard ones."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:30
msgid ""
"Almost every design decision has pros and cons. A decision is `good` if "
"its pros outweigh its cons. Always think about both sides."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:31
msgid ""
"Debugging is hard. Changesets should be small so that sources of bugs can"
" be easily pinpointed."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:32
msgid "Unit/integration tests are our friends."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:35
msgid ""
"“There are two ways of constructing a software design: One way is to make"
" it so simple that there are obviously no deficiencies, and the other way"
" is to make it so complicated that there are no obvious deficiencies. "
"`The first method is far more difficult`.”     --- `C.A.R. Hoare "
"<https://en.wikipedia.org/wiki/Tony_Hoare>`_"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:38
msgid "Effective communication"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:40
msgid ""
"How much information we effectively convey, is way more important than "
"how many words we typed."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:41
msgid "Be constructive. Be polite. Be organized. Be concise."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:42
msgid "Bulleted lists are our friends."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:43
msgid ""
"Proofread before you post: if you are the reader, can you understand what"
" you typed?"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:44
msgid ""
"If you are not a native speaker, consider using a spell checker such as "
"`Grammarly <https://app.grammarly.com/>`_."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:48
msgid "Making good pull requests"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:50
msgid ""
"PRs with **small** changesets are preferred. A PR should ideally address "
"**only one issue**."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:51
msgid ""
"All commits in a PR will always be **squashed and merged into master as a"
" single commit**."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:52
msgid ""
"When implementing a complex feature, consider breaking it down into small"
" PRs, to keep a more detailed development history and to interact with "
"core developers more frequently."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:53
msgid ""
"If you want early feedback from core developers, open a PR in **Draft** "
"state on GitHub so that you can share your progress."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:54
msgid "If you are making multiple PRs"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:56
msgid ""
"Independent PRs should be based on **different** branches forking from "
"``master``;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:57
msgid ""
"PRs with dependencies should be raised only after all prerequisite PRs "
"are merged into ``master``."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:59
msgid "All PRs should ideally come with corresponding **tests**;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:60
msgid ""
"All PRs should come with **documentation update**, except for internal "
"compiler implementations;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:61
msgid ""
"All PRs should always be **rebased** onto the latest master branch before"
" merging;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:62
msgid ""
"All PRs should pass **continuous integration tests** before they get "
"merged;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:63
msgid "PR authors **should not squash commits on their own**;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:64
msgid "PR titles should follow :ref:`prtag`;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:65
msgid ""
"A great article from Google on `how to have your PR merged quickly "
"<https://testing.googleblog.com/2017/06/code-health-too-many-comments-on-"
"your.html>`_. `[PDF] <https://github.com/yuanming-"
"hu/public_files/blob/master/graphics/taichi/google_review_comments.pdf>`_"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:69
msgid "Reviewing & PR merging"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:71
msgid "Please try to follow these tips from Google"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:73
msgid ""
"`Code Health: Understanding Code In Review "
"<https://testing.googleblog.com/2018/05/code-health-understanding-code-"
"in-review.html>`_; `[PDF] <https://github.com/yuanming-"
"hu/public_files/blob/master/graphics/taichi/google_understanding_code.pdf>`_"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:74
msgid ""
"`Code Health: Respectful Reviews == Useful Reviews "
"<https://testing.googleblog.com/2019/11/code-health-respectful-reviews-"
"useful.html>`_. `[PDF] <https://github.com/yuanming-"
"hu/public_files/blob/master/graphics/taichi/google_respectful_reviews.pdf>`_"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:76
msgid "The merger should always **squash and merge** PRs into the master branch;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:77
msgid "The master branch is required to have a **linear history**;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:78
msgid ""
"Make sure the PR passes **continuous integration tests**, except for "
"cases like documentation updates;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:79
msgid "Make sure the title follows :ref:`prtag`."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:83
msgid "Using continuous integration"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:85
msgid ""
"Continuous Integration (CI), will **build** and **test** your commits in "
"a PR against in environments."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:86
msgid ""
"Currently, Taichi uses `Travis CI <https://travis-ci.org>`_ (for OS X and"
" Linux) and `AppVeyor <https://www.appveyor.com>`_ (for Windows)."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:87
msgid "CI will be triggered everytime you push commits to an open PR."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:88
msgid ""
"You can prepend ``[skip ci]`` to your commit message to avoid triggering "
"CI. e.g. ``[skip ci] This commit will not trigger CI``"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:89
msgid ""
"A tick on the right of commit hash means CI passed, a cross means CI "
"failed."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:92
msgid "Enforcing code style"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:93
msgid ""
"Locally, you can run ``ti format`` in the command line to re-format code "
"style. Note that you have to install ``clang-format-6.0`` and ``yapf "
"v0.29.0`` locally before you use ``ti format``."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:94
msgid ""
"If you don't have to install these formatting tools locally, use the "
"**format server**. It's an online version of ``ti format``."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:96
msgid "Go to http://kun.csail.mit.edu:31415/, and click at the desired PR id."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:97
msgid ""
"Come back to the PR page, you'll see a user called @taichi-gardener (bot)"
" pushed a commit named ``[skip ci] enforce code format``."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:98
msgid ""
"You won't see the bot's commit if it didn't find anything not matching "
"the format."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:99
msgid ""
"Then please run ``git pull`` in your local branch to pull the formatted "
"code."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:100
msgid ""
"Note that commit messages marked with ``[format]`` will automatically "
"trigger the format server. e.g. ``[format] your commit message``"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:106
msgid "PR title tags"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:107
msgid ""
"Please always prepend exactly one tag such as ``[Metal]`` to PR titles. "
"For example, \"[Metal] Support bitmasked SNode\", \"[OpenGL] "
"AtomicMin/Max support\", or \"[Opt] Enhanced constant folding\"."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:109
msgid "Existing tags:"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:111
msgid "``[Metal], [OpenGL], [CPU], [CUDA], [AMDGPU], [LLVM]``: backends;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:112
msgid "``[LLVM]``: the LLVM backend shared by CPUs and CUDA;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:113
msgid "``[Lang]``: frontend language features, including syntax sugars;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:114
msgid "``[Std]``: standard library, e.g. `ti.Matrix` and `ti.Vector`;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:115
msgid "``[IR]``: intermediate representation;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:116
msgid ""
"``[Sparse]``: sparse computation, dynamic memory allocator, and garbage "
"collection;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:117
msgid "``[Opt]``: IR optimization passes;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:118
msgid "``[Async]``: asynchronous execution engine;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:119
msgid "``[Type]``: type system;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:120
msgid "``[Infra]``: general infrastructure, e.g. logging, image reader;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:121
msgid "``[GUI]``: the built-in GUI system;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:122
msgid "``[Refactor]``: code refactoring;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:123
msgid "``[AutoDiff]``: automatic differentiation;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:124
msgid "``[CLI]``: commandline interfaces, e.g. the ``ti`` command;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:125
msgid "``[Doc]``: documentation;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:126
msgid "``[Example]``: examples under ``taichi/examples/``;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:127
msgid "``[Test]``: adding or improving tests under ``tests/``;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:128
msgid "``[PyPI]``: PyPI package release;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:129
msgid ""
"``[Misc]``: something that doesn't belong to any category, such as "
"version bump, reformatting;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:130
msgid "``[Bug]``: bug fixes;"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:131
msgid ""
"**When introducing a new tag, please update the list here in the first PR"
" with that tag, so that people can follow.**"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:135
msgid ""
"We do appreciate all kinds of contributions, yet we should not expose the"
" title of every PR to end-users. Therefore the changelog will distinguish"
" `what the user should know` from `what the developers are doing`. This "
"is done by **capitalizing PR tags**:"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:139
msgid ""
"PRs with visible/notable features to the users should be marked with tags"
" starting with **the first letter capitalized**, e.g. ``[Metal], "
"[OpenGL], [IR], [Lang], [CLI]``. When releasing a new version, a script "
"will generate a changelog with these changes (PR title) highlighted. "
"Therefore it is **important** to make sure the end-users can understand "
"what your PR does, **based on your PR title**."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:141
msgid ""
"Other PRs (underlying development/intermediate implementation) should use"
" tags with **everything in lowercase letters**: e.g. ``[metal], [opengl],"
" [ir], [lang], [cli]``."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:144
msgid "Tips on the Taichi compiler development"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:146
msgid ""
":ref:`compilation` may worth checking out. It explains the whole "
"compilation process."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:148
msgid ""
":ref:`regression` may worth checking out when the work involves IR "
"optimization."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:150
msgid ""
"When creating a Taichi program using ``ti.init(arch=desired_arch, "
"**kwargs)``, pass in the following parameters to make the Taichi compiler"
" print out IR:"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:152
msgid ""
"``print_preprocessed = True``: print results of the frontend Python AST "
"transform. The resulting scripts will generate a Taichi Frontend AST when"
" executed."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:153
msgid ""
"``print_ir = True``: print the Taichi IR transformation process of kernel"
" (excluding accessors) compilation."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:154
msgid "``print_kernel_llvm_ir = True``: print the emitted LLVM IR by Taichi."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:155
msgid ""
"``print_kernel_llvm_ir_optimized = True``: print the optimized LLVM IR "
"for each kernel."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:156
msgid ""
"``print_accessor_ir = True``: print the IR transformation process of data"
" accessors, which are special and simple kernels. (This is rarely used, "
"unless you are debugging the compilation of data accessors.)"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:160
msgid ""
"Data accessors in Python-scope are implemented as special Taichi kernels."
" For example, ``x[1, 2, 3] = 3`` will call the writing accessor kernel of"
" ``x``, and ``print(y[42])`` will call the reading accessor kernel of "
"``y``."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:166
msgid "Testing"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:168
msgid ""
"Tests should be added to ``taichi/tests``. Use ``ti test`` to run all the"
" tests. Use ``ti test -v`` for verbose outputs. Use ``ti test "
"<filename(s)>`` to run specific tests. e.g. ``ti test numpy_io`` and ``ti"
" test test_numpy_io.py`` are equivalent. Use ``ti test -a <arch(s)>`` for"
" test against specified architectures. e.g. ``ti test -a opengl`` or ``ti"
" test numpy_io -a cuda,metal``. Use ``ti test -na <arch(s)>`` for test "
"all architectures exclude some of them. e.g. ``ti test -na opengl,cuda``."
" Use ``ti test -c`` to run only the C++ tests. e.g. ``ti test -c "
"alg_simp``"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:176
msgid "For more options, see ``ti test -h``."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:181
msgid ""
"Use ``ti doc`` to build the documentation locally. Open the documentation"
" at ``taichi/doc/build/index.html``. On Linux/OS X, use ``watch -n 1 ti "
"doc`` to continuously build the documentation."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:186
msgid "C++ and Python standards"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:188
msgid ""
"The C++ part of Taichi is written in C++17, and the Python part in 3.6+. "
"You can assume that C++17 and Python 3.6 features are always available."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:193
msgid "(Linux only) pinpointing runtime errors using ``gdb``"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:194
msgid ""
"A quick way to pinpoint common runtime errors such as segmentation "
"faults/assertion failures. When Taichi crashes, ``gdb`` will be triggered"
" and attach to the current thread. You might be prompt to enter sudo "
"password required for gdb thread attaching. After entering ``gdb``, check"
" the stack backtrace with command ``bt`` (``backtrace``), then find the "
"line of code triggering the error."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:202
msgid "Efficient code navigation across Python/C++"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:203
msgid ""
"If you work on the language frontend (Python/C++ interface), to navigate "
"around the code base, `ffi-navigator <https://github.com/tqchen/ffi-"
"navigator>`_ allows you to jump from Python bindings to their definitions"
" in C++. Follow their README to set up your editor."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:209
msgid "Folder structure"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:211
msgid "Key folders are"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:213
msgid "``taichi``: The core compiler implementation"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:215
msgid "``program``: Top-level constructs"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:216
msgid "``runtime``: Runtime environments"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:217
msgid "``codegen``: Code generators"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:218
msgid "``struct``: Struct compilers"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:219
msgid "``backends``: Device-dependent code generators/runtime environments"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:220
msgid "``llvm``: LLVM utils"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:221
msgid "``ir``: Intermediate representation"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:222
msgid "``transforms``: IR transform passes"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:223
msgid "``analysis``: Static analysis passes"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:224
msgid "``python``: C++/Python interfaces"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:226
msgid "``python``: Python frontend implementation"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:227
msgid "``examples``: Examples"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:228
msgid "``docs``: Documentation"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:229
msgid "``tests``: C++ and Python tests"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:230
msgid "``benchmarks``: Performance benchmarks"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:231
msgid "``misc``: Random (yet useful) files"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:232
msgid "..."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:235
msgid "Upgrading CUDA"
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:237
msgid ""
"Right now we are targeting CUDA 10. When upgrading CUDA version, the file"
" ``external/cuda_libdevice/slim_libdevice.10.bc`` should also be replaced"
" with a newer version."
msgstr ""

#: ../../taichi/docs/contributor_guide.rst:240
msgid ""
"To generate the slimmed version of libdevice based on a full "
"``libdevice.X.bc`` file from a CUDA installation, use ``ti run "
"make_slim_libdevice [libdevice.X.bc file]``"
msgstr ""

#: ../../taichi/docs/cpp_style.rst:2
msgid "C++ Style"
msgstr ""

#: ../../taichi/docs/cpp_style.rst:5
msgid "Naming"
msgstr ""

#: ../../taichi/docs/cpp_style.rst:6
msgid ""
"Variable names should consist of lowercase words connected by "
"underscores, e.g. ``llvm_context``."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:7
msgid ""
"Class and struct names should consist of words with first letters "
"capitalized, e.g. ``CodegenLLVM``."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:8
msgid ""
"Macros should be capital start with ``TI``, such as ``TI_INFO``, "
"``TI_IMPLEMENTATION``."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:10
msgid ""
"We do not encourage the use of macro, although there are cases where "
"macros are inevitable."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:12
msgid ""
"Filenames should consist of lowercase words connected by underscores, "
"e.g. ``ir_printer.cpp``."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:15
msgid "Dos"
msgstr ""

#: ../../taichi/docs/cpp_style.rst:16
msgid "Use ``auto`` for local variables when appropriate."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:17
msgid "Mark ``override`` and ``const`` when necessary."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:20
msgid "Don'ts"
msgstr ""

#: ../../taichi/docs/cpp_style.rst:21
msgid "C language legacies:"
msgstr ""

#: ../../taichi/docs/cpp_style.rst:23
msgid "``printf`` (use ``fmtlib::print`` instead)."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:24
msgid ""
"``new`` & ``free``. Use smart pointers (``std::unique_ptr, "
"std::shared_ptr`` instead for ownership management)."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:26
msgid "Prefix member functions with ``m_`` or ``_``."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:27
msgid "Virtual function call in constructors/destructors."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:28
msgid "``NULL``, use ``nullptr`` instead."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:29
msgid "``using namespace std;`` in global scope."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:30
msgid "``typedef``. Use ``using`` instead."
msgstr ""

#: ../../taichi/docs/cpp_style.rst:33
msgid "Automatic code formatting"
msgstr ""

#: ../../taichi/docs/cpp_style.rst:34
msgid "Please run ``ti format``"
msgstr ""

#: ../../taichi/docs/dev_install.rst:4
msgid "Developer installation"
msgstr ""

#: ../../taichi/docs/dev_install.rst:6
msgid ""
"Note this is for the compiler developers of the Taichi programming "
"language. End users should use the pip packages instead of building from "
"scratch. To build with NVIDIA GPU support, CUDA 10.0+ is needed. This "
"installation guide works for Ubuntu 16.04+ and OS X 10.14+. For precise "
"build instructions on Windows, please check out `appveyor.yml "
"<https://github.com/taichi-dev/taichi/blob/master/appveyor.yml>`_, which "
"does basically the same thing as the following instructions."
msgstr ""

#: ../../taichi/docs/dev_install.rst:12
msgid ""
"Note that on Linux/OS X, ``clang`` is the only supported compiler for "
"compiling the Taichi compiler. On Windows only MSVC supported."
msgstr ""

#: ../../taichi/docs/dev_install.rst:15
msgid "Installing Depedencies"
msgstr ""

#: ../../taichi/docs/dev_install.rst:17
msgid "Make sure you are using Python 3.6/3.7/3.8"
msgstr ""

#: ../../taichi/docs/dev_install.rst:18
msgid "Execute"
msgstr ""

#: ../../taichi/docs/dev_install.rst:20
msgid ""
"python3 -m pip install --user setuptools astpretty astor pytest opencv-"
"python pybind11\n"
"python3 -m pip install --user Pillow numpy scipy GitPython yapf colorama "
"psutil autograd"
msgstr ""

#: ../../taichi/docs/dev_install.rst:25
msgid ""
"(If on Ubuntu) Execute ``sudo apt install libtinfo-dev clang-8``. "
"(``clang-7`` should work as well)."
msgstr ""

#: ../../taichi/docs/dev_install.rst:27
msgid "(If on other Linux distributions) Please build clang 8.0.1 from scratch:"
msgstr ""

#: ../../taichi/docs/dev_install.rst:29
msgid ""
"wget https://github.com/llvm/llvm-"
"project/releases/download/llvmorg-8.0.1/cfe-8.0.1.src.tar.xz\n"
"tar xvJf cfe-8.0.1.src.tar.xz\n"
"cd cfe-8.0.1.src\n"
"mkdir build\n"
"cd build\n"
"cmake ..\n"
"make -j 8\n"
"sudo make install"
msgstr ""

#: ../../taichi/docs/dev_install.rst:41
msgid "Make sure you have LLVM 8.0.1 built from scratch. To do so:"
msgstr ""

#: ../../taichi/docs/dev_install.rst:43
msgid ""
"wget https://github.com/llvm/llvm-"
"project/releases/download/llvmorg-8.0.1/llvm-8.0.1.src.tar.xz\n"
"tar xvJf llvm-8.0.1.src.tar.xz\n"
"cd llvm-8.0.1.src\n"
"mkdir build\n"
"cd build\n"
"cmake .. -DLLVM_ENABLE_RTTI:BOOL=ON -DBUILD_SHARED_LIBS:BOOL=OFF "
"-DCMAKE_BUILD_TYPE=Release -DLLVM_TARGETS_TO_BUILD=\"X86;NVPTX\" "
"-DLLVM_ENABLE_ASSERTIONS=ON\n"
"# If you are building on NVIDIA Jetson TX2, use "
"-DLLVM_TARGETS_TO_BUILD=\"ARM;NVPTX\"\n"
"make -j 8\n"
"sudo make install"
msgstr ""

#: ../../taichi/docs/dev_install.rst:56
msgid "Setting up Taichi for development"
msgstr ""

#: ../../taichi/docs/dev_install.rst:58
msgid "Clone the taichi repo, and build:"
msgstr ""

#: ../../taichi/docs/dev_install.rst:60
msgid ""
"git clone https://github.com/taichi-dev/taichi --depth=1 --branch=master\n"
"git submodule update --init --recursive --depth=1\n"
"cd taichi\n"
"mkdir build\n"
"cd build\n"
"cmake ..\n"
"# if you are building with CUDA 10.0, use the line below:\n"
"# cmake .. -DCUDA_VERSION=10.0 -DTI_WITH_CUDA:BOOL=True\n"
"make -j 8"
msgstr ""

#: ../../taichi/docs/dev_install.rst:72
msgid "Add the following script to your ``~/.bashrc``:"
msgstr ""

#: ../../taichi/docs/dev_install.rst:74
msgid ""
"export TAICHI_REPO_DIR=/home/XXX/taichi  # Path to your taichi repository"
"\n"
"export PYTHONPATH=$TAICHI_REPO_DIR/python/:$PYTHONPATH\n"
"export PATH=$TAICHI_REPO_DIR/bin/:$PATH\n"
"# export PATH=/opt/llvm/bin:$PATH # Uncomment if your llvm-8 or clang-8 "
"is in /opt"
msgstr ""

#: ../../taichi/docs/dev_install.rst:81
msgid "Execute ``source ~/.bashrc`` to reload shell config."
msgstr ""

#: ../../taichi/docs/dev_install.rst:82
msgid ""
"Execute ``python3 -m taichi test`` to run all the tests. It may take up "
"to 5 minutes to run all tests."
msgstr ""

#: ../../taichi/docs/dev_install.rst:83
msgid "Check out ``examples`` for runnable examples. Run them with ``python3``."
msgstr ""

#: ../../taichi/docs/dev_install.rst:87
msgid "Setting up CUDA 10.1 on Ubuntu 18.04"
msgstr ""

#: ../../taichi/docs/dev_install.rst:89
msgid ""
"First, make sure you have CUDA 10.1 installed. Check this by running "
"``nvcc --version`` or ``cat /usr/local/cuda/version.txt``"
msgstr ""

#: ../../taichi/docs/dev_install.rst:93
msgid ""
"If you don't have it - go ahead to `this website "
"<https://developer.nvidia.com/cuda-downloads>`_ and download it."
msgstr ""

#: ../../taichi/docs/dev_install.rst:95
msgid ""
"These instructions were copied from the webiste above for x86_64 "
"architecture"
msgstr ""

#: ../../taichi/docs/dev_install.rst:97
msgid ""
"wget "
"https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64"
"/cuda-ubuntu1804.pin\n"
"sudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-"
"pin-600\n"
"wget "
"http://developer.download.nvidia.com/compute/cuda/10.1/Prod/local_installers"
"/cuda-repo-ubuntu1804-10-1-local-10.1.243-418.87.00_1.0-1_amd64.deb\n"
"sudo dpkg -i cuda-repo-"
"ubuntu1804-10-1-local-10.1.243-418.87.00_1.0-1_amd64.deb\n"
"sudo apt-key add /var/cuda-"
"repo-10-1-local-10.1.243-418.87.00/7fa2af80.pub\n"
"sudo apt-get update\n"
"sudo apt-get -y install cuda"
msgstr ""

#: ../../taichi/docs/dev_install.rst:108
msgid "Prebuilt LLVM for Windows CI"
msgstr ""

#: ../../taichi/docs/dev_install.rst:110
msgid ""
"cmake .. -G\"Visual Studio 15 2017 Win64\"  -DLLVM_ENABLE_RTTI:BOOL=ON "
"-DBUILD_SHARED_LIBS:BOOL=OFF -DCMAKE_BUILD_TYPE=Release "
"-DLLVM_TARGETS_TO_BUILD=\"X86;NVPTX\" -DLLVM_ENABLE_ASSERTIONS=ON "
"-Thost=x64 -DLLVM_BUILD_TESTS:BOOL=OFF -DCMAKE_INSTALL_PREFIX=installed"
msgstr ""

#: ../../taichi/docs/dev_install.rst:114
msgid ""
"Then use Visual Studio to build. After building the ``INSTALL`` project "
"(under folder \"CMakePredefinedTargets\"). After build completes, find "
"your LLVM binaries/headers in `build/include`."
msgstr ""

#: ../../taichi/docs/dev_install.rst:117
msgid "Troubleshooting"
msgstr ""

#: ../../taichi/docs/dev_install.rst:119
msgid "Run with debug mode to see if there's any illegal memory access"
msgstr ""

#: ../../taichi/docs/dev_install.rst:120
msgid ""
"Disable compiler optimizations to quickly confirm that the issue is not "
"cause by optimization"
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:4
#: ../../taichi/docs/overview.rst:10
msgid "Differentiable programming"
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:6
msgid ""
"This page is work in progress. Please check out `the DiffTaichi paper "
"<https://arxiv.org/pdf/1910.00935.pdf>`_ and `video "
"<https://www.youtube.com/watch?v=Z1xvAZve9aE>`_ to learn more about "
"Taichi differentiable programming."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:8
msgid ""
"The `DiffTaichi repo <https://github.com/yuanming-hu/difftaichi>`_ "
"contains 10 differentiable physical simulators built with Taichi "
"differentiable programming."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:11
msgid ""
"Unlike tools such as TensorFlow where **immutable** output buffers are "
"generated, the **imperative** programming paradigm adopted in Taichi "
"allows programmers to freely modify global tensors. To make automatic "
"differentiation well-defined under this setting, we make the following "
"assumption on Taichi programs for differentiable programming:"
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:16
msgid "**Global Data Access Rules:**"
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:18
msgid ""
"If a global tensor element is written more than once, then starting from "
"the second write, the write **must** come in the form of an atomic add "
"(“accumulation\", using ``ti.atomic_add`` or simply ``+=``)."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:20
msgid ""
"No read accesses happen to a global tensor element, until its "
"accumulation is done."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:22
msgid ""
"**Kernel Simplicity Rule:** Kernel body consists of multiple `simply "
"nested` for-loops. I.e., each for-loop can either contain exactly one "
"(nested) for-loop (and no other statements), or a group of statements "
"without loops."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:25
msgid "Example:"
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:27
msgid ""
"@ti.kernel\n"
"def differentiable_task():\n"
"  for i in x:\n"
"    x[i] = y[i]\n"
"\n"
"  for i in range(10):\n"
"    for j in range(20):\n"
"      for k in range(300):\n"
"        ... do whatever you want, as long as there are no loops\n"
"\n"
"  # Not allowed. The outer for loop contains two for loops\n"
"  for i in range(10):\n"
"    for j in range(20):\n"
"      ...\n"
"    for j in range(20):\n"
"      ..."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:46
msgid "Taichi programs that violate this rule has an undefined gradient behavior."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:50
msgid ""
"**static for-loops** (e.g. ``for i in ti.static(range(4))``) will get "
"unrolled by the Python frontend preprocessor and does not count as a "
"level of loop."
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:53
msgid ""
"A few examples with neural network controllers optimized using "
"differentiable simulators and brute-force gradient descent:"
msgstr ""

#: ../../taichi/docs/differentiable_programming.rst:61
msgid "Documentation WIP."
msgstr ""

#: ../../taichi/docs/external.rst:4
msgid "Interacting with external arrays"
msgstr ""

#: ../../taichi/docs/external.rst:6
msgid "**External arrays** refer to ``numpy.ndarray`` or ``torch.Tensor``."
msgstr ""

#: ../../taichi/docs/external.rst:9
msgid "Conversion between Taichi tensors and external arrays"
msgstr ""

#: ../../taichi/docs/external.rst:11
msgid "Use ``to_numpy``/``from_numpy``/``to_torch``/``from_torch``:"
msgstr ""

#: ../../taichi/docs/external.rst:13
msgid ""
"n = 4\n"
"m = 7\n"
"\n"
"# Taichi tensors\n"
"val = ti.var(ti.i32, shape=(n, m))\n"
"vec = ti.Vector(3, dt=ti.i32, shape=(n, m))\n"
"mat = ti.Matrix(3, 4, dt=ti.i32, shape=(n, m))\n"
"\n"
"# Scalar\n"
"arr = np.ones(shape=(n, m), dtype=np.int32)\n"
"\n"
"val.from_numpy(arr)\n"
"\n"
"arr = val.to_numpy()\n"
"\n"
"# Vector\n"
"arr = np.ones(shape=(n, m, 3), dtype=np.int32)\n"
"\n"
"vec.from_numpy(arr)\n"
"\n"
"arr = np.ones(shape=(n, m, 3, 1), dtype=np.int32)\n"
"vec.from_numpy(arr)\n"
"\n"
"arr = vec.to_numpy()\n"
"assert arr.shape == (n, m, 3, 1)\n"
"\n"
"arr = vec.to_numpy(as_vector=True)\n"
"assert arr.shape == (n, m, 3)\n"
"\n"
"# Matrix\n"
"arr = np.ones(shape=(n, m, 3, 4), dtype=np.int32)\n"
"\n"
"mat.from_numpy(arr)\n"
"\n"
"arr = mat.to_numpy()\n"
"assert arr.shape == (n, m, 3, 4)"
msgstr ""

#: ../../taichi/docs/external.rst:54
msgid "Using external arrays as Taichi kernel parameters"
msgstr ""

#: ../../taichi/docs/external.rst:56
msgid ""
"The type hint for external array parameters is ``ti.ext_arr()``. Please "
"see the example below. Note that struct-for's on external arrays are not "
"supported."
msgstr ""

#: ../../taichi/docs/external.rst:59
msgid ""
"n = 4\n"
"m = 7\n"
"\n"
"val = ti.var(ti.i32, shape=(n, m))\n"
"\n"
"@ti.kernel\n"
"def test_numpy(arr: ti.ext_arr()):\n"
"  for i in range(n):\n"
"    for j in range(m):\n"
"      arr[i, j] += i + j\n"
"\n"
"a = np.empty(shape=(n, m), dtype=np.int32)\n"
"\n"
"for i in range(n):\n"
"  for j in range(m):\n"
"    a[i, j] = i * j\n"
"\n"
"test_numpy(a)\n"
"\n"
"for i in range(n):\n"
"  for j in range(m):\n"
"    assert a[i, j] == i * j + i + j"
msgstr ""

#: ../../taichi/docs/faq.rst:2
msgid "Frequently Asked Questions"
msgstr ""

#: ../../taichi/docs/faq.rst:4
msgid ""
"**Can a user iterate over irregular topology instead of grids, such as "
"tetrahedra meshes, line segment vertices?** These structures have to be "
"represented using 1D arrays in Taichi. You can still iterate over it "
"using `for i in x` or `for i in range(n)`. However, at compile time, "
"there's little the Taichi compiler can do for you to optimize it. You can"
" still tweak the data layout to get different run time cache behaviors "
"and performance numbers."
msgstr ""

#: ../../taichi/docs/faq.rst:8
msgid ""
"**Can potential energies be differentiated automatically to get forces?**"
" Yes. Taichi supports automatic differentiation. We do have an `example "
"<https://github.com/yuanming-"
"hu/taichi/blob/master/examples/mpm_lagrangian_forces.py>`_ for this."
msgstr ""

#: ../../taichi/docs/faq.rst:12
msgid ""
"**Does the compiler backend support the same quality of optimizations for"
" the GPU and CPU? For instance, if I switch to using the CUDA backend, do"
" I lose the cool hash-table optimizations?** Mostly. The CPU/GPU "
"compilation workflow are basically the same, except for vectorization on "
"SIMD CPUs. You still have the hash table optimization on GPUs."
msgstr ""

#: ../../taichi/docs/global_settings.rst:2
msgid "Global Settings"
msgstr ""

#: ../../taichi/docs/global_settings.rst:4
msgid ""
"Restart the Taichi runtime system (clear memory, destroy all variables "
"and kernels): ``ti.reset()``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:5
msgid "Eliminate verbose outputs: ``ti.get_runtime().set_verbose(False)``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:6
msgid "To not trigger GDB when crashes: ``export TI_GDB_TRIGGER=0``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:7
msgid "To not use unified memory for CUDA: ``export TI_USE_UNIFIED_MEMORY=0``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:8
msgid ""
"To specify pre-allocated memory size for CUDA: ``export "
"TI_DEVICE_MEMORY_GB=0.5``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:9
msgid "Show more detailed log (TI_TRACE): ``export TI_LOG_LEVEL=trace``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:10
msgid "To specify which GPU to use for CUDA: ``export CUDA_VISIBLE_DEVICES=0``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:11
msgid "To specify which Arch to use: ``export TI_ARCH=cuda``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:12
msgid "To print intermediate IR generated: ``export TI_PRINT_IR=1``"
msgstr ""

#: ../../taichi/docs/global_settings.rst:13
msgid "To print verbose details: ``export TI_VERBOSE=1``"
msgstr ""

#: ../../taichi/docs/gui.rst:4
msgid "GUI system"
msgstr ""

#: ../../taichi/docs/gui.rst:6
msgid ""
"Taichi has a built-in GUI system to help users display graphic results "
"easier."
msgstr ""

#: ../../taichi/docs/gui.rst:10
msgid "Create a window"
msgstr ""

#: ../../taichi/docs/gui.rst ../../taichi/docs/matrix.rst
#: ../../taichi/docs/scalar_tensor.rst ../../taichi/docs/snode.rst
#: ../../taichi/docs/vector.rst
msgid "Parameters"
msgstr ""

#: ../../taichi/docs/gui.rst:15
msgid "(string) the window title"
msgstr ""

#: ../../taichi/docs/gui.rst:16
msgid "(scalar or tuple) resolution / size of the window"
msgstr ""

#: ../../taichi/docs/gui.rst:17
msgid "(optional, RGB hex) background color of the window"
msgstr ""

#: ../../taichi/docs/gui.rst:18
msgid "(GUI) an object represents the window"
msgstr ""

#: ../../taichi/docs/gui.rst:20
msgid "Create a window. If ``res`` is scalar, then width will be equal to height."
msgstr ""

#: ../../taichi/docs/gui.rst:23
msgid "This creates a window whose width is 1024, height is 768:"
msgstr ""

#: ../../taichi/docs/gui.rst:27
msgid "gui = ti.GUI('Window Title', (1024, 768))"
msgstr ""

#: ../../taichi/docs/gui.rst:32 ../../taichi/docs/gui.rst:54
#: ../../taichi/docs/gui.rst:90 ../../taichi/docs/gui.rst:100
#: ../../taichi/docs/gui.rst:114 ../../taichi/docs/gui.rst:125
#: ../../taichi/docs/gui.rst:136
msgid "(GUI) the window object"
msgstr ""

#: ../../taichi/docs/gui.rst:33
msgid "(optional, string) see notes below"
msgstr ""

#: ../../taichi/docs/gui.rst:35
msgid "Show the window on the screen."
msgstr ""

#: ../../taichi/docs/gui.rst:38
msgid ""
"If `filename` is specified, screenshot will be saved to the file "
"specified by the name. For example, this screenshots each frame of the "
"window, and save it in ``.png``'s:"
msgstr ""

#: ../../taichi/docs/gui.rst:42
msgid ""
"for frame in range(10000):\n"
"    render(img)\n"
"    gui.set_image(img)\n"
"    gui.show(f'{frame:06d}.png')"
msgstr ""

#: ../../taichi/docs/gui.rst:49
msgid "Paint a window"
msgstr ""

#: ../../taichi/docs/gui.rst:55
msgid "(np.array or Tensor) tensor containing the image, see notes below"
msgstr ""

#: ../../taichi/docs/gui.rst:57
msgid "Set a image to display on the window."
msgstr ""

#: ../../taichi/docs/gui.rst:59
msgid ""
"The pixel, ``i`` from bottom to up, ``j`` from left to right, is set to "
"the value of ``img[i, j]``."
msgstr ""

#: ../../taichi/docs/gui.rst:62
msgid "If the window size is ``(x, y)``, then the ``img`` must be one of:"
msgstr ""

#: ../../taichi/docs/gui.rst:64
msgid "``ti.var(shape=(x, y))``, a grey-scale image"
msgstr ""

#: ../../taichi/docs/gui.rst:66
msgid "``ti.var(shape=(x, y, 3))``, where `3` is for `(r, g, b)` channels"
msgstr ""

#: ../../taichi/docs/gui.rst:68
msgid "``ti.Vector(3, shape=(x, y))`` (see :ref:`vector`)"
msgstr ""

#: ../../taichi/docs/gui.rst:70
msgid "``np.ndarray(shape=(x, y))``"
msgstr ""

#: ../../taichi/docs/gui.rst:72
msgid "``np.ndarray(shape=(x, y, 3))``"
msgstr ""

#: ../../taichi/docs/gui.rst:75
msgid "The data type of ``img`` must be one of:"
msgstr ""

#: ../../taichi/docs/gui.rst:77
msgid "float32, clamped into [0, 1]"
msgstr ""

#: ../../taichi/docs/gui.rst:79
msgid "float64, clamped into [0, 1]"
msgstr ""

#: ../../taichi/docs/gui.rst:81
msgid "uint8, range [0, 255]"
msgstr ""

#: ../../taichi/docs/gui.rst:83
msgid "uint16, range [0, 65535]"
msgstr ""

#: ../../taichi/docs/gui.rst:85
msgid "uint32, range [0, UINT_MAX]"
msgstr ""

#: ../../taichi/docs/gui.rst:91
msgid "(tuple of 2) the position of circle"
msgstr ""

#: ../../taichi/docs/gui.rst:92
msgid "(optional, RGB hex) color to fill the circle"
msgstr ""

#: ../../taichi/docs/gui.rst:93 ../../taichi/docs/gui.rst:103
msgid "(optional, scalar) the radius of circle"
msgstr ""

#: ../../taichi/docs/gui.rst:95
msgid "Draw a solid circle."
msgstr ""

#: ../../taichi/docs/gui.rst:101
msgid "(np.array) the position of circles"
msgstr ""

#: ../../taichi/docs/gui.rst:102
msgid "(optional, RGB hex or np.array of uint32) color(s) to fill circles"
msgstr ""

#: ../../taichi/docs/gui.rst:105
msgid "Draw solid circles."
msgstr ""

#: ../../taichi/docs/gui.rst:109
msgid ""
"If ``color`` is a numpy array, circle at ``pos[i]`` will be colored with "
"``color[i]``, therefore it must have the same size with ``pos``."
msgstr ""

#: ../../taichi/docs/gui.rst:115
msgid "(tuple of 2) the first end point position of line"
msgstr ""

#: ../../taichi/docs/gui.rst:116
msgid "(tuple of 2) the second end point position of line"
msgstr ""

#: ../../taichi/docs/gui.rst:117
msgid "(optional, RGB hex) the color of line"
msgstr ""

#: ../../taichi/docs/gui.rst:118
msgid "(optional, scalar) the width of line"
msgstr ""

#: ../../taichi/docs/gui.rst:120
msgid "Draw a line."
msgstr ""

#: ../../taichi/docs/gui.rst:126
msgid "(tuple of 2) the first end point position of triangle"
msgstr ""

#: ../../taichi/docs/gui.rst:127
msgid "(tuple of 2) the second end point position of triangle"
msgstr ""

#: ../../taichi/docs/gui.rst:128
msgid "(tuple of 2) the third end point position of triangle"
msgstr ""

#: ../../taichi/docs/gui.rst:129
msgid "(optional, RGB hex) the color to fill the triangle"
msgstr ""

#: ../../taichi/docs/gui.rst:131
msgid "Draw a solid triangle."
msgstr ""

#: ../../taichi/docs/gui.rst:137
msgid "(tuple of 2) the top-left point position of rectangle"
msgstr ""

#: ../../taichi/docs/gui.rst:138
msgid "(tuple of 2) the bottom-right point position of rectangle"
msgstr ""

#: ../../taichi/docs/gui.rst:139
msgid "(optional, RGB hex) the color of stroke line"
msgstr ""

#: ../../taichi/docs/gui.rst:140
msgid "(optional, scalar) the width of stroke line"
msgstr ""

#: ../../taichi/docs/gui.rst:142
msgid "Draw a hollow rectangle."
msgstr ""

#: ../../taichi/docs/gui.rst:146
msgid "Event processing"
msgstr ""

#: ../../taichi/docs/gui.rst:148
msgid ""
"Every event have a key and type. *Event key* is the key that you pressed "
"on keyboard or mouse, can be one of:"
msgstr ""

#: ../../taichi/docs/gui.rst:153
msgid ""
"ti.GUI.ESCAPE\n"
"ti.GUI.SHIFT\n"
"ti.GUI.LEFT\n"
"'a'\n"
"'b'\n"
"...\n"
"ti.GUI.LMB\n"
"ti.GUI.RMB"
msgstr ""

#: ../../taichi/docs/gui.rst:162
msgid ""
"*Event type* is the type of event, for now, there are just three type of "
"event:"
msgstr ""

#: ../../taichi/docs/gui.rst:166
msgid ""
"ti.GUI.RELEASE  # key up\n"
"ti.GUI.PRESS    # key down\n"
"ti.GUI.MOTION   # mouse moved"
msgstr ""

#: ../../taichi/docs/gui.rst:171
msgid ""
"A *event filter* is a list combined of *key*, *type* and *(type, key)* "
"tuple, e.g.:"
msgstr ""

#: ../../taichi/docs/gui.rst:173
msgid ""
"# if ESC pressed or released:\n"
"gui.get_event(ti.GUI.ESCAPE)\n"
"\n"
"# if any key is pressed:\n"
"gui.get_event(ti.GUI.PRESS)\n"
"\n"
"# if ESC pressed or SPACE released:\n"
"gui.get_event((ti.GUI.PRESS, ti.GUI.ESCAPE), (ti.GUI.RELEASE, "
"ti.GUI.SPACE))"
msgstr ""

#: ../../taichi/docs/gui.rst:187 ../../taichi/docs/gui.rst:212
#: ../../taichi/docs/gui.rst:230 ../../taichi/docs/gui.rst:250
msgid "(GUI)"
msgstr ""

#: ../../taichi/docs/gui.rst:188 ../../taichi/docs/gui.rst:213
msgid "(optional, EventFilter) filter out matched events"
msgstr ""

#: ../../taichi/docs/gui.rst:189
msgid "(bool) ``False`` if there is no pending event, vise versa"
msgstr ""

#: ../../taichi/docs/gui.rst:191
msgid "Try to pop a event from the queue, and store it in ``gui.event``."
msgstr ""

#: ../../taichi/docs/gui.rst:193 ../../taichi/docs/gui.rst:253
msgid "For example:"
msgstr ""

#: ../../taichi/docs/gui.rst:197
msgid ""
"while gui.get_event():\n"
"    print('Event key', gui.event.key)"
msgstr ""

#: ../../taichi/docs/gui.rst:201
msgid "For example, loop until ESC is pressed:"
msgstr ""

#: ../../taichi/docs/gui.rst:205
msgid ""
"gui = ti.GUI('Title', (640, 480))\n"
"while not gui.get_event(ti.GUI.ESCAPE):\n"
"    gui.set_image(img)\n"
"    gui.show()"
msgstr ""

#: ../../taichi/docs/gui.rst:214
msgid "(generator) a python generator, see below"
msgstr ""

#: ../../taichi/docs/gui.rst:216
msgid ""
"Basically the same as ``gui.get_event``, except for this one returns a "
"generator of events instead of storing into ``gui.event``:"
msgstr ""

#: ../../taichi/docs/gui.rst:220
msgid ""
"for e in gui.get_events():\n"
"    if e.key == ti.GUI.ESCAPE:\n"
"        exit()\n"
"    elif e.type == ti.GUI.SPACE:\n"
"        do_something()\n"
"    elif e.type in ['a', ti.GUI.LEFT]:\n"
"        ..."
msgstr ""

#: ../../taichi/docs/gui.rst:231
msgid "(EventKey) keys you want to detect"
msgstr ""

#: ../../taichi/docs/gui.rst:232
msgid "(bool) ``True`` if one of the keys pressed, vice versa"
msgstr ""

#: ../../taichi/docs/gui.rst:236
msgid ""
"Must be used together with ``gui.get_event``, or it won't be updated! For"
" example:"
msgstr ""

#: ../../taichi/docs/gui.rst:241
msgid ""
"while True:\n"
"    gui.get_event()  # must be called before is_pressed\n"
"    if gui.is_pressed('a', ti.GUI.LEFT):\n"
"        print('Go left!')\n"
"    elif gui.is_pressed('d', ti.GUI.RIGHT):\n"
"        print('Go right!')"
msgstr ""

#: ../../taichi/docs/gui.rst:251
msgid "(tuple of 2) current cursor position within the window"
msgstr ""

#: ../../taichi/docs/gui.rst:257
msgid "mouse_x, mouse_y = gui.get_cursor_pos()"
msgstr ""

#: ../../taichi/docs/gui.rst:261
msgid "Image I/O"
msgstr ""

#: ../../taichi/docs/gui.rst:263
msgid ""
"img = ti.imread('hello.png')\n"
"ti.imshow(img, 'Window Title')\n"
"ti.imwrite(img, 'hello2.png')"
msgstr ""

#: ../../taichi/docs/gui.rst:269
msgid "TODO: complete here"
msgstr ""

#: ../../taichi/docs/hello.rst:2
msgid "Hello, world!"
msgstr ""

#: ../../taichi/docs/hello.rst:4
msgid ""
"We introduce the Taichi programming language through a very basic "
"`fractal` example."
msgstr ""

#: ../../taichi/docs/hello.rst:6
msgid "First of all, let's install Taichi via ``pip``:"
msgstr ""

#: ../../taichi/docs/hello.rst:8
msgid ""
"# Python 3.6+ needed\n"
"python3 -m pip install taichi"
msgstr ""

#: ../../taichi/docs/hello.rst:13
msgid ""
"Now you are ready to run the Taichi code below (``python3 fractal.py``) "
"to compute a `Julia set <https://en.wikipedia.org/wiki/Julia_set>`_:"
msgstr ""

#: ../../taichi/docs/hello.rst:18
msgid ""
"# fractal.py\n"
"\n"
"import taichi as ti\n"
"\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"n = 320\n"
"pixels = ti.var(dt=ti.f32, shape=(n * 2, n))\n"
"\n"
"\n"
"@ti.func\n"
"def complex_sqr(z):\n"
"    return ti.Vector([z[0]**2 - z[1]**2, z[1] * z[0] * 2])\n"
"\n"
"\n"
"@ti.kernel\n"
"def paint(t: ti.f32):\n"
"    for i, j in pixels:  # Parallized over all pixels\n"
"        c = ti.Vector([-0.8, ti.cos(t) * 0.2])\n"
"        z = ti.Vector([i / n - 1, j / n - 0.5]) * 2\n"
"        iterations = 0\n"
"        while z.norm() < 20 and iterations < 50:\n"
"            z = complex_sqr(z) + c\n"
"            iterations += 1\n"
"        pixels[i, j] = 1 - iterations * 0.02\n"
"\n"
"\n"
"gui = ti.GUI(\"Julia Set\", res=(n * 2, n))\n"
"\n"
"for i in range(1000000):\n"
"    paint(i * 0.03)\n"
"    gui.set_image(pixels)\n"
"    gui.show()"
msgstr ""

#: ../../taichi/docs/hello.rst:54
msgid "Let's dive into this simple Taichi program."
msgstr ""

#: ../../taichi/docs/hello.rst:57
msgid "import taichi as ti"
msgstr ""

#: ../../taichi/docs/hello.rst:58
msgid ""
"Taichi is a domain-specific language (DSL) embedded in Python. To make "
"Taichi as easy to use as a Python package, we have done heavy engineering"
" with this goal in mind - letting every Python programmer write Taichi "
"codes with minimal learning effort. You can even use your favorite Python"
" package management system, Python IDEs and other Python packages in "
"conjunction with Taichi."
msgstr ""

#: ../../taichi/docs/hello.rst:64 ../../taichi/docs/overview.rst:8
msgid "Portability"
msgstr ""

#: ../../taichi/docs/hello.rst:66
msgid ""
"Taichi programs run on either CPUs or GPUs. Initialize Taichi according "
"to your hardware platform as follows:"
msgstr ""

#: ../../taichi/docs/hello.rst:68
msgid ""
"# Run on GPU, automatically detect backend\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"# Run on GPU, with the NVIDIA CUDA backend\n"
"ti.init(arch=ti.cuda)\n"
"# Run on GPU, with the OpenGL backend\n"
"ti.init(arch=ti.opengl)\n"
"# Run on GPU, with the Apple Metal backend, if you are on OS X\n"
"ti.init(arch=ti.metal)\n"
"\n"
"# Run on CPU (default)\n"
"ti.init(arch=ti.cpu)"
msgstr ""

#: ../../taichi/docs/hello.rst:84
msgid "Supported backends on different platforms:"
msgstr ""

#: ../../taichi/docs/hello.rst:87
msgid "platform"
msgstr ""

#: ../../taichi/docs/hello.rst:87
msgid "CPU"
msgstr ""

#: ../../taichi/docs/hello.rst:87
msgid "CUDA"
msgstr ""

#: ../../taichi/docs/hello.rst:89 ../../taichi/docs/legacy_installation.rst:34
msgid "Windows"
msgstr ""

#: ../../taichi/docs/hello.rst:89 ../../taichi/docs/hello.rst:91
#: ../../taichi/docs/hello.rst:93
msgid "N/A"
msgstr ""

#: ../../taichi/docs/hello.rst:91
msgid "Linux"
msgstr ""

#: ../../taichi/docs/hello.rst:93
msgid "Mac OS X"
msgstr ""

#: ../../taichi/docs/hello.rst:96
msgid "(OK: supported; N/A: not available)"
msgstr ""

#: ../../taichi/docs/hello.rst:98
msgid ""
"With ``arch=ti.gpu``, Taichi will first try to run with CUDA. If CUDA is "
"not supported on your machine, Taichi will fall back on Metal or OpenGL. "
"If no GPU backend (CUDA, Metal, or OpenGL) is supported, Taichi will fall"
" back on CPUs."
msgstr ""

#: ../../taichi/docs/hello.rst:104
msgid ""
"When used with the CUDA backend on Windows or ARM devices (e.g. NVIDIA "
"Jetson), Taichi by default allocates 1 GB GPU memory for tensor storage. "
"You can override this behavior by initializing with "
"``ti.init(arch=ti.cuda, device_memory_GB=3.4)`` to allocate ``3.4`` GB "
"GPU memory, or ``ti.init(arch=ti.cuda, device_memory_fraction=0.3)`` to "
"allocate ``30%`` of the total GPU memory."
msgstr ""

#: ../../taichi/docs/hello.rst:109
msgid ""
"On other platforms, Taichi will make use of its on-demand memory "
"allocator to adaptively allocate memory."
msgstr ""

#: ../../taichi/docs/hello.rst:112
msgid "(Sparse) tensors"
msgstr ""

#: ../../taichi/docs/hello.rst:114
msgid ""
"Taichi is a data-oriented programming language where dense or spatially-"
"sparse tensors are the first-class citizens. See :ref:`sparse` for more "
"details on sparse tensors."
msgstr ""

#: ../../taichi/docs/hello.rst:117
msgid ""
"In the code above, ``pixels = ti.var(dt=ti.f32, shape=(n * 2, n))`` "
"allocates a 2D dense tensor named ``pixels`` of size ``(640, 320)`` and "
"element data type ``ti.f32`` (i.e. ``float`` in C)."
msgstr ""

#: ../../taichi/docs/hello.rst:121
msgid "Functions and kernels"
msgstr ""

#: ../../taichi/docs/hello.rst:123
msgid ""
"Computation resides in Taichi **kernels**. Kernel arguments must be type-"
"hinted. The language used in Taichi kernels and functions looks exactly "
"like Python, yet the Taichi frontend compiler converts it into a language"
" that is **compiled, statically-typed, lexically-scoped, parallel and "
"differentiable**."
msgstr ""

#: ../../taichi/docs/hello.rst:127
msgid ""
"Taichi **functions**, which can be called by Taichi kernels and other "
"Taichi functions, should be defined with the keyword ``ti.func``."
msgstr ""

#: ../../taichi/docs/hello.rst:131
msgid ""
"**Taichi-scopes v.s. Python-scopes**: everything decorated with "
"``ti.kernel`` and ``ti.func`` is in Taichi-scope, which will be compiled "
"by the Taichi compiler. Everything else is in Python-scopes. They are "
"simply Python code."
msgstr ""

#: ../../taichi/docs/hello.rst:136
msgid ""
"Taichi kernels must be called in the Python-scope. I.e., **nested kernels"
" are not supported**. Nested functions are allowed. **Recursive functions"
" are not supported for now**."
msgstr ""

#: ../../taichi/docs/hello.rst:139
msgid "Taichi functions can only be called in Taichi-scope."
msgstr ""

#: ../../taichi/docs/hello.rst:141
msgid ""
"For those who come from the world of CUDA, ``ti.func`` corresponds to "
"``__device__`` while ``ti.kernel`` corresponds to ``__global__``."
msgstr ""

#: ../../taichi/docs/hello.rst:145
msgid "Parallel for-loops"
msgstr ""

#: ../../taichi/docs/hello.rst:146
msgid ""
"For loops at the outermost scope in a Taichi kernel is **automatically "
"parallelized**. For loops can have two forms, i.e. `range-for loops` and "
"`struct-for loops`."
msgstr ""

#: ../../taichi/docs/hello.rst:149
msgid ""
"**Range-for loops** are no different from Python for loops, except that "
"it will be parallelized when used at the outermost scope. Range-for loops"
" can be nested."
msgstr ""

#: ../../taichi/docs/hello.rst:152
msgid ""
"@ti.kernel\n"
"def fill():\n"
"    for i in range(10): # Parallelized\n"
"        x[i] += i\n"
"\n"
"        s = 0\n"
"        for j in range(5): # Serialized in each parallel thread\n"
"            s += j\n"
"\n"
"        y[i] = s\n"
"\n"
"@ti.kernel\n"
"def fill_3d():\n"
"    # Parallelized for all 3 <= i < 8, 1 <= j < 6, 0 <= k < 9\n"
"    for i, j, k in ti.ndrange((3, 8), (1, 6), 9):\n"
"        x[i, j, k] = i + j + k"
msgstr ""

#: ../../taichi/docs/hello.rst:173 ../../taichi/docs/hello.rst:199
msgid ""
"It is the loop **at the outermost scope** that gets parallelized, not the"
" outermost loop."
msgstr ""

#: ../../taichi/docs/hello.rst:175
msgid ""
"@ti.kernel\n"
"def foo():\n"
"    for i in range(10): # Parallelized :-)\n"
"        ...\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    if k > 42:\n"
"        for i in range(10): # Serial :-(\n"
"            ..."
msgstr ""

#: ../../taichi/docs/hello.rst:188
msgid ""
"**Struct-for loops** are particularly useful when iterating over (sparse)"
" tensor elements. In the code above, ``for i, j in pixels`` loops over "
"all the pixel coordinates, i.e. ``(0, 0), (0, 1), (0, 2), ... , (0, 319),"
" (1, 0), ..., (639, 319)``."
msgstr ""

#: ../../taichi/docs/hello.rst:193
msgid ""
"Struct-for is the key to :ref:`sparse` in Taichi, as it will only loop "
"over active elements in a sparse tensor. In dense tensors, all elements "
"are active."
msgstr ""

#: ../../taichi/docs/hello.rst:197
msgid "Struct-for loops must live at the outer-most scope of kernels."
msgstr ""

#: ../../taichi/docs/hello.rst:201
msgid ""
"@ti.kernel\n"
"def foo():\n"
"    for i in x:\n"
"        ...\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    # The outermost scope is a `if` statement\n"
"    if k > 42:\n"
"        for i in x: # Not allowed. Struct-fors must live in the outermost"
" scope.\n"
"            ..."
msgstr ""

#: ../../taichi/docs/hello.rst:220
msgid "``break`` **is not supported in parallel loops**:"
msgstr ""

#: ../../taichi/docs/hello.rst:222
msgid ""
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      ...\n"
"      break # Error!\n"
"\n"
"  for i in range(10):\n"
"      ...\n"
"      break # Error!\n"
"\n"
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      for j in range(10):\n"
"          ...\n"
"          break # OK!"
msgstr ""

#: ../../taichi/docs/hello.rst:243
msgid "Interacting with Python"
msgstr ""

#: ../../taichi/docs/hello.rst:245
msgid ""
"Everything outside Taichi-scopes (``ti.func`` and ``ti.kernel``) is "
"simply Python code. In Python-scopes, you can access Taichi tensor "
"elements using plain indexing syntax. For example, to access a single "
"pixel of the rendered image in Python, simply use"
msgstr ""

#: ../../taichi/docs/hello.rst:249
msgid ""
"pixels[42, 11] = 0.7\n"
"print(pixels[42, 11]) # prints 0.7"
msgstr ""

#: ../../taichi/docs/hello.rst:255
msgid ""
"You can also use your favorite Python packages (e.g. ``numpy``, "
"``pytorch``, ``matplotlib``) together with Taichi. Taichi provides helper"
" functions such as ``from_numpy`` and ``to_torch`` for tensor format "
"conversion:"
msgstr ""

#: ../../taichi/docs/hello.rst:258
msgid ""
"import numpy as np\n"
"pixels.from_numpy(np.random.rand(n * 2, n))\n"
"\n"
"import matplotlib.pyplot as plt\n"
"plt.imshow(pixels.to_numpy())\n"
"plt.show()"
msgstr ""

#: ../../taichi/docs/hello.rst:267
msgid "See :ref:`external` for more details."
msgstr ""

#: ../../taichi/docs/index.rst:4
msgid "Overview"
msgstr ""

#: ../../taichi/docs/index.rst:12
msgid "Basic Concepts"
msgstr ""

#: ../../taichi/docs/index.rst:23
msgid "API References"
msgstr ""

#: ../../taichi/docs/index.rst:33
msgid "Advanced Programming"
msgstr ""

#: ../../taichi/docs/index.rst:46
msgid "Contributing"
msgstr ""

#: ../../taichi/docs/index.rst:56
msgid "Miscellaneous"
msgstr ""

#: ../../taichi/docs/index.rst:68
msgid "Legacy"
msgstr ""

#: ../../taichi/docs/index.rst:2
msgid "The Taichi Programming Language"
msgstr ""

#: ../../taichi/docs/internal.rst:2
msgid "Internal designs (WIP)"
msgstr ""

#: ../../taichi/docs/internal.rst:6
msgid "Intermediate representation"
msgstr ""

#: ../../taichi/docs/internal.rst:7
msgid "Use ``ti.init(print_ir=True)`` to print IR on the console."
msgstr ""

#: ../../taichi/docs/internal.rst:11
msgid "Code generation"
msgstr ""

#: ../../taichi/docs/internal.rst:15
msgid "Statistics"
msgstr ""

#: ../../taichi/docs/internal.rst:17
msgid ""
"In some cases, it is helpful to gather certain quantitative information "
"about internal events during Taichi program execution. The ``Statistics``"
" class is designed for this purpose."
msgstr ""

#: ../../taichi/docs/internal.rst:20
msgid "Usage:"
msgstr ""

#: ../../taichi/docs/internal.rst:22
msgid ""
"#include \"taichi/util/statistics.h\"\n"
"\n"
"// add 1.0 to counter \"codegen_offloaded_tasks\"\n"
"taichi::stat.add(\"codegen_offloaded_tasks\");\n"
"\n"
"// add the number of statements in \"ir\" to counter "
"\"codegen_statements\"\n"
"taichi::stat.add(\"codegen_statements\", "
"irpass::analysis::count_statements(this->ir));"
msgstr ""

#: ../../taichi/docs/internal.rst:33
msgid "Note the keys are ``std::string`` and values are ``double``."
msgstr ""

#: ../../taichi/docs/internal.rst:35
msgid "To print out all statistics in Python:"
msgstr ""

#: ../../taichi/docs/internal.rst:37
msgid "ti.core.print_stat()"
msgstr ""

#: ../../taichi/docs/internal.rst:43
msgid "Why Python frontend"
msgstr ""

#: ../../taichi/docs/internal.rst:45
msgid "Embedding Taichi in ``python`` has the following advantages:"
msgstr ""

#: ../../taichi/docs/internal.rst:47
msgid "Easy to learn. Taichi has a very similar syntax to Python."
msgstr ""

#: ../../taichi/docs/internal.rst:48
msgid "Easy to run. No ahead-of-time compilation is needed."
msgstr ""

#: ../../taichi/docs/internal.rst:49
msgid "This design allows people to reuse existing python infrastructure:"
msgstr ""

#: ../../taichi/docs/internal.rst:51
msgid ""
"IDEs. A python IDE mostly works for Taichi with syntax highlighting, "
"syntax checking, and autocomplete."
msgstr ""

#: ../../taichi/docs/internal.rst:52
msgid ""
"Package manager (pip). A developed Taichi application and be easily "
"submitted to ``PyPI`` and others can easily set it up with ``pip``."
msgstr ""

#: ../../taichi/docs/internal.rst:53
msgid ""
"Existing packages. Interacting with other python components (e.g. "
"``matplotlib`` and ``numpy``) is just trivial."
msgstr ""

#: ../../taichi/docs/internal.rst:55
msgid ""
"The built-in AST manipulation tools in ``python`` allow us to do magical "
"things, as long as the kernel body can be parsed by the Python parser."
msgstr ""

#: ../../taichi/docs/internal.rst:57
msgid "However, this design has drawbacks as well:"
msgstr ""

#: ../../taichi/docs/internal.rst:59
msgid ""
"Taichi kernels must parse-able by Python parsers. This means Taichi "
"syntax cannot go beyond Python syntax."
msgstr ""

#: ../../taichi/docs/internal.rst:61
msgid ""
"For example, indexing is always needed when accessing elements in Taichi "
"tensors, even if the tensor is 0D. Use ``x[None] = 123`` to set the value"
" in ``x`` if ``x`` is 0D. This is because ``x = 123`` will set ``x`` "
"itself (instead of its containing value) to be the constant ``123`` in "
"python syntax, and, unfortunately, we cannot modify this behavior."
msgstr ""

#: ../../taichi/docs/internal.rst:63
msgid ""
"Python has relatively low performance. This can cause a performance issue"
" when initializing large Taichi tensors with pure python scripts. A "
"Taichi kernel should be used to initialize a huge tensor."
msgstr ""

#: ../../taichi/docs/layout.rst:4
msgid "Advanced dense layouts"
msgstr ""

#: ../../taichi/docs/layout.rst:6
msgid ""
"Tensors (:ref:`scalar_tensor`) can be *placed* in a specific shape and "
"*layout*. Defining a proper layout can be critical to performance, "
"especially for memory-bound applications. A carefully designed data "
"layout can significantly improve cache/TLB-hit rates and cacheline "
"utilization. Although when performance is not the first priority, you "
"probably don't have to worry about it."
msgstr ""

#: ../../taichi/docs/layout.rst:9
msgid ""
"In Taichi, the layout is defined in a recursive manner. See :ref:`snode` "
"for more details about how this works. We suggest starting with the "
"default layout specification (simply by specifying ``shape`` when "
"creating tensors using ``ti.var/Vector/Matrix``), and then migrate to "
"more advanced layouts using the ``ti.root.X`` syntax if necessary."
msgstr ""

#: ../../taichi/docs/layout.rst:12
msgid ""
"Taichi decouples algorithms from data layouts, and the Taichi compiler "
"automatically optimizes data accesses on a specific data layout. These "
"Taichi features allow programmers to quickly experiment with different "
"data layouts and figure out the most efficient one on a specific task and"
" computer architecture."
msgstr ""

#: ../../taichi/docs/layout.rst:16
msgid "From ``shape`` to ``ti.root.X``"
msgstr ""

#: ../../taichi/docs/layout.rst:18
msgid "For example, this declares a 0-D tensor:"
msgstr ""

#: ../../taichi/docs/layout.rst:20
msgid ""
"x = ti.var(ti.f32)\n"
"ti.root.place(x)\n"
"# is equivalent to:\n"
"x = ti.var(ti.f32, shape=())"
msgstr ""

#: ../../taichi/docs/layout.rst:27
msgid "This declares a 1D tensor of size ``3``:"
msgstr ""

#: ../../taichi/docs/layout.rst:29
msgid ""
"x = ti.var(ti.f32)\n"
"ti.root.dense(ti.i, 3).place(x)\n"
"# is equivalent to:\n"
"x = ti.var(ti.f32, shape=3)"
msgstr ""

#: ../../taichi/docs/layout.rst:36
msgid "This declares a 2D tensor of shape ``(3, 4)``:"
msgstr ""

#: ../../taichi/docs/layout.rst:38
msgid ""
"x = ti.var(ti.f32)\n"
"ti.root.dense(ti.ij, (3, 4)).place(x)\n"
"# is equivalent to:\n"
"x = ti.var(ti.f32, shape=(3, 4))"
msgstr ""

#: ../../taichi/docs/layout.rst:45
msgid ""
"You may wonder, why not simply specify the ``shape`` of the tensor? Why "
"bother using the more complex version? Good question, let go forward and "
"figure out why."
msgstr ""

#: ../../taichi/docs/layout.rst:50
msgid "Row-major versus column-major"
msgstr ""

#: ../../taichi/docs/layout.rst:52
msgid "Let's start with the simplest layout."
msgstr ""

#: ../../taichi/docs/layout.rst:54
msgid ""
"Since address spaces are linear in modern computers, for 1D Taichi "
"tensors, the address of the ``i``-th element is simply ``i``."
msgstr ""

#: ../../taichi/docs/layout.rst:56
msgid ""
"To store a multi-dimensional tensor, however, it has to be flattened, in "
"order to fit into the 1D address space. For example, to store a 2D tensor"
" of size ``(3, 2)``, there are two ways to do this:"
msgstr ""

#: ../../taichi/docs/layout.rst:59
msgid "The address of ``(i, j)``-th is ``base + i * 2 + j`` (row-major)."
msgstr ""

#: ../../taichi/docs/layout.rst:61
msgid "The address of ``(i, j)``-th is ``base + j * 3 + i`` (column-major)."
msgstr ""

#: ../../taichi/docs/layout.rst:63
msgid "To specify which layout to use in Taichi:"
msgstr ""

#: ../../taichi/docs/layout.rst:65
msgid ""
"ti.root.dense(ti.i, 3).dense(ti.j, 2).place(x)    # row-major (default)\n"
"ti.root.dense(ti.j, 2).dense(ti.i, 3).place(y)    # column-major"
msgstr ""

#: ../../taichi/docs/layout.rst:70
msgid ""
"Both ``x`` and ``y`` have the same shape of ``(3, 2)``, and they can be "
"accessed in the same manner, where ``0 <= i < 3 && 0 <= j < 2``. They can"
" be accessed in the same manner: ``x[i, j]`` and ``y[i, j]``. However, "
"they have a very different memory layouts:"
msgstr ""

#: ../../taichi/docs/layout.rst:73
msgid ""
"#     address low ........................... address high\n"
"# x:  x[0,0]   x[0,1]   x[0,2] | x[1,0]   x[1,1]   x[1,2]\n"
"# y:  y[0,0]   y[1,0] | y[0,1]   y[1,1] | y[0,2]   y[1,2]"
msgstr ""

#: ../../taichi/docs/layout.rst:79
msgid ""
"See? ``x`` first increases the first index (i.e. row-major), while ``y`` "
"first increases the second index (i.e. column-major)."
msgstr ""

#: ../../taichi/docs/layout.rst:83
msgid "For those people from C/C++, here's what they looks like:"
msgstr ""

#: ../../taichi/docs/layout.rst:85
msgid ""
"int x[3][2];  // row-major\n"
"int y[2][3];  // column-major\n"
"\n"
"for (int i = 0; i < 3; i++) {\n"
"    for (int j = 0; j < 2; j++) {\n"
"        do_something ( x[i][j] );\n"
"        do_something ( y[j][i] );\n"
"    }\n"
"}"
msgstr ""

#: ../../taichi/docs/layout.rst:99
msgid "Array of Structures (AoS), Structure of Arrays (SoA)"
msgstr ""

#: ../../taichi/docs/layout.rst:101
msgid "Tensors of same size can be placed together."
msgstr ""

#: ../../taichi/docs/layout.rst:103
msgid ""
"For example, this places two 1D tensors of size ``3`` (array of "
"structure, AoS):"
msgstr ""

#: ../../taichi/docs/layout.rst:105
msgid "ti.root.dense(ti.i, 3).place(x, y)"
msgstr ""

#: ../../taichi/docs/layout.rst:109
msgid "Their memory layout:"
msgstr ""

#: ../../taichi/docs/layout.rst:111
msgid ""
"#  address low ............. address high\n"
"#  x[0]   y[0] | x[1]  y[1] | x[2]   y[2]"
msgstr ""

#: ../../taichi/docs/layout.rst:116
msgid ""
"In contrast, this places two tensor placed separately (structure of "
"array, SoA):"
msgstr ""

#: ../../taichi/docs/layout.rst:118
msgid ""
"ti.root.dense(ti.i, 3).place(x)\n"
"ti.root.dense(ti.i, 3).place(y)"
msgstr ""

#: ../../taichi/docs/layout.rst:123
msgid "Now, their memory layout:"
msgstr ""

#: ../../taichi/docs/layout.rst:125
msgid ""
"#  address low ............. address high\n"
"#  x[0]  x[1]   x[2] | y[0]   y[1]   y[2]"
msgstr ""

#: ../../taichi/docs/layout.rst:131
msgid ""
"Normally, you don't have to worry about the performance nuances between "
"different layouts, and should just define the simplest layout as a start."
" However, locality sometimes have a significant impact on the "
"performance, especially when the tensor is huge."
msgstr ""

#: ../../taichi/docs/layout.rst:134
msgid ""
"**To improve spatial locality of memory accesses (i.e. cache hit rate / "
"cacheline utilization), it's sometimes helpful to place the data elements"
" within relatively close storage locations if they are often accessed "
"together.** Take a simple 1D wave equation solver for example:"
msgstr ""

#: ../../taichi/docs/layout.rst:137
msgid ""
"N = 200000\n"
"pos = ti.var(ti.f32)\n"
"vel = ti.var(ti.f32)\n"
"ti.root.dense(ti.i, N).place(pos)\n"
"ti.root.dense(ti.i, N).place(vel)\n"
"\n"
"@ti.kernel\n"
"def step():\n"
"    pos[i] += vel[i] * dt\n"
"    vel[i] += -k * pos[i] * dt"
msgstr ""

#: ../../taichi/docs/layout.rst:151
msgid ""
"Here, we placed ``pos`` and ``vel`` seperately. So the distance in "
"address space between ``pos[i]`` and ``vel[i]`` is ``200000``. This will "
"result in a poor spatial locality and lots of cache-misses, which damages"
" the performance. A better placement is to place them together:"
msgstr ""

#: ../../taichi/docs/layout.rst:154
msgid "ti.root.dense(ti.i, N).place(pos, vel)"
msgstr ""

#: ../../taichi/docs/layout.rst:158
msgid ""
"Then ``vel[i]`` is placed right next to ``pos[i]``, this can increase the"
" cache-hit rate and therefore increase the performance."
msgstr ""

#: ../../taichi/docs/layout.rst:162
msgid "Flat layouts versus hierarchical layouts"
msgstr ""

#: ../../taichi/docs/layout.rst:164
msgid ""
"By default, when allocating a ``ti.var``, it follows the simplest data "
"layout."
msgstr ""

#: ../../taichi/docs/layout.rst:166
msgid ""
"val = ti.var(ti.f32, shape=(32, 64, 128))\n"
"# C++ equivalent: float val[32][64][128]"
msgstr ""

#: ../../taichi/docs/layout.rst:171
msgid ""
"However, at times this data layout can be suboptimal for certain types of"
" computer graphics tasks. For example, ``val[i, j, k]`` and ``val[i + 1, "
"j, k]`` are very far away (``32 KB``) from each other, and leads to poor "
"access locality under certain computation tasks. Specifically, in tasks "
"such as texture trilinear interpolation, the two elements are not even "
"within the same ``4KB`` pages, creating a huge cache/TLB pressure."
msgstr ""

#: ../../taichi/docs/layout.rst:174
msgid "A better layout might be"
msgstr ""

#: ../../taichi/docs/layout.rst:176
msgid ""
"val = ti.var(ti.f32)\n"
"ti.root.dense(ti.ijk, (8, 16, 32)).dense(ti.ijk, (4, 4, 4)).place(val)"
msgstr ""

#: ../../taichi/docs/layout.rst:181
msgid ""
"This organizes ``val`` in ``4x4x4`` blocks, so that with high probability"
" ``val[i, j, k]`` and its neighbours are close to each other (i.e., in "
"the same cacheline or memory page)."
msgstr ""

#: ../../taichi/docs/layout.rst:185
msgid "Struct-fors on advanced dense data layouts"
msgstr ""

#: ../../taichi/docs/layout.rst:187
msgid ""
"Struct-fors on nested dense data structures will automatically follow "
"their data order in memory. For example, if 2D scalar tensor ``A`` is "
"stored in row-major order,"
msgstr ""

#: ../../taichi/docs/layout.rst:189
msgid ""
"for i, j in A:\n"
"  A[i, j] += 1"
msgstr ""

#: ../../taichi/docs/layout.rst:194
msgid ""
"will iterate over elements of ``A`` following row-major order. If ``A`` "
"is column-major, then the iteration follows the column-major order."
msgstr ""

#: ../../taichi/docs/layout.rst:196
msgid ""
"If ``A`` is hierarchical, it will be iterated level by level. This "
"maximizes the memory bandwidth utilization in most cases."
msgstr ""

#: ../../taichi/docs/layout.rst:198
msgid ""
"Struct-for loops on sparse tensors follow the same philosophy, and will "
"be discussed further in :ref:`sparse`."
msgstr ""

#: ../../taichi/docs/layout.rst:202
msgid "Examples"
msgstr ""

#: ../../taichi/docs/layout.rst:204
msgid "2D matrix, row-major"
msgstr ""

#: ../../taichi/docs/layout.rst:206
msgid ""
"A = ti.var(ti.f32)\n"
"ti.root.dense(ti.ij, (256, 256)).place(A)"
msgstr ""

#: ../../taichi/docs/layout.rst:211
msgid "2D matrix, column-major"
msgstr ""

#: ../../taichi/docs/layout.rst:213
msgid ""
"A = ti.var(ti.f32)\n"
"ti.root.dense(ti.ji, (256, 256)).place(A) # Note ti.ji instead of ti.ij"
msgstr ""

#: ../../taichi/docs/layout.rst:218
msgid "`8x8` blocked 2D array of size `1024x1024`"
msgstr ""

#: ../../taichi/docs/layout.rst:220
msgid ""
"density = ti.var(ti.f32)\n"
"ti.root.dense(ti.ij, (128, 128)).dense(ti.ij, (8, 8)).place(density)"
msgstr ""

#: ../../taichi/docs/layout.rst:226
msgid "3D Particle positions and velocities, AoS"
msgstr ""

#: ../../taichi/docs/layout.rst:228
msgid ""
"pos = ti.Vector(3, dt=ti.f32)\n"
"vel = ti.Vector(3, dt=ti.f32)\n"
"ti.root.dense(ti.i, 1024).place(pos, vel)\n"
"# equivalent to\n"
"ti.root.dense(ti.i, 1024).place(pos(0), pos(1), pos(2), vel(0), vel(1), "
"vel(2))"
msgstr ""

#: ../../taichi/docs/layout.rst:236
msgid "3D Particle positions and velocities, SoA"
msgstr ""

#: ../../taichi/docs/layout.rst:238
msgid ""
"pos = ti.Vector(3, dt=ti.f32)\n"
"vel = ti.Vector(3, dt=ti.f32)\n"
"for i in range(3):\n"
"  ti.root.dense(ti.i, 1024).place(pos(i))\n"
"for i in range(3):\n"
"  ti.root.dense(ti.i, 1024).place(vel(i))"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:2
msgid "Installing the legacy Taichi Library"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:5
msgid ""
"This is NOT for installing the Taichi programming language. Unless you "
"are building a legacy project based on the `legacy Taichi library "
"<https://github.com/yuanming-hu/taichi/tree/legacy>`_ (e.g. `taichi_mpm "
"<https://github.com/yuanming-hu/taichi_mpm>`_ and `spgrid_topo_opt "
"<https://github.com/yuanming-hu/spgrid_topo_opt>`_) you should always "
"install Taichi using ``pip``."
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:11
msgid ""
"If you are working on the Taichi compiler and need to build from scratch,"
" see :ref:`dev_install`."
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:13
msgid "Supported platforms:"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:15
msgid "Ubuntu (gcc 5+)"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:16
msgid "Mac OS X (gcc 5+, clang 4.0+)"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:17
msgid "Windows (Microsoft Visual Studio 2017)"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:19
msgid "Make sure you have ``python 3.5`` +."
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:23
msgid "Ubuntu, Arch Linux, and Mac OS X"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:25
msgid ""
"wget https://raw.githubusercontent.com/yuanming-"
"hu/taichi/legacy/install.py\n"
"python3 install.py"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:31
msgid ""
"Note, if python complains that a package is missing, simply rerun "
"install.py and the package should be loaded."
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:35
msgid ""
"Download and execute `this script <https://raw.githubusercontent.com"
"/yuanming-hu/taichi/legacy/install.py>`_ with python3."
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:37
msgid ""
"Additional environment variables: (assuming taichi is installed in "
"``DIR/taichi``) Set ``TAICHI_REPO_DIR`` as  ``DIR/taichi`` (e.g. "
"``E:/repos/taichi``). Add ``%TAICHI_REPO_DIR%/python`` to ``PYTHONPATH``,"
" ``DIR/taichi/bin`` (e.g. ``E:/repos/taichi/bin``) to ``PATH``. Restart "
"cmd or PowerShell, and you should be able to run command ``ti``."
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:43
msgid "Build with Double Precision (64 bit) Float Point"
msgstr ""

#: ../../taichi/docs/legacy_installation.rst:44
msgid ""
"export TC_USE_DOUBLE=1\n"
"ti build"
msgstr ""

#: ../../taichi/docs/matrix.rst:4
msgid "Matrices"
msgstr ""

#: ../../taichi/docs/matrix.rst:6
msgid ""
"``ti.Matrix`` is for small matrices (e.g. `3x3`) only. If you have "
"`64x64` matrices, you should consider using a 2D tensor of scalars."
msgstr ""

#: ../../taichi/docs/matrix.rst:7
msgid ""
"``ti.Vector`` is the same as ``ti.Matrix``, except that it has only one "
"column."
msgstr ""

#: ../../taichi/docs/matrix.rst:8
msgid "Differentiate element-wise product ``*`` and matrix product ``@``."
msgstr ""

#: ../../taichi/docs/matrix.rst:9
msgid ""
"``ti.Vector(n, dt=ti.f32)`` or ``ti.Matrix(n, m, dt=ti.f32)`` to create "
"tensors of vectors/matrices."
msgstr ""

#: ../../taichi/docs/matrix.rst:10
msgid "``ti.transposed(A)`` or simply ``A.T()``"
msgstr ""

#: ../../taichi/docs/matrix.rst:11
msgid "``ti.inverse(A)``"
msgstr ""

#: ../../taichi/docs/matrix.rst:12
msgid "``ti.Matrix.abs(A)``"
msgstr ""

#: ../../taichi/docs/matrix.rst:13
msgid "``ti.tr(A)``"
msgstr ""

#: ../../taichi/docs/matrix.rst:14
msgid "``ti.determinant(A, type)``"
msgstr ""

#: ../../taichi/docs/matrix.rst:15
msgid ""
"``ti.cross(a, b)``, where ``a`` and ``b`` are 3D vectors (i.e. ``3x1`` "
"matrices)"
msgstr ""

#: ../../taichi/docs/matrix.rst:16
msgid "``A.cast(type)``"
msgstr ""

#: ../../taichi/docs/matrix.rst:17
msgid "``R, S = ti.polar_decompose(A, ti.f32)``"
msgstr ""

#: ../../taichi/docs/matrix.rst:18
msgid ""
"``U, sigma, V = ti.svd(A, ti.f32)`` (Note that ``sigma`` is a ``3x3`` "
"diagonal matrix)"
msgstr ""

#: ../../taichi/docs/matrix.rst:20
msgid "TODO: doc here better like Vector. WIP"
msgstr ""

#: ../../taichi/docs/matrix.rst:22
msgid "A matrix in Taichi can have two forms:"
msgstr ""

#: ../../taichi/docs/matrix.rst:24
msgid ""
"as a temporary local variable. An ``n by m`` matrix consists of ``n * m``"
" scalar values."
msgstr ""

#: ../../taichi/docs/matrix.rst:25
msgid ""
"as a an element of a global tensor. In this case, the tensor is an "
"N-dimensional array of ``n by m`` matrices."
msgstr ""

#: ../../taichi/docs/matrix.rst:28 ../../taichi/docs/scalar_tensor.rst:8
#: ../../taichi/docs/vector.rst:14
msgid "Declaration"
msgstr ""

#: ../../taichi/docs/matrix.rst:31
msgid "As global tensors of matrices"
msgstr ""

#: ../../taichi/docs/matrix.rst:35
msgid "(scalar) the number of rows in the matrix"
msgstr ""

#: ../../taichi/docs/matrix.rst:36
msgid "(scalar) the number of columns in the matrix"
msgstr ""

#: ../../taichi/docs/matrix.rst:37 ../../taichi/docs/vector.rst:22
msgid "(DataType) data type of the components"
msgstr ""

#: ../../taichi/docs/matrix.rst:38 ../../taichi/docs/vector.rst:23
msgid "(scalar or tuple) shape the tensor of vectors, see :ref:`tensor`"
msgstr ""

#: ../../taichi/docs/matrix.rst:40
msgid "For example, this creates a 5x4 tensor of 3x3 matrices: ::"
msgstr ""

#: ../../taichi/docs/matrix.rst:43
msgid ""
"# Python-scope\n"
"a = ti.Matrix(3, 3, dt=ti.f32, shape=(5, 4))"
msgstr ""

#: ../../taichi/docs/matrix.rst:48
msgid ""
"In Python-scope, ``ti.var`` declares :ref:`scalar_tensor`, while "
"``ti.Matrix`` declares tensors of matrices."
msgstr ""

#: ../../taichi/docs/matrix.rst:52 ../../taichi/docs/matrix.rst:143
#: ../../taichi/docs/vector.rst:37 ../../taichi/docs/vector.rst:84
msgid "As a temporary local variable"
msgstr ""

#: ../../taichi/docs/matrix.rst:56 ../../taichi/docs/vector.rst:41
msgid "(scalar) the first component of the vector"
msgstr ""

#: ../../taichi/docs/matrix.rst:57 ../../taichi/docs/vector.rst:42
msgid "(scalar) the second component of the vector"
msgstr ""

#: ../../taichi/docs/matrix.rst:59
msgid "For example, this creates a 3x1 matrix with components (2, 3, 4): ::"
msgstr ""

#: ../../taichi/docs/matrix.rst:62
msgid ""
"# Taichi-scope\n"
"a = ti.Matrix([2, 3, 4])"
msgstr ""

#: ../../taichi/docs/matrix.rst:67
msgid "this is equivalent to ti.Vector([x, y, ...])"
msgstr ""

#: ../../taichi/docs/matrix.rst:72
msgid "(scalar) the first component of the first row"
msgstr ""

#: ../../taichi/docs/matrix.rst:73
msgid "(scalar) the second component of the first row"
msgstr ""

#: ../../taichi/docs/matrix.rst:74
msgid "(scalar) the first component of the second row"
msgstr ""

#: ../../taichi/docs/matrix.rst:75
msgid "(scalar) the second component of the second row"
msgstr ""

#: ../../taichi/docs/matrix.rst:77
msgid ""
"For example, this creates a 2x2 matrix with components (2, 3) in the "
"first row and (4, 5) in the second row: ::"
msgstr ""

#: ../../taichi/docs/matrix.rst:80
msgid ""
"# Taichi-scope\n"
"a = ti.Matrix([[2, 3], [4, 5])"
msgstr ""

#: ../../taichi/docs/matrix.rst:87
msgid "(vector) vector of elements forming first row (or column)"
msgstr ""

#: ../../taichi/docs/matrix.rst:88
msgid "(vector) vector of elements forming second row (or column)"
msgstr ""

#: ../../taichi/docs/matrix.rst:89
msgid "(vector) vector of elements forming third row (or column)"
msgstr ""

#: ../../taichi/docs/matrix.rst:91
msgid ""
"For example, this creates a 3x3 matrix by concactinating vectors into "
"rows (or columns): ::"
msgstr ""

#: ../../taichi/docs/matrix.rst:94
msgid ""
"# Taichi-scope\n"
"v0 = ti.Vector([1.0, 2.0, 3.0])\n"
"v1 = ti.Vector([4.0, 5.0, 6.0])\n"
"v2 = ti.Vector([7.0, 8.0, 9.0])\n"
"\n"
"# to specify data in rows\n"
"a = ti.Matrix(rows=[v0, v1, v2])\n"
"\n"
"# to specify data in columns instead\n"
"a = ti.Matrix(cols=[v0, v1, v2])\n"
"\n"
"# lists can be used instead of vectors\n"
"a = ti.Matrix(rows=[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])"
msgstr ""

#: ../../taichi/docs/matrix.rst:110 ../../taichi/docs/vector.rst:52
msgid "Accessing components"
msgstr ""

#: ../../taichi/docs/matrix.rst:113 ../../taichi/docs/vector.rst:17
#: ../../taichi/docs/vector.rst:55
msgid "As global tensors of vectors"
msgstr ""

#: ../../taichi/docs/matrix.rst:116
msgid "(tensor of matrices) the tensor of matrices"
msgstr ""

#: ../../taichi/docs/matrix.rst:117 ../../taichi/docs/vector.rst:59
msgid "(scalar) index of the first tensor dimension"
msgstr ""

#: ../../taichi/docs/matrix.rst:118 ../../taichi/docs/vector.rst:60
msgid "(scalar) index of the second tensor dimension"
msgstr ""

#: ../../taichi/docs/matrix.rst:119 ../../taichi/docs/matrix.rst:148
msgid "(scalar) row index of the matrix"
msgstr ""

#: ../../taichi/docs/matrix.rst:120 ../../taichi/docs/matrix.rst:149
msgid "(scalar) column index of the matrix"
msgstr ""

#: ../../taichi/docs/matrix.rst:122
msgid "This extracts the first element in matrix ``a[6, 3]``: ::"
msgstr ""

#: ../../taichi/docs/matrix.rst:125
msgid ""
"x = a[6, 3][0, 0]\n"
"\n"
"# or\n"
"mat = a[6, 3]\n"
"x = mat[0, 0]"
msgstr ""

#: ../../taichi/docs/matrix.rst:133
msgid ""
"**Always** use two pair of square brackets to access scalar elements from"
" tensors of matrices."
msgstr ""

#: ../../taichi/docs/matrix.rst:135
msgid ""
"The indices in the first pair of brackets locate the matrix inside the "
"tensor of matrices;"
msgstr ""

#: ../../taichi/docs/matrix.rst:136
msgid ""
"The indices in the second pair of brackets locate the scalar element "
"inside the matrix."
msgstr ""

#: ../../taichi/docs/matrix.rst:138
msgid ""
"For 0-D tensors of matrices, indices in the first pair of brackets should"
" be ``[None]``."
msgstr ""

#: ../../taichi/docs/matrix.rst:147
msgid "(Matrix) the matrix"
msgstr ""

#: ../../taichi/docs/matrix.rst:151
msgid ""
"For example, this extracts the element in row 0 column 1 of matrix ``a``:"
" ::"
msgstr ""

#: ../../taichi/docs/matrix.rst:154
msgid "x = a[0, 1]"
msgstr ""

#: ../../taichi/docs/matrix.rst:156
msgid "This sets the element in row 1 column 3 of ``a`` to 4: ::"
msgstr ""

#: ../../taichi/docs/matrix.rst:159
msgid "a[1, 3] = 4"
msgstr ""

#: ../../taichi/docs/matrix.rst:162 ../../taichi/docs/vector.rst:104
msgid "Methods"
msgstr ""

#: ../../taichi/docs/meta.rst:4 ../../taichi/docs/overview.rst:11
msgid "Metaprogramming"
msgstr ""

#: ../../taichi/docs/meta.rst:6
msgid "Taichi provides metaprogramming infrastructures. Metaprogramming can"
msgstr ""

#: ../../taichi/docs/meta.rst:8
msgid ""
"Unify the development of dimensionality-dependent code, such as 2D/3D "
"physical simulations"
msgstr ""

#: ../../taichi/docs/meta.rst:9
msgid "Improve run-time performance by from run-time costs to compile time"
msgstr ""

#: ../../taichi/docs/meta.rst:10
msgid "Simplify the development of Taichi standard library"
msgstr ""

#: ../../taichi/docs/meta.rst:12
msgid ""
"Taichi kernels are *lazily instantiated* and a lot of computation can "
"happen at *compile-time*. Every kernel in Taichi is a template kernel, "
"even if it has no template arguments."
msgstr ""

#: ../../taichi/docs/meta.rst:18
msgid "Template metaprogramming"
msgstr ""

#: ../../taichi/docs/meta.rst:20
msgid ""
"@ti.kernel\n"
"def copy(x: ti.template(), y: ti.template()):\n"
"    for i in x:\n"
"        y[i] = x[i]"
msgstr ""

#: ../../taichi/docs/meta.rst:29
msgid "Dimensionality-independent programming using grouped indices"
msgstr ""

#: ../../taichi/docs/meta.rst:31
msgid ""
"@ti.kernel\n"
"def copy(x: ti.template(), y: ti.template()):\n"
"    for I in ti.grouped(y):\n"
"        x[I] = y[I]\n"
"\n"
"@ti.kernel\n"
"def array_op(x: ti.template(), y: ti.template()):\n"
"    # If tensor x is 2D\n"
"    for I in ti.grouped(x): # I is a vector of size x.dim() and data type"
" i32\n"
"        y[I + ti.Vector([0, 1])] = I[0] + I[1]\n"
"    # is equivalent to\n"
"    for i, j in x:\n"
"        y[i, j + 1] = i + j"
msgstr ""

#: ../../taichi/docs/meta.rst:48
msgid "Tensor size reflection"
msgstr ""

#: ../../taichi/docs/meta.rst:50
msgid ""
"Sometimes it will be useful to get the dimensionality (``tensor.dim()``) "
"and shape (``tensor.shape()``) of tensors. These functions can be used in"
" both Taichi kernels and python scripts."
msgstr ""

#: ../../taichi/docs/meta.rst:53
msgid ""
"@ti.func\n"
"def print_tensor_size(x: ti.template()):\n"
"  print(x.dim())\n"
"  for i in ti.static(range(x.dim())):\n"
"    print(x.shape()[i])"
msgstr ""

#: ../../taichi/docs/meta.rst:61
msgid "For sparse tensors, the full domain shape will be returned."
msgstr ""

#: ../../taichi/docs/meta.rst:64
msgid "Compile-time evaluations"
msgstr ""

#: ../../taichi/docs/meta.rst:65
msgid ""
"Using compile-time evaluation will allow certain computation to happen "
"when kernels are instantiated. Such computation has no overhead at "
"runtime."
msgstr ""

#: ../../taichi/docs/meta.rst:68
msgid ""
"Use ``ti.static`` for compile-time branching (for those who come from "
"C++17, this is `if constexpr "
"<https://en.cppreference.com/w/cpp/language/if>`_.)"
msgstr ""

#: ../../taichi/docs/meta.rst:70
msgid ""
"enable_projection = True\n"
"\n"
"@ti.kernel\n"
"def static():\n"
"  if ti.static(enable_projection): # No runtime overhead\n"
"    x[0] = 1"
msgstr ""

#: ../../taichi/docs/meta.rst:80
msgid "Use ``ti.static`` for forced loop unrolling"
msgstr ""

#: ../../taichi/docs/meta.rst:82
msgid ""
"@ti.kernel\n"
"def g2p(f: ti.i32):\n"
"for p in range(0, n_particles):\n"
" base = ti.cast(x[f, p] * inv_dx - 0.5, ti.i32)\n"
" fx = x[f, p] * inv_dx - ti.cast(base, real)\n"
" w = [0.5 * ti.sqr(1.5 - fx), 0.75 - ti.sqr(fx - 1.0),\n"
"      0.5 * ti.sqr(fx - 0.5)]\n"
" new_v = ti.Vector([0.0, 0.0])\n"
" new_C = ti.Matrix([[0.0, 0.0], [0.0, 0.0]])\n"
"\n"
" # Unrolled 9 iterations for higher performance\n"
" for i in ti.static(range(3)):\n"
"   for j in ti.static(range(3)):\n"
"     dpos = ti.cast(ti.Vector([i, j]), real) - fx\n"
"     g_v = grid_v_out[base(0) + i, base(1) + j]\n"
"     weight = w[i](0) * w[j](1)\n"
"     new_v += weight * g_v\n"
"     new_C += 4 * weight * ti.outer_product(g_v, dpos) * inv_dx\n"
"\n"
" v[f + 1, p] = new_v\n"
" x[f + 1, p] = x[f, p] + dt * v[f + 1, p]\n"
" C[f + 1, p] = new_C"
msgstr ""

#: ../../taichi/docs/meta.rst:109
msgid "When to use for loops with ``ti.static``"
msgstr ""

#: ../../taichi/docs/meta.rst:111
msgid "There are several reasons why ``ti.static`` for loops should be used."
msgstr ""

#: ../../taichi/docs/meta.rst:113
msgid "Loop unrolling for performance."
msgstr ""

#: ../../taichi/docs/meta.rst:114
msgid ""
"Loop over vector/matrix elements. Indices into Taichi matrices must be a "
"compile-time constant. Indexing into taichi tensors can be run-time "
"variables. For example, if ``x`` is a 1-D tensor of 3D vector, accessed "
"as ``x[tensor_index][matrix index]``. The first index can be variable, "
"yet the second must be a constant."
msgstr ""

#: ../../taichi/docs/meta.rst:116
msgid "For example, code for resetting this tensor of vectors should be"
msgstr ""

#: ../../taichi/docs/meta.rst:118
msgid ""
"@ti.kernel\n"
"def reset():\n"
"  for i in x:\n"
"    for j in ti.static(range(3)):\n"
"      # The inner loop must be unrolled since j is a vector index instead"
"\n"
"      # of a global tensor index.\n"
"      x[i][j] = 0"
msgstr ""

#: ../../taichi/docs/odop.rst:2
msgid "Objective data-oriented programming"
msgstr ""

#: ../../taichi/docs/odop.rst:4
msgid ""
"Taichi is a `data-oriented <https://en.wikipedia.org/wiki/Data-"
"oriented_design>`_ programming (DOP) language. However, simple DOP makes "
"modularization hard."
msgstr ""

#: ../../taichi/docs/odop.rst:6
msgid ""
"To allow modularized code, Taichi borrow some concepts from object-"
"oriented programming (OOP)."
msgstr ""

#: ../../taichi/docs/odop.rst:8
msgid ""
"For convenience, let's call the hybrid scheme **objective data-oriented "
"programming** (ODOP)."
msgstr ""

#: ../../taichi/docs/odop.rst:10
msgid "TODO: More documentation here."
msgstr ""

#: ../../taichi/docs/odop.rst:12
msgid "A brief example:"
msgstr ""

#: ../../taichi/docs/odop.rst:14
msgid ""
"import taichi as ti\n"
"\n"
"ti.init()\n"
"\n"
"@ti.data_oriented\n"
"class Array2D:\n"
"  def __init__(self, n, m, increment):\n"
"    self.n = n\n"
"    self.m = m\n"
"    self.val = ti.var(ti.f32)\n"
"    self.total = ti.var(ti.f32)\n"
"    self.increment = increment\n"
"    ti.root.dense(ti.ij, (self.n, self.m)).place(self.val)\n"
"    ti.root.place(self.total)\n"
"\n"
"  @staticmethod\n"
"  @ti.func\n"
"  def clamp(x):  # Clamp to [0, 1)\n"
"      return max(0, min(1 - 1e-6, x))\n"
"\n"
"  @ti.kernel\n"
"  def inc(self):\n"
"    for i, j in self.val:\n"
"      ti.atomic_add(self.val[i, j], self.increment)\n"
"\n"
"  @ti.kernel\n"
"  def inc2(self, increment: ti.i32):\n"
"    for i, j in self.val:\n"
"      ti.atomic_add(self.val[i, j], increment)\n"
"\n"
"  @ti.kernel\n"
"  def reduce(self):\n"
"    for i, j in self.val:\n"
"      ti.atomic_add(self.total, self.val[i, j] * 4)\n"
"\n"
"arr = Array2D(128, 128, 3)\n"
"\n"
"double_total = ti.var(ti.f32, shape=())\n"
"\n"
"ti.root.lazy_grad()\n"
"\n"
"arr.inc()\n"
"arr.inc.grad()\n"
"assert arr.val[3, 4] == 3\n"
"arr.inc2(4)\n"
"assert arr.val[3, 4] == 7\n"
"\n"
"with ti.Tape(loss=arr.total):\n"
"  arr.reduce()\n"
"\n"
"for i in range(arr.n):\n"
"  for j in range(arr.m):\n"
"    assert arr.val.grad[i, j] == 4\n"
"\n"
"@ti.kernel\n"
"def double():\n"
"  double_total[None] = 2 * arr.total\n"
"\n"
"with ti.Tape(loss=double_total):\n"
"  arr.reduce()\n"
"  double()\n"
"\n"
"for i in range(arr.n):\n"
"  for j in range(arr.m):\n"
"    assert arr.val.grad[i, j] == 8"
msgstr ""

#: ../../taichi/docs/overview.rst:2
msgid "Why new programming language"
msgstr ""

#: ../../taichi/docs/overview.rst:4
msgid ""
"Taichi is a high-performance programming language for computer graphics "
"applications. The design goals are"
msgstr ""

#: ../../taichi/docs/overview.rst:6
msgid "Productivity"
msgstr ""

#: ../../taichi/docs/overview.rst:7
msgid "Performance"
msgstr ""

#: ../../taichi/docs/overview.rst:9
msgid "Spatially sparse computation"
msgstr ""

#: ../../taichi/docs/overview.rst:14
msgid "Design decisions"
msgstr ""

#: ../../taichi/docs/overview.rst:16
msgid "Decouple computation from data structures"
msgstr ""

#: ../../taichi/docs/overview.rst:17
msgid "Domain-specific compiler optimizations"
msgstr ""

#: ../../taichi/docs/overview.rst:18
msgid "Megakernels"
msgstr ""

#: ../../taichi/docs/overview.rst:19
msgid "Two-scale automatic differentiation"
msgstr ""

#: ../../taichi/docs/overview.rst:20
msgid "Embedding in Python"
msgstr ""

#: ../../taichi/docs/performance.rst:2
msgid "Performance tips"
msgstr ""

#: ../../taichi/docs/performance.rst:4
msgid ""
"Avoid synchronization: when using GPU, an asynchronous task queue will be"
" maintained. Whenever reading/writing global tensors, a synchronization "
"will be invoked, which leads to idle cycles on CPU/GPU."
msgstr ""

#: ../../taichi/docs/performance.rst:6
msgid ""
"Make Use of GPU Shared Memory and L1-d$ ``ti.cache_l1(x)`` will enforce "
"data loads related to ``x`` cached in L1-cache. ``ti.cache_shared(x)`` "
"will allocate shared memory. TODO: add examples"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:4 ../../taichi/docs/tensor_matrix.rst:12
msgid "Tensors of scalars"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:12
msgid "(DataType) type of the tensor element"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:13
msgid "(optional, scalar or tuple) the shape of tensor"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:15
msgid ""
"For example, this creates a *dense* tensor with four ``int32`` as "
"elements: ::"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:18
msgid "x = ti.var(ti.i32, shape=4)"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:20
msgid "This creates a 4x3 *dense* tensor with ``float32`` elements: ::"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:23
msgid "x = ti.var(ti.f32, shape=(4, 3))"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:25
msgid ""
"If shape is ``()`` (empty tuple), then a 0-D tensor (scalar) is created: "
"::"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:28
msgid "x = ti.var(ti.f32, shape=())"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:30
msgid "Then access it by passing ``None`` as index: ::"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:33
msgid "x[None] = 2"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:35
msgid ""
"If shape is **not provided** or ``None``, the user must manually "
"``place`` it afterwards: ::"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:38
msgid ""
"x = ti.var(ti.f32)\n"
"ti.root.dense(ti.ij, (4, 3)).place(x)\n"
"# equivalent to: x = ti.var(ti.f32, shape=(4, 3))"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:44
msgid ""
"Not providing ``shape`` allows you to *place* the tensor in a layout "
"other than the default *dense*, see :ref:`layout` for more details."
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:49
msgid ""
"All variables should be created and placed before any kernel invocation "
"or any of them accessed from python-scope. For example:"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:51
msgid ""
"x = ti.var(ti.f32)\n"
"x[None] = 1 # ERROR: x not placed!"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:56
msgid ""
"x = ti.var(ti.f32, shape=())\n"
"@ti.kernel\n"
"def func():\n"
"    x[None] = 1\n"
"\n"
"func()\n"
"y = ti.var(ti.f32, shape=())\n"
"# ERROR: cannot create tensor after kernel invocation!"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:67
msgid ""
"x = ti.var(ti.f32, shape=())\n"
"x[None] = 1\n"
"y = ti.var(ti.f32, shape=())\n"
"# ERROR: cannot create tensor after any tensor accesses from the Python-"
"scope!"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:76
msgid "Attribute"
msgstr ""

#: ../../taichi/docs/scalar_tensor.rst:78
msgid "TODO: WIP"
msgstr ""

#: ../../taichi/docs/snode.rst:4
msgid "Structural nodes (SNodes)"
msgstr ""

#: ../../taichi/docs/snode.rst:6
msgid ""
"After writing the computation code, the user needs to specify the "
"internal data structure hierarchy. Specifying a data structure includes "
"choices at both the macro level, dictating how the data structure "
"components nest with each other and the way they represent sparsity, and "
"the micro level, dictating how data are grouped together (e.g. structure "
"of arrays vs. array of structures). Our language provides *structural "
"nodes (SNodes)* to compose the hierarchy and particular properties. These"
" constructs and their semantics are listed below:"
msgstr ""

#: ../../taichi/docs/snode.rst:9
msgid "dense: A fixed-length contiguous array."
msgstr ""

#: ../../taichi/docs/snode.rst:11
msgid ""
"bitmasked: This is similar to dense, but it also uses a mask to maintain "
"sparsity information, one bit per child."
msgstr ""

#: ../../taichi/docs/snode.rst:13
msgid ""
"pointer: Store pointers instead of the whole structure to save memory and"
" maintain sparsity."
msgstr ""

#: ../../taichi/docs/snode.rst:15
msgid ""
"dynamic: Variable-length array, with a predefined maximum length. It "
"serves the role of ``std::vector`` in C++ or ``list`` in Python, and can "
"be used to maintain objects (e.g. particles) contained in a block."
msgstr ""

#: ../../taichi/docs/snode.rst:18
msgid ""
"See :ref:`layout` for more details. ``ti.root`` is the root node of the "
"data structure."
msgstr ""

#: ../../taichi/docs/snode.rst:22
msgid "(SNode) where to place"
msgstr ""

#: ../../taichi/docs/snode.rst:23
msgid "(tensor) tensor(s) to be placed"
msgstr ""

#: ../../taichi/docs/snode.rst:24
msgid "(SNode) the ``snode`` itself"
msgstr ""

#: ../../taichi/docs/snode.rst:26
msgid "The following code places two 0-D tensors named ``x`` and ``y``:"
msgstr ""

#: ../../taichi/docs/snode.rst:30
msgid ""
"x = ti.var(dt=ti.i32)\n"
"y = ti.var(dt=ti.f32)\n"
"ti.root.place(x, y)"
msgstr ""

#: ../../taichi/docs/snode.rst:36 ../../taichi/docs/snode.rst:63
msgid "the tensor"
msgstr ""

#: ../../taichi/docs/snode.rst:37
msgid "(tuple of integers) the shape of tensor"
msgstr ""

#: ../../taichi/docs/snode.rst:39
msgid "For example,"
msgstr ""

#: ../../taichi/docs/snode.rst:43
msgid ""
"ti.root.dense(ti.ijk, (3, 5, 4)).place(x)\n"
"x.shape() # returns (3, 5, 4)"
msgstr ""

#: ../../taichi/docs/snode.rst:48 ../../taichi/docs/snode.rst:75
msgid "(SNode)"
msgstr ""

#: ../../taichi/docs/snode.rst:49
msgid "axis (0 for ``i`` and 1 for ``j``)"
msgstr ""

#: ../../taichi/docs/snode.rst:50
msgid "(scalar) the size of tensor alone that axis"
msgstr ""

#: ../../taichi/docs/snode.rst:52
msgid "Equivalent to ``tensor.shape()[i]``."
msgstr ""

#: ../../taichi/docs/snode.rst:56
msgid ""
"ti.root.dense(ti.ijk, (3, 5, 4)).place(x)\n"
"x.snode().get_shape(0)  # 3\n"
"x.snode().get_shape(1)  # 5\n"
"x.snode().get_shape(2)  # 4"
msgstr ""

#: ../../taichi/docs/snode.rst:64
msgid "(scalar) the dimensionality of the tensor"
msgstr ""

#: ../../taichi/docs/snode.rst:66
msgid "Equivalent to ``len(tensor.shape())``."
msgstr ""

#: ../../taichi/docs/snode.rst:70
msgid ""
"ti.root.dense(ti.ijk, (8, 9, 10)).place(x)\n"
"x.dim()  # 3"
msgstr ""

#: ../../taichi/docs/snode.rst:76
msgid "(SNode) the parent node of ``snode``"
msgstr ""

#: ../../taichi/docs/snode.rst:80
msgid ""
"blk1 = ti.root.dense(ti.i, 8)\n"
"blk2 = blk1.dense(ti.j, 4)\n"
"blk3 = blk2.bitmasked(ti.k, 6)\n"
"blk1.parent()  # ti.root\n"
"blk2.parent()  # blk1\n"
"blk3.parent()  # blk2"
msgstr ""

#: ../../taichi/docs/snode.rst:87
msgid "TODO: add tensor.parent(), and add see also ref here"
msgstr ""

#: ../../taichi/docs/snode.rst:91
msgid "Node types"
msgstr ""

#: ../../taichi/docs/snode.rst:96 ../../taichi/docs/snode.rst:133
msgid "(SNode) parent node where the child is derived from"
msgstr ""

#: ../../taichi/docs/snode.rst:97
msgid "(Index or Indices) indices used for this node"
msgstr ""

#: ../../taichi/docs/snode.rst:98
msgid "(scalar or tuple) shape the tensor of vectors"
msgstr ""

#: ../../taichi/docs/snode.rst:99 ../../taichi/docs/snode.rst:137
msgid "(SNode) the derived child node"
msgstr ""

#: ../../taichi/docs/snode.rst:101
msgid "The following code places a 1-D tensor of size ``3``:"
msgstr ""

#: ../../taichi/docs/snode.rst:105
msgid ""
"x = ti.var(dt=ti.i32)\n"
"ti.root.dense(ti.i, 3).place(x)"
msgstr ""

#: ../../taichi/docs/snode.rst:108
msgid "The following code places a 2-D tensor of shape ``(3, 4)``:"
msgstr ""

#: ../../taichi/docs/snode.rst:112
msgid ""
"x = ti.var(dt=ti.i32)\n"
"ti.root.dense(ti.ij, (3, 4)).place(x)"
msgstr ""

#: ../../taichi/docs/snode.rst:117
msgid ""
"If ``shape`` is a scalar and there are multiple indices, then ``shape`` "
"will be automatically expanded to fit the number of indices. For example,"
msgstr ""

#: ../../taichi/docs/snode.rst:122
msgid "snode.dense(ti.ijk, 3)"
msgstr ""

#: ../../taichi/docs/snode.rst:124
msgid "is equivalent to"
msgstr ""

#: ../../taichi/docs/snode.rst:128
msgid "snode.dense(ti.ijk, (3, 3, 3))"
msgstr ""

#: ../../taichi/docs/snode.rst:134
msgid "(Index) the ``dynamic`` node indices"
msgstr ""

#: ../../taichi/docs/snode.rst:135
msgid "(scalar) the maximum size of the dynamic node"
msgstr ""

#: ../../taichi/docs/snode.rst:136
msgid ""
"(optional, scalar) the number of elements in each dynamic memory "
"allocation chunk"
msgstr ""

#: ../../taichi/docs/snode.rst:139
msgid ""
"``dynamic`` nodes acts like ``std::vector`` in C++ or ``list`` in Python."
" Taichi's dynamic memory allocation system allocates its memory on the "
"fly."
msgstr ""

#: ../../taichi/docs/snode.rst:142
msgid "The following places a 1-D dynamic tensor of maximum size ``16``:"
msgstr ""

#: ../../taichi/docs/snode.rst:146
msgid "ti.root.dynamic(ti.i, 16).place(x)"
msgstr ""

#: ../../taichi/docs/snode.rst:154
msgid "TODO: add descriptions here"
msgstr ""

#: ../../taichi/docs/snode.rst:157
msgid "Working with ``dynamic`` SNodes"
msgstr ""

#: ../../taichi/docs/snode.rst:161 ../../taichi/docs/snode.rst:168
msgid "(SNode, dynamic)"
msgstr ""

#: ../../taichi/docs/snode.rst:162 ../../taichi/docs/snode.rst:169
msgid "(scalar or tuple of scalars) the ``dynamic`` node indices"
msgstr ""

#: ../../taichi/docs/snode.rst:163
msgid "(scalar) the current size of the dynamic node"
msgstr ""

#: ../../taichi/docs/snode.rst:170
msgid "(depends on SNode data type) value to store"
msgstr ""

#: ../../taichi/docs/snode.rst:171
msgid "(``int32``) the size of the dynamic node, before appending"
msgstr ""

#: ../../taichi/docs/snode.rst:173
msgid "Inserts ``val`` into the ``dynamic`` node with indices ``indices``."
msgstr ""

#: ../../taichi/docs/snode.rst:177
msgid "Taichi tensors like powers of two"
msgstr ""

#: ../../taichi/docs/snode.rst:179
msgid ""
"Non-power-of-two tensor dimensions are promoted into powers of two and "
"thus these tensors will occupy more virtual address space. For example, a"
" (dense) tensor of size ``(18, 65)`` will be materialized as ``(32, "
"128)``."
msgstr ""

#: ../../taichi/docs/snode.rst:184
msgid "Indices"
msgstr ""

#: ../../taichi/docs/snode.rst:194
msgid "(TODO)"
msgstr ""

#: ../../taichi/docs/sparse.rst:4
msgid "Sparse computation (WIP)"
msgstr ""

#: ../../taichi/docs/sparse.rst:8
msgid ""
"The Taichi compiler backend is under migration from source-to-source "
"compilation to LLVM for compilation speed and portability. Sparse "
"computation with the new LLVM backend is not yet fully implemented on "
"multithreaded CPUs and GPUs."
msgstr ""

#: ../../taichi/docs/sparse.rst:11
msgid ""
"If you are interested in sparse computation in Taichi, please read our "
"`paper <http://taichi.graphics/wp-"
"content/uploads/2019/09/taichi_lang.pdf>`_, watch the `introduction video"
" <https://www.youtube.com/watch?v=wKw8LMF3Djo>`_, or check out the "
"SIGGRAPH Asia 2019 `slides <http://taichi.graphics/wp-"
"content/uploads/2019/12/taichi_slides.pdf>`_."
msgstr ""

#: ../../taichi/docs/sparse.rst:14
msgid ""
"The legacy source-to-source backend (commit ``dc162e11``) provides full "
"sparse computation functionality. However, since little engineering has "
"been done to make that commit portable (i.e. easy to compile on different"
" platforms), we suggest waiting until the LLVM version of sparse "
"computation is fully implemented."
msgstr ""

#: ../../taichi/docs/sparse.rst:17
msgid ""
"Sparse computation functionalities with the new LLVM backend will be back"
" online by the end of December 2019."
msgstr ""

#: ../../taichi/docs/syntax.rst:2
msgid "Syntax"
msgstr ""

#: ../../taichi/docs/syntax.rst:5
msgid "Kernels"
msgstr ""

#: ../../taichi/docs/syntax.rst:7
msgid ""
"Kernel arguments must be type-hinted. Kernels can have at most 8 "
"parameters, e.g.,"
msgstr ""

#: ../../taichi/docs/syntax.rst:9
msgid ""
"@ti.kernel\n"
"def print_xy(x: ti.i32, y: ti.f32):\n"
"    print(x + y)"
msgstr ""

#: ../../taichi/docs/syntax.rst:16
msgid ""
"A kernel can have a **scalar** return value. If a kernel has a return "
"value, it must be type-hinted. The return value will be automatically "
"cast into the hinted type. e.g.,"
msgstr ""

#: ../../taichi/docs/syntax.rst:19
msgid ""
"@ti.kernel\n"
"def add_xy(x: ti.f32, y: ti.f32) -> ti.i32:\n"
"    return x + y  # same as: ti.cast(x + y, ti.i32)\n"
"\n"
"res = add_xy(2.3, 1.1)\n"
"print(res)  # 3, since return type is ti.i32"
msgstr ""

#: ../../taichi/docs/syntax.rst:31
msgid ""
"For now, we only support one scalar as return value. Returning "
"``ti.Matrix`` or ``ti.Vector`` is not supported. Python-style tuple "
"return is not supported either. For example:"
msgstr ""

#: ../../taichi/docs/syntax.rst:33
msgid ""
"@ti.kernel\n"
"def bad_kernel() -> ti.Matrix:\n"
"    return ti.Matrix([[1, 0], [0, 1]])  # Error\n"
"\n"
"@ti.kernel\n"
"def bad_kernel() -> (ti.i32, ti.f32):\n"
"    x = 1\n"
"    y = 0.5\n"
"    return x, y  # Error"
msgstr ""

#: ../../taichi/docs/syntax.rst:46
msgid ""
"We also support **template arguments** (see "
":ref:`template_metaprogramming`) and **external array arguments** (see "
":ref:`external`) in Taichi kernels."
msgstr ""

#: ../../taichi/docs/syntax.rst:50
msgid ""
"When using differentiable programming, there are a few more constraints "
"on kernel structures. See the **Kernel Simplicity Rule** in "
":ref:`differentiable`."
msgstr ""

#: ../../taichi/docs/syntax.rst:52
msgid ""
"Also, please do not use kernel return values in differentiable "
"programming, since the return value will not be tracked by automatic "
"differentiation. Instead, store the result into a global variable (e.g. "
"``loss[None]``)."
msgstr ""

#: ../../taichi/docs/syntax.rst:55
msgid "Functions"
msgstr ""

#: ../../taichi/docs/syntax.rst:57
msgid ""
"Use ``@ti.func`` to decorate your Taichi functions. These functions are "
"callable only in `Taichi`-scope. Do not call them in `Python`-scopes."
msgstr ""

#: ../../taichi/docs/syntax.rst:59
msgid ""
"@ti.func\n"
"def laplacian(t, i, j):\n"
"    return inv_dx2 * (\n"
"        -4 * p[t, i, j] + p[t, i, j - 1] + p[t, i, j + 1] + p[t, i + 1, "
"j] +\n"
"        p[t, i - 1, j])\n"
"\n"
"@ti.kernel\n"
"def fdtd(t: ti.i32):\n"
"    for i in range(n_grid): # Parallelized\n"
"        for j in range(n_grid): # Serial loops in each parallel threads\n"
"            laplacian_p = laplacian(t - 2, i, j)\n"
"            laplacian_q = laplacian(t - 1, i, j)\n"
"            p[t, i, j] = 2 * p[t - 1, i, j] + (\n"
"                c * c * dt * dt + c * alpha * dt) * laplacian_q - p[\n"
"                           t - 2, i, j] - c * alpha * dt * laplacian_p"
msgstr ""

#: ../../taichi/docs/syntax.rst:80
msgid ""
"Functions with multiple ``return`` statements are not supported for now. "
"Use a **local** variable to store the results, so that you end up with "
"only one ``return`` statement:"
msgstr ""

#: ../../taichi/docs/syntax.rst:82
msgid ""
"# Bad function - two return statements\n"
"@ti.func\n"
"def safe_sqrt(x):\n"
"  if x >= 0:\n"
"    return ti.sqrt(x)\n"
"  else:\n"
"    return 0.0\n"
"\n"
"# Good function - single return statement\n"
"@ti.func\n"
"def safe_sqrt(x):\n"
"  rst = 0.0\n"
"  if x >= 0:\n"
"    rst = ti.sqrt(x)\n"
"  else:\n"
"    rst = 0.0\n"
"  return rst"
msgstr ""

#: ../../taichi/docs/syntax.rst:104
msgid ""
"Currently, all functions are force-inlined. Therefore, no recursion is "
"allowed."
msgstr ""

#: ../../taichi/docs/syntax.rst:108
msgid "Function arguments are passed by value."
msgstr ""

#: ../../taichi/docs/syntax.rst:113
msgid "Scalar arithmetics"
msgstr ""

#: ../../taichi/docs/syntax.rst:114
msgid "Supported scalar functions:"
msgstr ""

#: ../../taichi/docs/syntax.rst:140
msgid ""
"Python 3 distinguishes ``/`` (true division) and ``//`` (floor division)."
" For example, ``1.0 / 2.0 = 0.5``, ``1 / 2 = 0.5``, ``1 // 2 = 0``, ``4.2"
" // 2 = 2``. Taichi follows this design:"
msgstr ""

#: ../../taichi/docs/syntax.rst:143
msgid ""
"**true divisions** on integral types will first cast their operands to "
"the default float point type."
msgstr ""

#: ../../taichi/docs/syntax.rst:144
msgid ""
"**floor divisions** on float-point types will first cast their operands "
"to the default integer type."
msgstr ""

#: ../../taichi/docs/syntax.rst:146
msgid ""
"To avoid such implicit casting, you can manually cast your operands to "
"desired types, using ``ti.cast``. See :ref:`default_precisions` for more "
"details on default numerical types."
msgstr ""

#: ../../taichi/docs/syntax.rst:151
msgid ""
"When these scalar functions are applied on :ref:`matrix` and "
":ref:`vector`, they are applied in an element-wise manner. For example:"
msgstr ""

#: ../../taichi/docs/syntax.rst:154
msgid ""
"B = ti.Matrix([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n"
"\n"
"A = ti.sin(B)\n"
"# is equivalent to\n"
"for i in ti.static(range(2)):\n"
"    for j in ti.static(range(3)):\n"
"        A[i, j] = ti.sin(B[i, j])"
msgstr ""

#: ../../taichi/docs/syntax.rst:166
msgid "Debugging"
msgstr ""

#: ../../taichi/docs/syntax.rst:168
msgid ""
"Debug your program with ``print(x)``. For example, if ``x`` is ``23``, "
"then it prints"
msgstr ""

#: ../../taichi/docs/syntax.rst:170
msgid "[debug] x = 23"
msgstr ""

#: ../../taichi/docs/syntax.rst:174
msgid "in the console."
msgstr ""

#: ../../taichi/docs/syntax.rst:178
msgid ""
"This is not the same as the ``print`` in Python-scope. For now ``print`` "
"in Taichi only takes **scalar numbers** as input. Strings, vectors and "
"matrices are not supported. Please use ``print(v[0]); print(v[1])`` if "
"you want to print a vector."
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:2
msgid "Syntax sugars"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:5
msgid "Aliases"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:7
msgid ""
"Creating aliases for global variables and functions with cumbersome names"
" can sometimes improve readability. In Taichi, this can be done by "
"assigning kernel and function local variables with ``ti.static()``, which"
" forces Taichi to use standard python pointer assignment."
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:9
msgid "For example, consider the simple kernel:"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:11
msgid ""
"@ti.kernel\n"
"def my_kernel():\n"
"  for i, j in tensor_a:\n"
"    tensor_b[i, j] = some_function(tensor_a[i, j])"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:18
msgid "The tensors and function be aliased to new names with ``ti.static``:"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:20
msgid ""
"@ti.kernel\n"
"def my_kernel():\n"
"  a, b, fun = ti.static(tensor_a, tensor_b, some_function)\n"
"  for i,j in a:\n"
"    b[i,j] = fun(a[i,j])"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:30
msgid ""
"Aliases can also be created for class members and methods, which can help"
" prevent cluttering objective data-oriented programming code with "
"``self``."
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:32
msgid ""
"For example, consider class kernel to compute the 2-D laplacian of some "
"tensor:"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:34
msgid ""
"@ti.kernel\n"
"def compute_laplacian(self):\n"
"  for i, j in a:\n"
"    self.b[i, j] = (self.a[i + 1,j] - 2.0*self.a[i, j] + self.a[i-1, "
"j])/(self.dx**2) \\\n"
"                + (self.a[i,j + 1] - 2.0*self.a[i, j] + self.a[i, "
"j-1])/(self.dy**2)"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:42
msgid "Using ``ti.static()``, it can be simplified to:"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:44
msgid ""
"@ti.kernel\n"
"def compute_laplacian(self):\n"
"  a,b,dx,dy = ti.static(self.a,self.b,self.dx,self.dy)\n"
"  for i,j in a:\n"
"    b[i,j] = (a[i+1, j] - 2.0*a[i, j] + a[i-1, j])/(dx**2) \\\n"
"           + (a[i, j+1] - 2.0*a[i, j] + a[i, j-1])/(dy**2)"
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:55
msgid ""
"``ti.static`` can also be used in combination with ``if`` (compile-time "
"branching) and ``for`` (compile-time unrolling). See :ref:`meta` for more"
" details."
msgstr ""

#: ../../taichi/docs/syntax_sugars.rst:57
msgid ""
"Here, we are using it for *compile-time const values*, i.e. the "
"**tensor/function handles** are constants at compile time."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:4
msgid "Tensors and matrices"
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:6
msgid ""
"Tensors are global variables provided by Taichi. Tensors can be either "
"sparse or dense. An element of a tensor can be either a scalar or a "
"vector/matrix."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:9
msgid ""
"Although mathematically matrices are treated as 2D tensors, in Taichi, "
"**tensor** and **matrix** are two completely different things. Matrices "
"can be used as tensor elements, so you have tensors of matrices."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:13
msgid "Every global variable is an N-dimensional tensor."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:14
msgid "Global `scalars` are treated as 0-D tensors of scalars."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:15
msgid ""
"Tensors are accessed using indices, e.g. ``x[i, j, k]`` if ``x`` is a "
"scalar 3D tensor. For a 0-D tensor, access it as ``x[None]``."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:16
msgid ""
"Even when accessing 0-D tensor ``x``, use ``x[None] = 0`` instead of ``x "
"= 0``. Please always use indexing to access entries in tensors."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:17
msgid "Tensor values are initially zero."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:18
msgid "Sparse tensors are initially inactive."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:19
msgid "See :ref:`scalar_tensor` for more details."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:23
msgid "Tensors of matrices"
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:24
msgid ""
"Suppose you have a ``128 x 64`` global grid ``A``, each node containing a"
" ``3 x 2`` matrices. In this case you need to allocate a ``128 x 64`` "
"tensor of ``3 x 2`` matrix, using the statement ``A = ti.Matrix(3, 2, "
"dt=ti.f32, shape=(128, 64))``."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:26
msgid ""
"If you want to get the matrix of grid node ``i, j``, please use ``mat = "
"A[i, j]``. ``mat`` is simply a ``3 x 2`` matrix"
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:27
msgid ""
"To get the element on the first row and second column of that matrix, use"
" ``mat[0, 1]`` or ``A[i, j][0, 1]``."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:28
msgid ""
"As you may have noticed, there are two indexing operators ``[]``, the "
"first is for tensor indexing, the second for matrix indexing."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:29
msgid ""
"For a tensor ``F`` of element ``ti.Matrix``, make sure you first index "
"the tensor dimensions, and then the matrix dimensions: ``F[i, j, k][0, "
"2]``. (Assuming ``F`` is a 3D tensor with ``ti.Matrix`` of size ``3x3`` "
"as elements)"
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:30
msgid "``ti.Vector`` is simply an alias of ``ti.Matrix``."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:31
msgid "See :ref:`matrix` for more on matrices."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:35
msgid "Matrix size"
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:36
msgid ""
"For performance reasons matrix operations will be unrolled, therefore we "
"suggest using only small matrices. For example, ``2x1``, ``3x3``, ``4x4``"
" matrices are fine, yet ``32x6`` is probably too big as a matrix size."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:41
msgid ""
"Due to the unrolling mechanisms, operating on large matrices (e.g. "
"``32x128``) can lead to long compilation time and low performance."
msgstr ""

#: ../../taichi/docs/tensor_matrix.rst:43
msgid ""
"If you have a dimension that is too large (e.g. ``64``), it's better to "
"declare a tensor of size ``64``. E.g., instead of declaring "
"``ti.Matrix(64, 32, dt=ti.f32, shape=(3, 2))``, declare ``ti.Matrix(3, 2,"
" dt=ti.f32, shape=(64, 32))``. Try to put large dimensions to tensors "
"instead of matrices."
msgstr ""

#: ../../taichi/docs/type.rst:2
msgid "Type system"
msgstr ""

#: ../../taichi/docs/type.rst:5
msgid "Supported types"
msgstr ""

#: ../../taichi/docs/type.rst:6
msgid "Currently, supported basic types in Taichi are"
msgstr ""

#: ../../taichi/docs/type.rst:8
msgid "int8 ``ti.i8``"
msgstr ""

#: ../../taichi/docs/type.rst:9
msgid "int16 ``ti.i16``"
msgstr ""

#: ../../taichi/docs/type.rst:10
msgid "int32 ``ti.i32``"
msgstr ""

#: ../../taichi/docs/type.rst:11
msgid "int64 ``ti.i64``"
msgstr ""

#: ../../taichi/docs/type.rst:12
msgid "uint8 ``ti.u8``"
msgstr ""

#: ../../taichi/docs/type.rst:13
msgid "uint16 ``ti.u16``"
msgstr ""

#: ../../taichi/docs/type.rst:14
msgid "uint32 ``ti.u32``"
msgstr ""

#: ../../taichi/docs/type.rst:15
msgid "uint64 ``ti.u64``"
msgstr ""

#: ../../taichi/docs/type.rst:16
msgid "float32 ``ti.f32``"
msgstr ""

#: ../../taichi/docs/type.rst:17
msgid "float64 ``ti.f64``"
msgstr ""

#: ../../taichi/docs/type.rst:20
msgid "Supported types on each backends:"
msgstr ""

#: ../../taichi/docs/type.rst:25
msgid "i8"
msgstr ""

#: ../../taichi/docs/type.rst:27
msgid "i16"
msgstr ""

#: ../../taichi/docs/type.rst:29
msgid "i32"
msgstr ""

#: ../../taichi/docs/type.rst:31
msgid "i64"
msgstr ""

#: ../../taichi/docs/type.rst:33
msgid "u8"
msgstr ""

#: ../../taichi/docs/type.rst:35
msgid "u16"
msgstr ""

#: ../../taichi/docs/type.rst:37
msgid "u32"
msgstr ""

#: ../../taichi/docs/type.rst:39
msgid "u64"
msgstr ""

#: ../../taichi/docs/type.rst:41
msgid "f32"
msgstr ""

#: ../../taichi/docs/type.rst:43
msgid "f64"
msgstr ""

#: ../../taichi/docs/type.rst:46
msgid "(OK: supported, EXT: require extension, MISS: not supported)"
msgstr ""

#: ../../taichi/docs/type.rst:49
msgid "Boolean types are represented using ``ti.i32``."
msgstr ""

#: ../../taichi/docs/type.rst:51
msgid ""
"Binary operations on different types will give you a promoted type, "
"following the C programming language, e.g."
msgstr ""

#: ../../taichi/docs/type.rst:53
msgid "``i32 + f32 = f32``"
msgstr ""

#: ../../taichi/docs/type.rst:54
msgid "``f32 + f64 = f64``"
msgstr ""

#: ../../taichi/docs/type.rst:55
msgid "``i32 + i64 = i64``"
msgstr ""

#: ../../taichi/docs/type.rst:61
msgid "Default precisions"
msgstr ""

#: ../../taichi/docs/type.rst:63
msgid ""
"By default, numerical literals have 32-bit precisions. For example, "
"``42`` has type ``ti.i32`` and ``3.14`` has type ``ti.f32``. Default "
"integer and float-point precisions (``default_ip`` and ``default_fp``) "
"can be specified when initializing Taichi:"
msgstr ""

#: ../../taichi/docs/type.rst:67
msgid ""
"ti.init(..., default_fp=ti.f32)\n"
"ti.init(..., default_fp=ti.f64)\n"
"\n"
"ti.init(..., default_ip=ti.i32)\n"
"ti.init(..., default_ip=ti.i64)"
msgstr ""

#: ../../taichi/docs/type.rst:77
msgid "Type casts"
msgstr ""

#: ../../taichi/docs/type.rst:79
msgid "Use ``ti.cast`` to cast scalar values."
msgstr ""

#: ../../taichi/docs/type.rst:81
msgid ""
"a = 1.4\n"
"b = ti.cast(a, ti.i32)\n"
"c = ti.cast(b, ti.f32)\n"
"\n"
"# Equivalently, use ``int()`` and ``float()``\n"
"#   to converting to default float-point/integer types\n"
"b = int(a)\n"
"c = float(b)\n"
"\n"
"# Element-wise casts in matrices\n"
"mat = ti.Matrix([[3.0, 0.0], [0.3, 0.1]])\n"
"mat_int = mat.cast(int)\n"
"mat_int2 = mat.cast(ti.i32)"
msgstr ""

#: ../../taichi/docs/type.rst:97
msgid ""
"Use ``ti.bit_cast`` to bit-cast a value into another data type. The "
"underlying bits will be preserved in this cast. The new type must have "
"the same width as the the old type. For example, bit-casting ``i32`` to "
"``f64`` is not allowed. Use this operation with caution."
msgstr ""

#: ../../taichi/docs/utilities.rst:2
msgid "Utilities"
msgstr ""

#: ../../taichi/docs/utilities.rst:5
msgid "Logging"
msgstr ""

#: ../../taichi/docs/utilities.rst:7
msgid ""
"'''\n"
"level can be {}\n"
"    ti.TRACE\n"
"    ti.DEBUG\n"
"    ti.INFO\n"
"    ti.WARN\n"
"    ti.ERR\n"
"    ti.CRITICAL\n"
"'''\n"
"ti.set_logging_level(level)"
msgstr ""

#: ../../taichi/docs/utilities.rst:20
msgid ""
"The default logging level is ``ti.INFO``. You can also override default "
"logging level by setting the environment variable like "
"``TI_LOG_LEVEL=warn``."
msgstr ""

#: ../../taichi/docs/utilities.rst:27
msgid "Benchmarking and Regression Tests"
msgstr ""

#: ../../taichi/docs/utilities.rst:29
msgid ""
"Run ``ti benchmark`` to run tests in benchmark mode. This will record the"
" performance of ``ti test``, and save it in ``benchmarks/output``."
msgstr ""

#: ../../taichi/docs/utilities.rst:31
msgid ""
"Run ``ti regression`` to show the difference between previous result in "
"``benchmarks/baseline``. And you can see if the performance is increasing"
" or decreasing after your commits. This is really helpful when your work "
"is related to IR optimizations."
msgstr ""

#: ../../taichi/docs/utilities.rst:33
msgid ""
"Run ``ti baseline`` to save the benchmark result to "
"``benchmarks/baseline`` for furture comparsion, this may be executed on "
"performance related PRs, before they are merged into master."
msgstr ""

#: ../../taichi/docs/utilities.rst:35
msgid ""
"For example, this is part of the output by ``ti regression`` after "
"enabling constant folding optimization pass:"
msgstr ""

#: ../../taichi/docs/utilities.rst:37
msgid ""
"linalg__________________polar_decomp______________________________\n"
"codegen_offloaded_tasks                       37 ->    39    +5.4%\n"
"codegen_statements                          3179 ->  3162    -0.5%\n"
"codegen_kernel_statements                   2819 ->  2788    -1.1%\n"
"codegen_evaluator_statements                   0 ->    14    +inf%\n"
"\n"
"linalg__________________init_matrix_from_vectors__________________\n"
"codegen_offloaded_tasks                       37 ->    39    +5.4%\n"
"codegen_statements                          3180 ->  3163    -0.5%\n"
"codegen_kernel_statements                   2820 ->  2789    -1.1%\n"
"codegen_evaluator_statements                   0 ->    14    +inf%"
msgstr ""

#: ../../taichi/docs/utilities.rst:53
msgid ""
"Currently ``ti benchmark`` only support benchmarking number-of-"
"statements, no time benchmarking is included since it depends on hardware"
" performance and therefore hard to compare if the baseline is from "
"another machine. We are to purchase a fixed-performance machine as a time"
" benchmark server at some point. Discussion at: https://github.com"
"/taichi-dev/taichi/issue/948"
msgstr ""

#: ../../taichi/docs/utilities.rst:58
msgid ""
"The suggested workflow for **the PR author** to run the regression tests "
"is:"
msgstr ""

#: ../../taichi/docs/utilities.rst:60
msgid "When a performance related PR is ready, checkout that PR locally."
msgstr ""

#: ../../taichi/docs/utilities.rst:62
msgid "Run ``ti benchmark && ti regression`` to obtain the result."
msgstr ""

#: ../../taichi/docs/utilities.rst:64
msgid "Decide wheater to approve or request change, depends on the result."
msgstr ""

#: ../../taichi/docs/utilities.rst:66 ../../taichi/docs/utilities.rst:77
msgid ""
"Right before merge, run ``ti baseline`` to save the benchmark result as "
"new baseline."
msgstr ""

#: ../../taichi/docs/utilities.rst:69
msgid ""
"**Reviewers** can also ask the PR author to run and upload the test "
"result, if they consider the PR performance sensitive. If the reviewers "
"would like to run the regression tests themselves, the suggested workflow"
" is:"
msgstr ""

#: ../../taichi/docs/utilities.rst:71
msgid ""
"When a stage of work is done, run ``ti benchmark && ti regression`` to "
"obtain result."
msgstr ""

#: ../../taichi/docs/utilities.rst:73
msgid ""
"When ready for review, post the latest result in PR comments, wait for "
"the reviewer."
msgstr ""

#: ../../taichi/docs/utilities.rst:75
msgid "Get feedback from the reviewer, and improve the result."
msgstr ""

#: ../../taichi/docs/utilities.rst:81
msgid "Trigger GDB when the program crashes"
msgstr ""

#: ../../taichi/docs/utilities.rst:83
msgid ""
"# Python\n"
"ti.set_gdb_trigger(True)\n"
"\n"
"// C++\n"
"CoreState::set_trigger_gdb_when_crash(true);\n"
"\n"
"# Shell\n"
"export TI_GDB_TRIGGER=1"
msgstr ""

#: ../../taichi/docs/utilities.rst:95
msgid "Interface System"
msgstr ""

#: ../../taichi/docs/utilities.rst:96
msgid "Print all interfaces and units"
msgstr ""

#: ../../taichi/docs/utilities.rst:98
msgid "ti.core.print_all_units()"
msgstr ""

#: ../../taichi/docs/utilities.rst:103
msgid "Serialization"
msgstr ""

#: ../../taichi/docs/utilities.rst:105
msgid ""
"The serialization module of taichi allows you to serialize/deserialize "
"objects into/from binary strings."
msgstr ""

#: ../../taichi/docs/utilities.rst:107
msgid ""
"You can use ``TI_IO`` macros to explicit define fields necessary in "
"Taichi."
msgstr ""

#: ../../taichi/docs/utilities.rst:109
msgid ""
"// TI_IO_DEF\n"
"struct Particle {\n"
"    Vector3f position, velocity;\n"
"    real mass;\n"
"    string name;\n"
"\n"
"    TI_IO_DEF(position, velocity, mass, name);\n"
"}\n"
"\n"
"// TI_IO_DECL\n"
"struct Particle {\n"
"    Vector3f position, velocity;\n"
"    real mass;\n"
"    bool has_name\n"
"    string name;\n"
"\n"
"    TI_IO_DECL() {\n"
"        TI_IO(position);\n"
"        TI_IO(velocity);\n"
"        TI_IO(mass);\n"
"        TI_IO(has_name);\n"
"        // More flexibility:\n"
"        if (has_name) {\n"
"            TI_IO(name);\n"
"        }\n"
"    }\n"
"}\n"
"\n"
"// TI_IO_DEF_VIRT();"
msgstr ""

#: ../../taichi/docs/utilities.rst:143
msgid "Progress Notification"
msgstr ""

#: ../../taichi/docs/utilities.rst:145
msgid ""
"The taichi messager can send an email to ``$TI_MONITOR_EMAIL`` when the "
"task finished or crashed. To enable:"
msgstr ""

#: ../../taichi/docs/utilities.rst:148
msgid ""
"from taichi.tools import messager\n"
"messager.enable(task_id='test')"
msgstr ""

#: ../../taichi/docs/vector.rst:4
msgid "Vectors"
msgstr ""

#: ../../taichi/docs/vector.rst:6
msgid "A vector in Taichi can have two forms:"
msgstr ""

#: ../../taichi/docs/vector.rst:8
msgid ""
"as a temporary local variable. An ``n`` component vector consists of "
"``n`` scalar values."
msgstr ""

#: ../../taichi/docs/vector.rst:9
msgid ""
"as an element of a global tensor. In this case, the tensor is an "
"N-dimensional array of ``n`` component vectors."
msgstr ""

#: ../../taichi/docs/vector.rst:11
msgid "See :ref:`tensor` for more details."
msgstr ""

#: ../../taichi/docs/vector.rst:21
msgid "(scalar) the number of components in the vector"
msgstr ""

#: ../../taichi/docs/vector.rst:25
msgid "For example, this creates a 5x4 tensor of 3 component vectors: ::"
msgstr ""

#: ../../taichi/docs/vector.rst:28
msgid ""
"# Python-scope\n"
"a = ti.Vector(3, dt=ti.f32, shape=(5, 4))"
msgstr ""

#: ../../taichi/docs/vector.rst:33
msgid ""
"In Python-scope, ``ti.var`` declares :ref:`scalar_tensor`, while "
"``ti.Vector`` declares tensors of vectors."
msgstr ""

#: ../../taichi/docs/vector.rst:44
msgid "For example, this creates a 3D vector with components (2, 3, 4): ::"
msgstr ""

#: ../../taichi/docs/vector.rst:47
msgid ""
"# Taichi-scope\n"
"a = ti.Vector([2, 3, 4])"
msgstr ""

#: ../../taichi/docs/vector.rst:58 ../../taichi/docs/vector.rst:88
msgid "(Vector) the vector"
msgstr ""

#: ../../taichi/docs/vector.rst:61
msgid "(scalar) index of the vector component"
msgstr ""

#: ../../taichi/docs/vector.rst:63
msgid "This extracts the first component of vector ``a[6, 3]``: ::"
msgstr ""

#: ../../taichi/docs/vector.rst:66
msgid ""
"x = a[6, 3][0]\n"
"\n"
"# or\n"
"vec = a[6, 3]\n"
"x = vec[0]"
msgstr ""

#: ../../taichi/docs/vector.rst:74
msgid ""
"**Always** use two pair of square brackets to access scalar elements from"
" tensors of vectors."
msgstr ""

#: ../../taichi/docs/vector.rst:76
msgid ""
"The indices in the first pair of brackets locate the vector inside the "
"tensor of vectors;"
msgstr ""

#: ../../taichi/docs/vector.rst:77
msgid ""
"The indices in the second pair of brackets locate the scalar element "
"inside the vector."
msgstr ""

#: ../../taichi/docs/vector.rst:79
msgid ""
"For 0-D tensors of vectors, indices in the first pair of brackets should "
"be ``[None]``."
msgstr ""

#: ../../taichi/docs/vector.rst:89
msgid "(scalar) index of the component"
msgstr ""

#: ../../taichi/docs/vector.rst:91
msgid "For example, this extracts the first component of vector ``a``: ::"
msgstr ""

#: ../../taichi/docs/vector.rst:94
msgid "x = a[0]"
msgstr ""

#: ../../taichi/docs/vector.rst:96
msgid "This sets the second component of ``a`` to 4: ::"
msgstr ""

#: ../../taichi/docs/vector.rst:99
msgid "a[1] = 4"
msgstr ""

#: ../../taichi/docs/vector.rst:101
msgid "TODO: add descriptions about ``a(i, j)``"
msgstr ""

#: ../../taichi/docs/vector.rst:108 ../../taichi/docs/vector.rst:127
#: ../../taichi/docs/vector.rst:128 ../../taichi/docs/vector.rst:155
#: ../../taichi/docs/vector.rst:156 ../../taichi/docs/vector.rst:173
msgid "(Vector)"
msgstr ""

#: ../../taichi/docs/vector.rst:109
msgid ""
"(optional, scalar) a safe-guard value for ``sqrt``, usually 0. See the "
"note below."
msgstr ""

#: ../../taichi/docs/vector.rst:110
msgid "(scalar) the magnitude / length / norm of vector"
msgstr ""

#: ../../taichi/docs/vector.rst:115
msgid ""
"a = ti.Vector([3, 4])\n"
"a.norm() # sqrt(3*3 + 4*4 + 0) = 5"
msgstr ""

#: ../../taichi/docs/vector.rst:118
msgid "``a.norm(eps)`` is equivalent to ``ti.sqrt(a.dot(a) + eps)``"
msgstr ""

#: ../../taichi/docs/vector.rst:121
msgid ""
"Set ``eps = 1e-5`` for example, to safe guard the operator's gradient on "
"zero vectors during differentiable programming."
msgstr ""

#: ../../taichi/docs/vector.rst:129
msgid "(scalar) the dot (inner) product of ``a`` and ``b``"
msgstr ""

#: ../../taichi/docs/vector.rst:131 ../../taichi/docs/vector.rst:159
#: ../../taichi/docs/vector.rst:177
msgid "E.g., ::"
msgstr ""

#: ../../taichi/docs/vector.rst:134
msgid ""
"a = ti.Vector([1, 3])\n"
"b = ti.Vector([2, 4])\n"
"a.dot(b) # 1*2 + 3*4 = 14"
msgstr ""

#: ../../taichi/docs/vector.rst:141 ../../taichi/docs/vector.rst:142
msgid "(Vector, 3 component)"
msgstr ""

#: ../../taichi/docs/vector.rst:143
msgid "(Vector, 3D) the cross product of ``a`` and ``b``"
msgstr ""

#: ../../taichi/docs/vector.rst:145
msgid "We use right-handed coordinate system, E.g., ::"
msgstr ""

#: ../../taichi/docs/vector.rst:148
msgid ""
"a = ti.Vector([1, 2, 3])\n"
"b = ti.Vector([4, 5, 6])\n"
"c = ti.cross(a, b) # [2*6 - 5*3, 4*3 - 1*6, 1*5 - 4*2]"
msgstr ""

#: ../../taichi/docs/vector.rst:157
msgid "(Matrix) the outer product of ``a`` and ``b``"
msgstr ""

#: ../../taichi/docs/vector.rst:162
msgid ""
"a = ti.Vector([1, 2, 3])\n"
"b = ti.Vector([4, 5, 6])\n"
"c = ti.outer_product(a, b) # NOTE: c[i, j] = a[i] * b[j]\n"
"# c = [[1*4, 1*5, 1*6], [2*4, 2*5, 2*6], [3*4, 3*5, 3*6]]"
msgstr ""

#: ../../taichi/docs/vector.rst:168
msgid ""
"This is not the same as `ti.cross`. ``a`` and ``b`` do not have to be 3 "
"component vectors."
msgstr ""

#: ../../taichi/docs/vector.rst:174
msgid "(DataType)"
msgstr ""

#: ../../taichi/docs/vector.rst:175
msgid "(Vector) vector with all components of ``a`` casted into type ``dt``"
msgstr ""

#: ../../taichi/docs/vector.rst:180
msgid ""
"# Taichi-scope\n"
"a = ti.Vector([1.6, 2.3])\n"
"a.cast(ti.i32) # [2, 3]"
msgstr ""

#: ../../taichi/docs/vector.rst:185
msgid ""
"Vectors are special matrices with only 1 column. In fact, ``ti.Vector`` "
"is just an alias of ``ti.Matrix``."
msgstr ""

#~ msgid "If you haven't done so, please install Taichi via ``pip``:"
#~ msgstr ""

#~ msgid "WIP"
#~ msgstr ""

#~ msgid ""
#~ "If the machine does not have CUDA"
#~ " support, Taichi will fall back to"
#~ " CPUs instead."
#~ msgstr ""

#~ msgid ""
#~ "Tests should be added to "
#~ "``taichi/tests``. Use ``ti test`` to run"
#~ " all the tests. Use ``ti test "
#~ "-v`` for verbose outputs. Use ``ti "
#~ "test <filename(s)>`` to run specific "
#~ "tests. e.g. ``ti test numpy_io`` and "
#~ "``ti test test_numpy_io.py`` are equivalent."
#~ " Use ``ti test -a <arch(s)>`` for "
#~ "test against specified architectures. e.g. "
#~ "``ti test -a opengl`` or ``ti test"
#~ " numpy_io -a cuda,metal``. Use ``ti "
#~ "test -c`` to run only the C++ "
#~ "tests. e.g. ``ti test -c alg_simp``"
#~ msgstr ""

#~ msgid "Returns"
#~ msgstr ""

#~ msgid "Parameters"
#~ msgstr ""

#~ msgid "返回"
#~ msgstr ""

#~ msgid ""
#~ "(If on Ubuntu) Execute ``sudo apt "
#~ "install libtinfo-dev clang-8`` (or "
#~ "``clang-7`` should work as well)."
#~ msgstr ""

#~ msgid "(If on Arch Linux) Execute"
#~ msgstr ""

#~ msgid ""
#~ "wget "
#~ "https://archive.archlinux.org/packages/c/clang/clang-8.0.1-1-x86_64.pkg.tar.xz"
#~ "\n"
#~ "sudo pacman -Qp clang-8.0.1-1-x86_64.pkg.tar.xz"
#~ msgstr ""

#~ msgid ""
#~ "If you have installed ``clang`` (9.0.1)"
#~ " before, this command will overrides "
#~ "the existing ``clang``. If you don't "
#~ "want to break up depedencies, please "
#~ "build from scratch and install it "
#~ "in ``/opt``. Then add ``/opt/clang/bin`` "
#~ "to your ``$PATH``."
#~ msgstr ""

#~ msgid "Contribution"
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid "``ti.length(dynamic_snode)``"
#~ msgstr ""

#~ msgid "TODO: update"
#~ msgstr ""

#~ msgid ""
#~ "gui = ti.GUI('Title', (640, 480))\n"
#~ "while not gui.is_pressed(ti.GUI.ESCAPE):\n"
#~ "    gui.set_image(img)\n"
#~ "    gui.show()"
#~ msgstr ""

#~ msgid ""
#~ "Also checkout ``examples/keyboard.py`` for "
#~ "more advanced event processing."
#~ msgstr ""

#~ msgid ""
#~ "x = 3\n"
#~ "y = 4\n"
#~ "z = ti.atomic_add(x, y)\n"
#~ "# now z = 7, y = 4, z = 3"
#~ msgstr ""

#~ msgid "``ti.sqr(x)``"
#~ msgstr ""

#~ msgid "Advanced data layouts"
#~ msgstr ""

#~ msgid ""
#~ "Memory layout is key to performance, "
#~ "especially for memory-bound applications. "
#~ "A carefully designed data layout can "
#~ "significantly improve cache/TLB-hit rates "
#~ "and cacheline utilization."
#~ msgstr ""

#~ msgid ""
#~ "We suggested starting with the default"
#~ " layout specification (simply by specifying"
#~ " ``shape`` when creating tensors using "
#~ "``ti.var/Vector/Matrix``), and then migrate to"
#~ " more advanced layouts using the "
#~ "``ti.root.X`` syntax."
#~ msgstr ""

#~ msgid "The default data layout using ``shape``"
#~ msgstr ""

#~ msgid ""
#~ "By default, when allocating a ``ti.var``"
#~ " , it follows the most naive "
#~ "data layout"
#~ msgstr ""

#~ msgid ""
#~ "Or equivalently, the same data layout"
#~ " can be specified using advanced "
#~ "`data layout description`:"
#~ msgstr ""

#~ msgid ""
#~ "# Create the global tensor\n"
#~ "val = ti.var(ti.f32)\n"
#~ "# Specify the shape and layout\n"
#~ "ti.root.dense(ti.ijk, (32, 64, 128)).place(val)"
#~ msgstr ""

#~ msgid ""
#~ "However, oftentimes this data layout is"
#~ " suboptimal for computer graphics tasks."
#~ " For example, ``val[i, j, k]`` and"
#~ " ``val[i + 1, j, k]`` are very"
#~ " far away (``32 KB``) from each "
#~ "other, and leads to poor access "
#~ "locality under certain computation tasks. "
#~ "Specifically, in tasks such as texture"
#~ " trilinear interpolation, the two elements"
#~ " are not even within the same "
#~ "``4KB`` pages, creating a huge cache/TLB"
#~ " pressure."
#~ msgstr ""

#~ msgid "Advanced data layout specification"
#~ msgstr ""

#~ msgid "3D Particle positions and velocities, arrays-of-structures"
#~ msgstr ""

#~ msgid "3D Particle positions and velocities, structures-of-arrays"
#~ msgstr ""

#~ msgid "Struct-fors on advanced (dense) data layouts"
#~ msgstr ""

#~ msgid ""
#~ "If ``A`` is blocked, the iteration "
#~ "will happen within each block first. "
#~ "This maximizes memory bandwidth utilization"
#~ " in most cases."
#~ msgstr ""

#~ msgid ""
#~ "Struct-fors on sparse tensors follows"
#~ " the same philosophy, and will be "
#~ "discussed further in :ref:`sparse`."
#~ msgstr ""

#~ msgid ""
#~ "# fractal.py\n"
#~ "\n"
#~ "import taichi as ti\n"
#~ "\n"
#~ "ti.init(arch=ti.gpu) # Run on GPU by default\n"
#~ "\n"
#~ "n = 320\n"
#~ "pixels = ti.var(dt=ti.f32, shape=(n * 2, n))\n"
#~ "\n"
#~ "@ti.func\n"
#~ "def complex_sqr(z):\n"
#~ "  return ti.Vector([z[0] ** 2 - z[1] ** 2, z[1] * z[0] * 2])\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def paint(t: ti.f32):\n"
#~ "  for i, j in pixels: # Parallized over all pixels\n"
#~ "    c = ti.Vector([-0.8, ti.sin(t) * 0.2])\n"
#~ "    z = ti.Vector([float(i) / n - 1, float(j) / n - 0.5]) * 2\n"
#~ "    iterations = 0\n"
#~ "    while z.norm() < 20 and iterations < 50:\n"
#~ "      z = complex_sqr(z) + c\n"
#~ "      iterations += 1\n"
#~ "    pixels[i, j] = 1 - iterations * 0.02\n"
#~ "\n"
#~ "gui = ti.GUI(\"Fractal\", (n * 2, n))\n"
#~ "\n"
#~ "for i in range(1000000):\n"
#~ "  paint(i * 0.03)\n"
#~ "  gui.set_image(pixels)\n"
#~ "  gui.show()"
#~ msgstr ""

#~ msgid ""
#~ "Taichi is an embedded domain-specific"
#~ " language (DSL) in Python. It "
#~ "pretends to be a plain Python "
#~ "package, although heavy engineering has "
#~ "been done to make this happen."
#~ msgstr ""

#~ msgid ""
#~ "This design decision virtually makes "
#~ "every Python programmer capable of "
#~ "writing Taichi programs, after minimal "
#~ "learning efforts. You can also reuse "
#~ "the package management system, Python "
#~ "IDEs, and existing Python packages."
#~ msgstr ""

#~ msgid ""
#~ "# Run on GPU, automatically detect backend\n"
#~ "ti.init(arch=ti.gpu)\n"
#~ "# Run on NVIDIA GPU, CUDA required\n"
#~ "ti.init(arch=ti.cuda)\n"
#~ "# Run on GPU, with the OpenGL backend\n"
#~ "ti.init(arch=ti.opengl)\n"
#~ "# Run on GPU, with the Apple Metal backend, if you are on OS X\n"
#~ "ti.init(arch=ti.metal)\n"
#~ "# Run on CPU (default)\n"
#~ "ti.init(arch=ti.cpu)"
#~ msgstr ""

#~ msgid "(OK: supported, WIP: work in progress, N/A: not available)"
#~ msgstr ""

#~ msgid ""
#~ "When specified ``arch=ti.gpu``, Taichi will"
#~ " try to run on CUDA. If CUDA"
#~ " is not supported on your machine,"
#~ " Taichi will fall back to Metal "
#~ "or OpenGL. If no GPU backend "
#~ "(CUDA, Metal, or OpenGL) is supported,"
#~ " Taichi will fall back to CPUs."
#~ msgstr ""

#~ msgid ""
#~ "When running the CUDA backend on "
#~ "Windows and ARM devices (e.g. NVIDIA "
#~ "Jetson), Taichi will by default allocate"
#~ " 1 GB memory for tensor storage. "
#~ "You can override this by initializing"
#~ " with ``ti.init(arch=ti.cuda, device_memory_GB=3.4)``"
#~ " to allocate ``3.4`` GB GPU memory,"
#~ " or ``ti.init(arch=ti.cuda, "
#~ "device_memory_fraction=0.3)`` to allocate ``30%``"
#~ " of total available GPU memory."
#~ msgstr ""

#~ msgid "(Sparse) Tensors"
#~ msgstr ""

#~ msgid ""
#~ "``pixels = ti.var(dt=ti.f32, shape=(n * "
#~ "2, n))`` allocates a 2D dense "
#~ "tensor named ``pixel`` of size ``(640,"
#~ " 320)`` and type ``ti.f32`` (i.e. "
#~ "``float`` in C)."
#~ msgstr ""

#~ msgid ""
#~ "**Taichi-scope v.s. Python-scope**: "
#~ "everything decorated with ``ti.kernel`` and"
#~ " ``ti.func`` is in Taichi-scope, "
#~ "which will be compiled by the "
#~ "Taichi compiler. Code outside the "
#~ "Taichi-scopes is simply native Python "
#~ "code."
#~ msgstr ""

#~ msgid ""
#~ "For loops at the outermost scope "
#~ "in a Taichi kernel is automatically "
#~ "parallelized. For loops can have two "
#~ "forms, i.e. `range-for loops` and "
#~ "`struct-for loops`."
#~ msgstr ""

#~ msgid ""
#~ "**Range-for loops** are no different "
#~ "from that in native Python, except "
#~ "that it will be parallelized when "
#~ "used as the outermost scope. Range-"
#~ "for loops can be nested."
#~ msgstr ""

#~ msgid ""
#~ "@ti.kernel\n"
#~ "def fill():\n"
#~ "  for i in range(10): # parallelized\n"
#~ "    x[i] += i\n"
#~ "\n"
#~ "    s = 0\n"
#~ "    for j in range(5): # serialized in each parallel thread\n"
#~ "      s += j\n"
#~ "\n"
#~ "    y[i] = s\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def fill_3d():\n"
#~ "  # Parallelized for all 3 <= i < 8, 1 <= j < 6, 0 <= k < 9\n"
#~ "  for i, j, k in ti.ndrange((3, 8), (1, 6), 9):\n"
#~ "    x[i, j, k] = i + j + k"
#~ msgstr ""

#~ msgid ""
#~ "**Struct-for loops** have a cleaner "
#~ "syntax, and are particularly useful when"
#~ " iterating over tensor elements. In "
#~ "the fractal code above, ``for i, j"
#~ " in pixels`` loops over all the "
#~ "pixel coordinates, i.e. ``(0, 0), (0,"
#~ " 1), (0, 2), ... , (0, 319),"
#~ " (1, 0), ..., (639, 319)``."
#~ msgstr ""

#~ msgid "Struct-for's must be at the outer-most scope of kernels."
#~ msgstr ""

#~ msgid ""
#~ "# Good kernel\n"
#~ "@ti.func\n"
#~ "def foo():\n"
#~ "  for i in x:\n"
#~ "    ...\n"
#~ "\n"
#~ "# Bad kernel\n"
#~ "@ti.func\n"
#~ "def bar(k: ti.i32):\n"
#~ "  # The outermost scope is a `if` statement, not the struct-for loop!\n"
#~ "  if k > 42:\n"
#~ "    for i in x:\n"
#~ "      ..."
#~ msgstr ""

#~ msgid "``break`` is not supported in **outermost (parallelized)** loops:"
#~ msgstr ""

#~ msgid ""
#~ "@ti.kernel\n"
#~ "def foo():\n"
#~ "  for i in x:\n"
#~ "      ...\n"
#~ "      break # ERROR! You cannot break a parallelized loop!\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def foo():\n"
#~ "  for i in x:\n"
#~ "      for j in y:\n"
#~ "          ...\n"
#~ "          break # OK"
#~ msgstr ""

#~ msgid ""
#~ "Everything outside Taichi-scope (``ti.func``"
#~ " and ``ti.kernel``) is simply Python. "
#~ "You can use your favorite Python "
#~ "packages (e.g. ``numpy``, ``pytorch``, "
#~ "``matplotlib``) with Taichi."
#~ msgstr ""

#~ msgid "Vector type system"
#~ msgstr ""

#~ msgid ""
#~ "@ti.data_oriented\n"
#~ "class Array2D:\n"
#~ "  def __init__(self, n, m, increment):\n"
#~ "    self.n = n\n"
#~ "    self.m = m\n"
#~ "    self.val = ti.var(ti.f32)\n"
#~ "    self.total = ti.var(ti.f32)\n"
#~ "    self.increment = increment\n"
#~ "\n"
#~ "  @staticmethod\n"
#~ "  @ti.func\n"
#~ "  def clamp(x):  # Clamp to [0, 1)\n"
#~ "      return max(0, min(1 - 1e-6, x))\n"
#~ "\n"
#~ "  def place(self, root):\n"
#~ "    root.dense(ti.ij, (self.n, self.m)).place(self.val)\n"
#~ "    root.place(self.total)\n"
#~ "\n"
#~ "  @ti.kernel\n"
#~ "  def inc(self):\n"
#~ "    for i, j in self.val:\n"
#~ "      ti.atomic_add(self.val[i, j], self.increment)\n"
#~ "\n"
#~ "  @ti.kernel\n"
#~ "  def inc2(self, increment: ti.i32):\n"
#~ "    for i, j in self.val:\n"
#~ "      ti.atomic_add(self.val[i, j], increment)\n"
#~ "\n"
#~ "  @ti.kernel\n"
#~ "  def reduce(self):\n"
#~ "    for i, j in self.val:\n"
#~ "      ti.atomic_add(self.total, self.val[i, j] * 4)\n"
#~ "\n"
#~ "arr = Array2D(128, 128, 3)\n"
#~ "\n"
#~ "double_total = ti.var(ti.f32)\n"
#~ "\n"
#~ "@ti.layout\n"
#~ "def place():\n"
#~ "  ti.root.place(\n"
#~ "      arr)  # Place an object. "
#~ "Make sure you defined place for "
#~ "that obj\n"
#~ "  ti.root.place(double_total)\n"
#~ "  ti.root.lazy_grad()\n"
#~ "\n"
#~ "arr.inc()\n"
#~ "arr.inc.grad()\n"
#~ "assert arr.val[3, 4] == 3\n"
#~ "arr.inc2(4)\n"
#~ "assert arr.val[3, 4] == 7\n"
#~ "\n"
#~ "with ti.Tape(loss=arr.total):\n"
#~ "  arr.reduce()\n"
#~ "\n"
#~ "for i in range(arr.n):\n"
#~ "  for j in range(arr.m):\n"
#~ "    assert arr.val.grad[i, j] == 4\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def double():\n"
#~ "  double_total[None] = 2 * arr.total\n"
#~ "\n"
#~ "with ti.Tape(loss=double_total):\n"
#~ "  arr.reduce()\n"
#~ "  double()\n"
#~ "\n"
#~ "for i in range(arr.n):\n"
#~ "  for j in range(arr.m):\n"
#~ "    assert arr.val.grad[i, j] == 8"
#~ msgstr ""

#~ msgid ""
#~ "Not providing ``shape`` allows you to"
#~ " *place* the tensor as *sparse* "
#~ "tensors, see :ref:`sparse` for more "
#~ "details."
#~ msgstr ""

#~ msgid "``ti.sin(x)``"
#~ msgstr ""

#~ msgid "``ti.cos(x)``"
#~ msgstr ""

#~ msgid "``ti.asin(x)``"
#~ msgstr ""

#~ msgid "``ti.acos(x)``"
#~ msgstr ""

#~ msgid "``ti.atan2(x, y)``"
#~ msgstr ""

#~ msgid "``ti.cast(x, type)``"
#~ msgstr ""

#~ msgid "``ti.sqrt(x)``"
#~ msgstr ""

#~ msgid "``ti.floor(x)``"
#~ msgstr ""

#~ msgid "``ti.inv(x)``"
#~ msgstr ""

#~ msgid "``ti.tan(x)``"
#~ msgstr ""

#~ msgid "``ti.tanh(x)``"
#~ msgstr ""

#~ msgid "``ti.exp(x)``"
#~ msgstr ""

#~ msgid "``ti.log(x)``"
#~ msgstr ""

#~ msgid "``ti.random(type)``"
#~ msgstr ""

#~ msgid "``abs(x)``"
#~ msgstr ""

#~ msgid "``max(a, b)``"
#~ msgstr ""

#~ msgid "``min(a, b)``"
#~ msgstr ""

#~ msgid "``x ** y``"
#~ msgstr ""

#~ msgid ""
#~ "Inplace adds are atomic on global "
#~ "data. I.e., ``a += b`` is "
#~ "equivalent to ``ti.atomic_add(a, b)``"
#~ msgstr ""

#~ msgid "Debug your program with ``print(x)``."
#~ msgstr ""

#~ msgid "See :ref:`linalg` for more on matrices."
#~ msgstr ""

#~ msgid ""
#~ "as an element of a global tensor."
#~ " In this case, the tensor is an"
#~ " N-dimensional array of ``n`` component "
#~ "vectors"
#~ msgstr ""

#~ msgid "See :ref:`tensor_matrix` for more details."
#~ msgstr ""

#~ msgid "Copyright (c) 2012 - present, Victor Zverovich"
#~ msgstr ""

#~ msgid ""
#~ "Permission is hereby granted, free of"
#~ " charge, to any person obtaining a"
#~ " copy of this software and associated"
#~ " documentation files (the \"Software\"), to"
#~ " deal in the Software without "
#~ "restriction, including without limitation the"
#~ " rights to use, copy, modify, merge,"
#~ " publish, distribute, sublicense, and/or "
#~ "sell copies of the Software, and "
#~ "to permit persons to whom the "
#~ "Software is furnished to do so, "
#~ "subject to the following conditions:"
#~ msgstr ""

#~ msgid ""
#~ "The above copyright notice and this "
#~ "permission notice shall be included in"
#~ " all copies or substantial portions "
#~ "of the Software."
#~ msgstr ""

#~ msgid ""
#~ "THE SOFTWARE IS PROVIDED \"AS IS\", "
#~ "WITHOUT WARRANTY OF ANY KIND, EXPRESS"
#~ " OR IMPLIED, INCLUDING BUT NOT "
#~ "LIMITED TO THE WARRANTIES OF "
#~ "MERCHANTABILITY, FITNESS FOR A PARTICULAR "
#~ "PURPOSE AND NONINFRINGEMENT. IN NO EVENT"
#~ " SHALL THE AUTHORS OR COPYRIGHT "
#~ "HOLDERS BE LIABLE FOR ANY CLAIM, "
#~ "DAMAGES OR OTHER LIABILITY, WHETHER IN"
#~ " AN ACTION OF CONTRACT, TORT OR "
#~ "OTHERWISE, ARISING FROM, OUT OF OR "
#~ "IN CONNECTION WITH THE SOFTWARE OR "
#~ "THE USE OR OTHER DEALINGS IN THE"
#~ " SOFTWARE."
#~ msgstr ""

#~ msgid "--- Optional exception to the license ---"
#~ msgstr ""

#~ msgid ""
#~ "As an exception, if, as a result"
#~ " of your compiling your source code,"
#~ " portions of this Software are "
#~ "embedded into a machine-executable "
#~ "object form of such source code, "
#~ "you may redistribute such embedded "
#~ "portions in such object form without "
#~ "including the above copyright and "
#~ "permission notices."
#~ msgstr ""

#~ msgid ""
#~ "Please check out `the DiffTaichi paper"
#~ " <https://arxiv.org/pdf/1910.00935.pdf>`_ and `video"
#~ " <https://www.youtube.com/watch?v=Z1xvAZve9aE>`_ to "
#~ "learn more about Taichi differentiable "
#~ "programming."
#~ msgstr ""

#~ msgid ""
#~ "Here ``external arrays`` refer to "
#~ "``numpy.ndarray`` or ``torch.Tensor``."
#~ msgstr ""

#~ msgid "Use external arrays as Taichi kernel parameters"
#~ msgstr ""

#~ msgid "To print verbosed details: ``export TI_VERBOSE=1``"
#~ msgstr ""

#~ msgid "Let's dive into components of this simple Taichi program."
#~ msgstr ""

#~ msgid ""
#~ "Taichi is a domain-specific language "
#~ "(DSL) embedded in Python. Heavy "
#~ "engineering has been done to make "
#~ "Taichi as easy to use as a "
#~ "Python package."
#~ msgstr ""

#~ msgid ""
#~ "After minimal learning efforts, every "
#~ "Python programmer will be capable of "
#~ "writing Taichi programs, You can also"
#~ " reuse the Python package management "
#~ "system, Python IDEs, and existing Python"
#~ " packages."
#~ msgstr ""

#~ msgid ""
#~ "Taichi code can run on CPUs or "
#~ "GPUs. Initialize Taichi according to "
#~ "your hardware platform:"
#~ msgstr ""

#~ msgid ""
#~ "With ``arch=ti.gpu``, Taichi will try to"
#~ " run on CUDA. If CUDA is not"
#~ " supported on your machine, Taichi "
#~ "will fall back to Metal or OpenGL."
#~ " If no GPU backend (CUDA, Metal, "
#~ "or OpenGL) is supported, Taichi will "
#~ "fall back to CPUs."
#~ msgstr ""

#~ msgid ""
#~ "When using the CUDA backend on "
#~ "Windows systems or ARM devices (e.g. "
#~ "NVIDIA Jetson), Taichi will by default"
#~ " allocate 1 GB memory for tensor "
#~ "storage. You can override this by "
#~ "initializing with ``ti.init(arch=ti.cuda, "
#~ "device_memory_GB=3.4)`` to allocate ``3.4`` GB"
#~ " GPU memory, or ``ti.init(arch=ti.cuda, "
#~ "device_memory_fraction=0.3)`` to allocate ``30%``"
#~ " of total available GPU memory."
#~ msgstr ""

#~ msgid ""
#~ "On other platforms Taichi will make "
#~ "use of its on-demand memory "
#~ "allocator to adaptively allocate memory."
#~ msgstr ""

#~ msgid ""
#~ "Taichi is a data-oriented programming"
#~ " language, where dense or spatially-"
#~ "sparse tensors are first-class citizens."
#~ " See :ref:`sparse` for more details "
#~ "on sparse tensors."
#~ msgstr ""

#~ msgid ""
#~ "In the code above, ``pixels = "
#~ "ti.var(dt=ti.f32, shape=(n * 2, n))`` "
#~ "allocates a 2D dense tensor named "
#~ "``pixel`` of size ``(640, 320)`` and "
#~ "element data type ``ti.f32`` (i.e. "
#~ "``float`` in C)."
#~ msgstr ""

#~ msgid ""
#~ "Computation happens within Taichi **kernels**."
#~ " Kernel arguments must be type-"
#~ "hinted. The language used in Taichi "
#~ "kernels and functions looks exactly like"
#~ " Python, yet the Taichi frontend "
#~ "compiler converts it into a language "
#~ "that is **compiled, statically-typed, "
#~ "lexically-scoped, parallel, and differentiable**."
#~ msgstr ""

#~ msgid ""
#~ "You can also define Taichi **functions**"
#~ " with ``ti.func``, which can be "
#~ "called and reused by kernels and "
#~ "other functions."
#~ msgstr ""

#~ msgid ""
#~ "**Taichi-scope v.s. Python-scope**: "
#~ "everything decorated with ``ti.kernel`` and"
#~ " ``ti.func`` is in Taichi-scope, "
#~ "which will be compiled by the "
#~ "Taichi compiler. Code outside the "
#~ "Taichi-scopes is simply normal Python "
#~ "code."
#~ msgstr ""

#~ msgid ""
#~ "For those who came from the world"
#~ " of CUDA, ``ti.func`` corresponds to "
#~ "``__device__``, and ``ti.kernel`` corresponds "
#~ "to ``__global__``."
#~ msgstr ""

#~ msgid ""
#~ "**Struct-for loops** have are "
#~ "particularly useful when iterating over "
#~ "(sparse) tensor elements. In the code"
#~ " above, ``for i, j in pixels`` "
#~ "loops over all the pixel coordinates,"
#~ " i.e. ``(0, 0), (0, 1), (0, 2),"
#~ " ... , (0, 319), (1, 0), ...,"
#~ " (639, 319)``."
#~ msgstr ""

#~ msgid "Struct-for's must live at the outer-most scope of kernels."
#~ msgstr ""

#~ msgid ""
#~ "Everything outside Taichi-scopes (``ti.func``"
#~ " and ``ti.kernel``) is simply Python. "
#~ "You can use your favorite Python "
#~ "packages (e.g. ``numpy``, ``pytorch``, "
#~ "``matplotlib``) with Taichi."
#~ msgstr ""

#~ msgid ""
#~ "In Python-scope, you can access "
#~ "Taichi tensors using plain indexing "
#~ "syntax, and helper functions such as "
#~ "``from_numpy`` and ``to_torch``:"
#~ msgstr ""

#~ msgid ""
#~ "image[42, 11] = 0.7\n"
#~ "print(image[1, 63])\n"
#~ "\n"
#~ "import numpy as np\n"
#~ "pixels.from_numpy(np.random.rand(n * 2, n))\n"
#~ "\n"
#~ "import matplotlib.pyplot as plt\n"
#~ "plt.imshow(pixels.to_numpy())\n"
#~ "plt.show()"
#~ msgstr ""

#~ msgid ""
#~ "@ti.kernel\n"
#~ "def copy(x: ti.template(), y: ti.template()):\n"
#~ "  for I in ti.grouped(y):\n"
#~ "    x[I] = y[I]\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def array_op(x: ti.template(), y: ti.template()):\n"
#~ "  # If tensor x is 2D\n"
#~ "  for I in ti.grouped(x): # I "
#~ "is a vector of size x.dim() and"
#~ " data type i32\n"
#~ "    y[I + ti.Vector([0, 1])] = I[0] + I[1]\n"
#~ "  # is equivalent to\n"
#~ "  for i, j in x:\n"
#~ "    y[i, j + 1] = i + j"
#~ msgstr ""

#~ msgid ""
#~ "See :ref:`layout` for more details about"
#~ " data layout. ``ti.root`` is the root"
#~ " node of the data structure."
#~ msgstr ""

#~ msgid ""
#~ "@ti.kernel\n"
#~ "def print_xy(x: ti.i32, y: ti.f32):\n"
#~ "  print(x + y)\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def copy(x: ti.template(), y: ti.template()):\n"
#~ "  for i in x:\n"
#~ "    y[i] = x[i]"
#~ msgstr ""

#~ msgid ""
#~ "A kernel can have **scalar** return "
#~ "value. If a kernel has a return"
#~ " value, it must be type-hinted. "
#~ "The return value will be automatically"
#~ " casted into the hinted type. e.g.,"
#~ msgstr ""

#~ msgid ""
#~ "For differentiable programming kernels should"
#~ " better have either serial statements "
#~ "or a single parallel for-loop. If"
#~ " you don't use differentiable programming,"
#~ " feel free to ignore this tip."
#~ msgstr ""

#~ msgid ""
#~ "For now, we only support one "
#~ "scalar as return value. Returning "
#~ "``ti.Matrix`` or `ti.Vector`` is not "
#~ "supported. Python-style tuple return is"
#~ " not supported. e.g.:"
#~ msgstr ""

#~ msgid ""
#~ "@ti.kernel\n"
#~ "def bad_kernel() -> ti.Matrix:\n"
#~ "    return ti.Matrix([[1, 0], [0, 1]])  # ERROR!\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def bad_kernel() -> (ti.i32, ti.f32):\n"
#~ "    x = 1\n"
#~ "    y = 0.5\n"
#~ "    return x, y  #  ERROR!"
#~ msgstr ""

#~ msgid ""
#~ "For correct gradient behaviors in "
#~ "differentiable programming, please refrain "
#~ "from using kernel return values. "
#~ "Instead, store the result into a "
#~ "global variable (e.g. ``loss[None]``)."
#~ msgstr ""

#~ msgid "(TODO: move the following to advanced topics)"
#~ msgstr ""

#~ msgid ""
#~ "@ti.kernel\n"
#~ "def a_hard_kernel_to_auto_differentiate():\n"
#~ "  sum = 0\n"
#~ "  for i in x:\n"
#~ "    sum += x[i]\n"
#~ "  for i in y:\n"
#~ "    y[i] = sum\n"
#~ "\n"
#~ "# instead, split it into multiple "
#~ "kernels to be nice to the Taichi"
#~ " autodiff compiler:\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def reduce():\n"
#~ "  for i in x:\n"
#~ "    sum[None] += x[i]\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def assign()\n"
#~ "  for i in y:\n"
#~ "    y[i] = sum[None]\n"
#~ "\n"
#~ "def main():\n"
#~ "  with ti.Tape(loss):\n"
#~ "    ...\n"
#~ "    sum[None] = 0\n"
#~ "    reduce()\n"
#~ "    assign()\n"
#~ "    ..."
#~ msgstr ""

#~ msgid ""
#~ "Use ``@ti.func`` to decorate your Taichi"
#~ " functions. These functions are callable"
#~ " only in `Taichi`-scope. Don't call "
#~ "them in `Python`-scope. All function "
#~ "calls are force-inlined, so no "
#~ "recursion supported."
#~ msgstr ""

#~ msgid ""
#~ "@ti.func\n"
#~ "def laplacian(t, i, j):\n"
#~ "  return inv_dx2 * (\n"
#~ "      -4 * p[t, i, j] + p[t,"
#~ " i, j - 1] + p[t, i, j"
#~ " + 1] + p[t, i + 1, j]"
#~ " +\n"
#~ "      p[t, i - 1, j])\n"
#~ "\n"
#~ "@ti.kernel\n"
#~ "def fdtd(t: ti.i32):\n"
#~ "  for i in range(n_grid): # Parallelized over GPU threads\n"
#~ "    for j in range(n_grid):\n"
#~ "      laplacian_p = laplacian(t - 2, i, j)\n"
#~ "      laplacian_q = laplacian(t - 1, i, j)\n"
#~ "      p[t, i, j] = 2 * p[t - 1, i, j] + (\n"
#~ "          c * c * dt * dt + c * alpha * dt) * laplacian_q - p[\n"
#~ "                     t - 2, i, j] - c * alpha * dt * laplacian_p"
#~ msgstr ""

#~ msgid ""
#~ "Functions with multiple ``return``'s are "
#~ "not supported for now. Use a "
#~ "**local** variable to store the results,"
#~ " so that you end up with only"
#~ " one ``return``:"
#~ msgstr ""

#~ msgid ""
#~ "# Bad function - two return's\n"
#~ "@ti.func\n"
#~ "def safe_sqrt(x):\n"
#~ "  if x >= 0:\n"
#~ "    return ti.sqrt(x)\n"
#~ "  else:\n"
#~ "    return 0.0\n"
#~ "\n"
#~ "# Good function - single return\n"
#~ "@ti.func\n"
#~ "def safe_sqrt(x):\n"
#~ "  rst = 0.0\n"
#~ "  if x >= 0:\n"
#~ "    rst = ti.sqrt(x)\n"
#~ "  else:\n"
#~ "    rst = 0.0\n"
#~ "  return rst"
#~ msgstr ""

#~ msgid "Data layout"
#~ msgstr ""

#~ msgid ""
#~ "Non-power-of-two tensor dimensions "
#~ "are promoted into powers of two "
#~ "and thus these tensors will occupy "
#~ "more virtual address space. For example,"
#~ " a tensor of size ``(18, 65)`` "
#~ "will be materialized as ``(32, 128)``."
#~ msgstr ""

#~ msgid ""
#~ "Note: when these scalar functions are"
#~ " applied on :ref:`matrix` and "
#~ ":ref:`vector`, it's applied element-wise, "
#~ "for example:"
#~ msgstr ""

#~ msgid ""
#~ "A = ti.sin(B)\n"
#~ "# is equalivant to (assuming B is a 3x2 matrix):\n"
#~ "for i in ti.static(range(3)):\n"
#~ "    for j in ti.static(range(2)):\n"
#~ "        A[i, j] = ti.sin(B[i, j])"
#~ msgstr ""

#~ msgid ""
#~ "*true divisions* on integral types will"
#~ " first cast their operands to the "
#~ "default float point type."
#~ msgstr ""

#~ msgid ""
#~ "*floor divisions* on float-point types"
#~ " will first cast their operands to"
#~ " the default integer type."
#~ msgstr ""

#~ msgid ""
#~ "To avoid such implicit casting, you "
#~ "can manually cast your operands to "
#~ "desired types, using ``ti.cast``. Read "
#~ ":ref:`default_precisions` for more details on"
#~ " default numerical types."
#~ msgstr ""

#~ msgid ""
#~ "Debug your program with ``print(x)``. "
#~ "For example, if ``x`` is ``23``, "
#~ "then it shows:"
#~ msgstr ""

#~ msgid "Embedding the language in ``python`` has the following advantages:"
#~ msgstr ""

#~ msgid ""
#~ "Creating aliases for global variables "
#~ "and functions with cumbersome names can"
#~ " sometimes improve readability. In Taichi,"
#~ " this can be done by assigning "
#~ "kernel and function local variables with"
#~ " ``ti.static()``, which forces Taichi to"
#~ " use standard python pointer assignement."
#~ msgstr ""

#~ msgid ""
#~ "By default, numerical literals have "
#~ "32-bit precisions. For example, ``42`` "
#~ "has type ``ti.i32`` and ``3.14`` has "
#~ "type ``ti.f32``. Default precisions can "
#~ "be specified when initializing Taichi:"
#~ msgstr ""

#~ msgid "Use ``ti.cast`` to type-cast scalar values."
#~ msgstr ""

#~ msgid ""
#~ "The default logging level is "
#~ "``ti.INFO``. You can also override "
#~ "default logging level by setting the "
#~ "environment variable ``TI_LOG_LEVEL`` to "
#~ "values such as ``trace`` and ``warn``."
#~ msgstr ""

#~ msgid ""
#~ "# Python\n"
#~ "ti.set_gdb_trigger(True)\n"
#~ "\n"
#~ "// C++\n"
#~ "CoreState::set_trigger_gdb_when_crash(true);"
#~ msgstr ""

