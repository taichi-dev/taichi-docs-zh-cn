# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018, Yuanming Hu
# This file is distributed under the same license as the taichi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
msgid ""
msgstr ""
"Project-Id-Version: taichi 0.5.14\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-05-12 14:33+0800\n"
"PO-Revision-Date: 2020-05-12 15:07-0400\n"
"Last-Translator: archibate <17721388340@qq.com>\n"
"Language: zh_CN\n"
"Language-Team: \n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"
"X-Generator: Poedit 2.3.1\n"

#: ../../hello.rst:2
msgid "Hello, world!"
msgstr "你好，世界！"

#: ../../hello.rst:4
msgid ""
"We introduce the Taichi programming language through a very basic `fractal` "
"example."
msgstr "我们将通过一个分形程序的例子来介绍Taichi。"

#: ../../hello.rst:6
msgid "First of all, let's install Taichi via ``pip``:"
msgstr "如果你还没有安装，请先通过 ``pip`` 安装Taichi："

#: ../../hello.rst:8
msgid ""
"# Python 3.6+ needed\n"
"python3 -m pip install taichi"
msgstr ""
"# 需要 Python 3.6 及以上\n"
"python3 -m pip install taichi"

#: ../../hello.rst:13
msgid ""
"Now you are ready to run the Taichi code below (``python3 fractal.py``) to "
"compute a `Julia set <https://en.wikipedia.org/wiki/Julia_set>`_:"
msgstr ""
"现在你可以通过 ``python3 fractal.py`` 运行下面这段Taichi代码了，我们将得到 "
"`Julia 集 <https://baike.baidu.com/item/%E6%9C%B1%E5%88%A9%E4%BA%9A%E9%9B"
"%86%E5%90%88/4140547>`_ 的图像："

#: ../../hello.rst:18
msgid ""
"# fractal.py\n"
"\n"
"import taichi as ti\n"
"\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"n = 320\n"
"pixels = ti.var(dt=ti.f32, shape=(n * 2, n))\n"
"\n"
"\n"
"@ti.func\n"
"def complex_sqr(z):\n"
"    return ti.Vector([z[0]**2 - z[1]**2, z[1] * z[0] * 2])\n"
"\n"
"\n"
"@ti.kernel\n"
"def paint(t: ti.f32):\n"
"    for i, j in pixels:  # Parallized over all pixels\n"
"        c = ti.Vector([-0.8, ti.cos(t) * 0.2])\n"
"        z = ti.Vector([i / n - 1, j / n - 0.5]) * 2\n"
"        iterations = 0\n"
"        while z.norm() < 20 and iterations < 50:\n"
"            z = complex_sqr(z) + c\n"
"            iterations += 1\n"
"        pixels[i, j] = 1 - iterations * 0.02\n"
"\n"
"\n"
"gui = ti.GUI(\"Julia Set\", res=(n * 2, n))\n"
"\n"
"for i in range(1000000):\n"
"    paint(i * 0.03)\n"
"    gui.set_image(pixels)\n"
"    gui.show()"
msgstr ""
"# fractal.py\n"
"\n"
"import taichi as ti\n"
"\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"n = 320\n"
"pixels = ti.var(dt=ti.f32, shape=(n * 2, n))\n"
"\n"
"@ti.func\n"
"def complex_sqr(z):\n"
"  return ti.Vector([z[0] ** 2 - z[1] ** 2, z[1] * z[0] * 2])\n"
"\n"
"@ti.kernel\n"
"def paint(t: ti.f32):\n"
"  for i, j in pixels: # 对于所有像素，并行执行\n"
"    c = ti.Vector([-0.8, ti.sin(t) * 0.2])\n"
"    z = ti.Vector([float(i) / n - 1, float(j) / n - 0.5]) * 2\n"
"    iterations = 0\n"
"    while z.norm() < 20 and iterations < 50:\n"
"      z = complex_sqr(z) + c\n"
"      iterations += 1\n"
"    pixels[i, j] = 1 - iterations * 0.02\n"
"\n"
"gui = ti.GUI(\"Fractal\", (n * 2, n))\n"
"\n"
"for i in range(1000000):\n"
"  paint(i * 0.03)\n"
"  gui.set_image(pixels)\n"
"  gui.show()"

#: ../../hello.rst:54
msgid "Let's dive into components of this simple Taichi program."
msgstr "我们来深入剖析一下这段小小的Taichi程序吧。"

#: ../../hello.rst:57
msgid "import taichi as ti"
msgstr "import taichi as ti"

#: ../../hello.rst:58
msgid ""
"Taichi is a domain-specific language (DSL) embedded in Python. Heavy "
"engineering has been done to make Taichi as easy to use as a Python package."
msgstr ""
"Taichi是一个嵌入Python的领域特定编程语言 (domain-specific language, DSL) 。"
"经过开发者们的大量软件工程，Taichi就像是一个普通的Python包一样容易使用。"

#: ../../hello.rst:61
msgid ""
"After minimal learning efforts, every Python programmer will be capable of "
"writing Taichi programs, You can also reuse the Python package management "
"system, Python IDEs, and existing Python packages."
msgstr ""
"只要学习很少的新知识，几乎每个Python程序员都可以熟练使用Taichi。Taichi可以和"
"现成的Python包管理系统、Python集成开发环境(IDE)、Python包一起使用。"

#: ../../hello.rst:65
msgid "Portability"
msgstr "可移植性"

#: ../../hello.rst:67
msgid ""
"Taichi code can run on CPUs or GPUs. Initialize Taichi according to your "
"hardware platform:"
msgstr "Taichi既能在CPU，也能在GPU上运行。你只需根据你的平台初始化Taichi："

#: ../../hello.rst:69
msgid ""
"# Run on GPU, automatically detect backend\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"# Run on GPU, with the NVIDIA CUDA backend\n"
"ti.init(arch=ti.cuda)\n"
"# Run on GPU, with the OpenGL backend\n"
"ti.init(arch=ti.opengl)\n"
"# Run on GPU, with the Apple Metal backend, if you are on OS X\n"
"ti.init(arch=ti.metal)\n"
"\n"
"# Run on CPU (default)\n"
"ti.init(arch=ti.cpu)"
msgstr ""
"# 在 GPU 上运行，自动选择后端\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"# 在 GPU 上运行， 使用 NVIDIA CUDA 后端\n"
"ti.init(arch=ti.cuda)\n"
"# 在 GPU 上运行， 使用 OpenGL 后端\n"
"ti.init(arch=ti.opengl)\n"
"# 在 GPU 上运行， 使用苹果 Metal 后端（仅对 OS X）有效\n"
"ti.init(arch=ti.metal)\n"
"\n"
"# 在 CPU 上运行 (默认)\n"
"ti.init(arch=ti.cpu)"

#: ../../hello.rst:85
msgid "Supported backends on different platforms:"
msgstr "不同操作系统所支持的后端："

#: ../../hello.rst:88
msgid "platform"
msgstr "平台"

#: ../../hello.rst:88
msgid "CPU"
msgstr ""

#: ../../hello.rst:88
msgid "CUDA"
msgstr ""

#: ../../hello.rst:88
msgid "OpenGL"
msgstr ""

#: ../../hello.rst:88
msgid "Metal"
msgstr ""

#: ../../hello.rst:90
msgid "Windows"
msgstr ""

#: ../../hello.rst:90 ../../hello.rst:92 ../../hello.rst:94
msgid "OK"
msgstr "可用"

#: ../../hello.rst:90 ../../hello.rst:92 ../../hello.rst:94
msgid "N/A"
msgstr "不可用"

#: ../../hello.rst:92
msgid "Linux"
msgstr ""

#: ../../hello.rst:94
msgid "Mac OS X"
msgstr ""

#: ../../hello.rst:97
msgid "(OK: supported; N/A: not available)"
msgstr ""
"（可用: 该系统上有最完整的支持；不可用: 由于平台限制，我们无法实现该后端）"

#: ../../hello.rst:99
msgid ""
"With ``arch=ti.gpu``, Taichi will try to run on CUDA. If CUDA is not "
"supported on your machine, Taichi will fall back to Metal or OpenGL. If no "
"GPU backend (CUDA, Metal, or OpenGL) is supported, Taichi will fall back to "
"CPUs."
msgstr ""
"当指定 ``arch=ti.gpu`` 时， Taichi 首先会尝试 CUDA。如果你的系统不支持 "
"CUDA，Taichi 会尝试 Metal 或者 OpenGL。如果没有任何可用的 GPU 后端 （CUDA，"
"Metal，OpenGL）, Taichi 会用 CPU 运行。"

#: ../../hello.rst:105
msgid ""
"When using the CUDA backend on Windows systems or ARM devices (e.g. NVIDIA "
"Jetson), Taichi will by default allocate 1 GB memory for tensor storage. "
"You can override this by initializing with ``ti.init(arch=ti.cuda, "
"device_memory_GB=3.4)`` to allocate ``3.4`` GB GPU memory, or ``ti."
"init(arch=ti.cuda, device_memory_fraction=0.3)`` to allocate ``30%`` of "
"total available GPU memory."
msgstr ""
"当在 Windows 操作系统 或者 ARM 设备（如 NVIDIA Jetson ）上使用 CUDA 后端"
"时， Taichi 会默认分配 1 GB 显存用于张量存储。要改变这一行为，您可以通过初始"
"化指令 ``ti.init(arch=ti.cuda, device_memory_GB=3.4)`` 来分配 ``3.4`` GB 显"
"存，或者使用 ``ti.init(arch=ti.cuda, device_memory_fraction=0.3)`` 来分配所"
"有可用显存的 ``30%``."

#: ../../hello.rst:110
msgid ""
"On other platforms Taichi will make use of its on-demand memory allocator "
"to adaptively allocate memory."
msgstr "在其他平台上， Taichi 会使用自适应内存分配器来动态地分配内存。"

#: ../../hello.rst:113
msgid "(Sparse) tensors"
msgstr "（稀疏）张量"

#: ../../hello.rst:115
msgid ""
"Taichi is a data-oriented programming language, where dense or spatially-"
"sparse tensors are first-class citizens. See :ref:`sparse` for more details "
"on sparse tensors."
msgstr ""
"Taichi是一门面向数据的编程语言，（稠密、稀疏）张量是一等公民。欲了解更多关于"
"稀疏张量的内容，请见 :ref:`sparse`。"

#: ../../hello.rst:118
msgid ""
"In the code above, ``pixels = ti.var(dt=ti.f32, shape=(n * 2, n))`` "
"allocates a 2D dense tensor named ``pixel`` of size ``(640, 320)`` and "
"element data type ``ti.f32`` (i.e. ``float`` in C)."
msgstr ""
"在以上代码中，``pixels = ti.var(dt=ti.f32, shape=(n * 2, n))`` 分配一个叫做 "
"``pixel`` 的二维张量，大小是 ``(640, 320)`` ，数据类型是 ``ti.f32`` (也即C语"
"言的 ``float``)."

#: ../../hello.rst:122
msgid "Functions and kernels"
msgstr "函数与内核"

#: ../../hello.rst:124
msgid ""
"Computation happens within Taichi **kernels**. Kernel arguments must be "
"type-hinted. The language used in Taichi kernels and functions looks "
"exactly like Python, yet the Taichi frontend compiler converts it into a "
"language that is **compiled, statically-typed, lexically-scoped, parallel, "
"and differentiable**."
msgstr ""
"Taichi的计算是在 **内核** 中进行的。内核的参数必须显式指定类型。Taichi内核与"
"函数中所用的语法，看起来和Python的很像，Taichi的前端编译器会将其转换为 **编"
"译型，静态类型，有词法作用域，并行执行，可微分** 的语言。"

#: ../../hello.rst:128
msgid ""
"You can also define Taichi **functions** with ``ti.func``, which can be "
"called and reused by kernels and other functions."
msgstr ""
"除了内核，还可以通过 ``@ti.func`` 来定义 **函数** ，函数可以被内核或函数调"
"用，以实现代码重用。"

#: ../../hello.rst:132
msgid ""
"**Taichi-scope v.s. Python-scope**: everything decorated with ``ti.kernel`` "
"and ``ti.func`` is in Taichi-scope, which will be compiled by the Taichi "
"compiler. Code outside the Taichi-scopes is simply normal Python code."
msgstr ""
"**Taichi作用域 与 Python作用域**：任何带有 ``@ti.kernel`` 和 ``@ti.func`` 装"
"饰器的函数体都在Taichi作用域中，这些代码会被Taichi编译。而在Taichi作用域之外"
"的就是Python作用域了，它们是单纯的Python代码。"

#: ../../hello.rst:137
msgid ""
"Taichi kernels must be called in the Python-scope. I.e., **nested kernels "
"are not supported**. Nested functions are allowed. **Recursive functions "
"are not supported for now**."
msgstr ""
"Taichi内核只有在Python作用域中才能调用，也就是说，**我们不支持嵌套内核**。嵌"
"套函数支持，但 **递归函数不支持** 。"

#: ../../hello.rst:140
msgid "Taichi functions can only be called in Taichi-scope."
msgstr "Taichi函数只有在Taichi作用域中才能调用。"

#: ../../hello.rst:142
msgid ""
"For those who came from the world of CUDA, ``ti.func`` corresponds to "
"``__device__``, and ``ti.kernel`` corresponds to ``__global__``."
msgstr ""
"用CUDA世界的话说，就是 ``ti.func`` 对应于 ``__device__``，``ti.kernel`` 对应"
"于 ``__global__``。"

#: ../../hello.rst:146
msgid "Parallel for-loops"
msgstr "并行执行的for循环"

#: ../../hello.rst:147
msgid ""
"For loops at the outermost scope in a Taichi kernel is **automatically "
"parallelized**. For loops can have two forms, i.e. `range-for loops` and "
"`struct-for loops`."
msgstr ""
"最外层作用域的 for 循环会自动被并行执行。Taichi 的 for 循环具有两种形式，区"
"间 for 循环，和结构 for 循环。"

#: ../../hello.rst:150
msgid ""
"**Range-for loops** are no different from Python for loops, except that it "
"will be parallelized when used at the outermost scope. Range-for loops can "
"be nested."
msgstr ""
"**区间for循环** 和普通的 Python for 循环没多大区别，只是 Taichi 最外层的 "
"for 会并行执行而已。区间 for 循环可以嵌套。"

#: ../../hello.rst:153
msgid ""
"@ti.kernel\n"
"def fill():\n"
"    for i in range(10): # Parallelized\n"
"        x[i] += i\n"
"\n"
"        s = 0\n"
"        for j in range(5): # Serialized in each parallel thread\n"
"            s += j\n"
"\n"
"        y[i] = s\n"
"\n"
"@ti.kernel\n"
"def fill_3d():\n"
"    # Parallelized for all 3 <= i < 8, 1 <= j < 6, 0 <= k < 9\n"
"    for i, j, k in ti.ndrange((3, 8), (1, 6), 9):\n"
"        x[i, j, k] = i + j + k"
msgstr ""
"@ti.kernel\n"
"def fill():\n"
"  for i in range(10): # 并行执行\n"
"    x[i] += i\n"
"\n"
"    s = 0\n"
"    for j in range(5): # 在每个并行的线程中顺序执行\n"
"      s += j\n"
"\n"
"    y[i] = s\n"
"\n"
"@ti.kernel\n"
"def fill_3d():\n"
"  # 在区间 3 <= i < 8, 1 <= j < 6, 0 <= k < 9 上展开并行\n"
"  for i, j, k in ti.ndrange((3, 8), (1, 6), 9):\n"
"    x[i, j, k] = i + j + k"

#: ../../hello.rst:174 ../../hello.rst:200
msgid ""
"It is the loop **at the outermost scope** that gets parallelized, not the "
"outermost loop."
msgstr "是最外层 **作用域** 的循环并行执行，而不是最外层的循环。"

#: ../../hello.rst:176
msgid ""
"@ti.kernel\n"
"def foo():\n"
"    for i in range(10): # Parallelized :-)\n"
"        ...\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    if k > 42:\n"
"        for i in range(10): # Serial :-(\n"
"            ..."
msgstr ""
"@ti.kernel\n"
"def foo():\n"
"    for i in range(10): # 并行 :-)\n"
"        …\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    if k > 42:\n"
"        for i in range(10): # 串行 :-(\n"
"            …"

#: ../../hello.rst:189
msgid ""
"**Struct-for loops** have are particularly useful when iterating over "
"(sparse) tensor elements. In the code above, ``for i, j in pixels`` loops "
"over all the pixel coordinates, i.e. ``(0, 0), (0, 1), (0, 2), ... , (0, "
"319), (1, 0), ..., (639, 319)``."
msgstr ""
"**结构for循环** 在遍历（稀疏）张量元素的时候很有用。例如在上述的代码中，"
"``for i, j in pixels`` 将遍历所有像素坐标点, 即 ``(0, 0), (0, 1), (0, "
"2), ... , (0, 319), (1, 0), ..., (639, 319)``。"

#: ../../hello.rst:194
msgid ""
"Struct-for is the key to :ref:`sparse` in Taichi, as it will only loop over "
"active elements in a sparse tensor. In dense tensors, all elements are "
"active."
msgstr ""
"结构 for 循环是 Taichi 稀疏计算（:ref:`sparse`）的关键，它只会遍历稀疏张量中"
"的活跃元素。对于稠密张量而言，所有元素都是活跃元素。"

#: ../../hello.rst:198
msgid "Struct-for's must live at the outer-most scope of kernels."
msgstr "结构for循环是只能用于内核的最外层作用域。"

#: ../../hello.rst:202
msgid ""
"@ti.kernel\n"
"def foo():\n"
"    for i in x:\n"
"        ...\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    # The outermost scope is a `if` statement\n"
"    if k > 42:\n"
"        for i in x: # Not allowed. Struct-fors must live in the outermost "
"scope.\n"
"            ..."
msgstr ""
"@ti.kernel\n"
"def foo():\n"
"    for i in x:\n"
"        …\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    # 最外层作用域是 `if` 语句\n"
"    if k > 42:\n"
"        for i in x: # 语法错误。结构 for 循环 只能用于最外层作用域\n"
"            … "

#: ../../hello.rst:221
msgid "``break`` **is not supported in parallel loops**:"
msgstr "**并行** 循环不支持 ``break`` 语句："

#: ../../hello.rst:223
msgid ""
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      ...\n"
"      break # Error!\n"
"\n"
"  for i in range(10):\n"
"      ...\n"
"      break # Error!\n"
"\n"
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      for j in range(10):\n"
"          ...\n"
"          break # OK!"
msgstr ""
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      ...\n"
"      break # 错误：并行执行的循环不能有break\n"
"\n"
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      for j in y:\n"
"          ...\n"
"          break # 可以"

#: ../../hello.rst:244
msgid "Interacting with Python"
msgstr "与 Python 交互"

#: ../../hello.rst:246
msgid ""
"Everything outside Taichi-scopes (``ti.func`` and ``ti.kernel``) is simply "
"Python. You can use your favorite Python packages (e.g. ``numpy``, "
"``pytorch``, ``matplotlib``) with Taichi."
msgstr ""
"Taichi 作用域 (``ti.func`` 和 ``ti.kernel``) 外的代码就是普通的 Python 代"
"码。 您可以随意使用喜欢的 Python 包 （如 ``numpy``，``pytorch``， "
"``matplotlib``）与 Taichi 交互。"

#: ../../hello.rst:248
msgid ""
"In Python-scope, you can access Taichi tensors using plain indexing syntax, "
"and helper functions such as ``from_numpy`` and ``to_torch``:"
msgstr ""
"在 Python 作用域，您可以用普通下标语法访问 Taichi 张量。我们也提供简单的转换"
"函数，如 ``from_numpy`` 和 ``to_torch``："

#: ../../hello.rst:250
msgid ""
"image[42, 11] = 0.7\n"
"print(image[1, 63])\n"
"\n"
"import numpy as np\n"
"pixels.from_numpy(np.random.rand(n * 2, n))\n"
"\n"
"import matplotlib.pyplot as plt\n"
"plt.imshow(pixels.to_numpy())\n"
"plt.show()"
msgstr ""

#~ msgid ""
#~ "This design decision virtually makes every Python programmer capable of "
#~ "writing Taichi programs, after minimal learning efforts. You can also "
#~ "reuse the package management system, Python IDEs, and existing Python "
#~ "packages."
#~ msgstr ""
#~ "这样的设计使任何已经掌握Python的程序员，无需很多额外的学习，就能编写"
#~ "Taichi程序。从而利用现成的包管理系统，Python IDE和Python包。"

#~ msgid ""
#~ "# Run on GPU, automatically detect backend\n"
#~ "ti.init(arch=ti.gpu)\n"
#~ "# Run on NVIDIA GPU, CUDA required\n"
#~ "ti.init(arch=ti.cuda)\n"
#~ "# Run on GPU, with the OpenGL backend\n"
#~ "ti.init(arch=ti.opengl)\n"
#~ "# Run on GPU, with the Apple Metal backend, if you are on OS X\n"
#~ "ti.init(arch=ti.metal)\n"
#~ "# Run on CPU (default)\n"
#~ "ti.init(arch=ti.cpu)"
#~ msgstr ""
#~ "# 在 GPU 上运行，自动检测可用的后端\n"
#~ "ti.init(arch=ti.gpu)\n"
#~ "# 在 NVIDIA GPU 上运行\n"
#~ "ti.init(arch=ti.cuda)\n"
#~ "# 通过 OpenGL 后端，在 GPU 上运行\n"
#~ "ti.init(arch=ti.opengl)\n"
#~ "# 通过苹果的 Metal 后端，在 GPU 上运行\n"
#~ "ti.init(arch=ti.metal)\n"
#~ "# 在 CPU 上运行（默认）\n"
#~ "ti.init(arch=ti.cpu)"

#~ msgid ""
#~ "# Good kernel\n"
#~ "@ti.func\n"
#~ "def foo():\n"
#~ "  for i in x:\n"
#~ "    ...\n"
#~ "\n"
#~ "# Bad kernel\n"
#~ "@ti.func\n"
#~ "def bar(k: ti.i32):\n"
#~ "  # The outermost scope is a `if` statement, not the struct-for loop!\n"
#~ "  if k > 42:\n"
#~ "    for i in x:\n"
#~ "      ..."
#~ msgstr ""
#~ "# 正面教材\n"
#~ "@ti.func\n"
#~ "def foo():\n"
#~ "  for i in x:\n"
#~ "    ...\n"
#~ "\n"
#~ "# 反面教材\n"
#~ "@ti.func\n"
#~ "def bar(k: ti.i32):\n"
#~ "  # 这里的最外层作用域是 if 语句，而不是 for 循环！\n"
#~ "  if k > 42:\n"
#~ "    for i in x:\n"
#~ "      ..."
