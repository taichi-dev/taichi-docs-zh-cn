# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018, Yuanming Hu
# This file is distributed under the same license as the taichi package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
msgid ""
msgstr ""
"Project-Id-Version: taichi 0.5.14\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-05-12 14:33+0800\n"
"PO-Revision-Date: 2020-05-09 10:27+0800\n"
"Last-Translator: archibate <17721388340@qq.com>\n"
"Language: zh_CN\n"
"Language-Team: \n"
"Plural-Forms: nplurals=1; plural=0\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../hello.rst:2
msgid "Hello, world!"
msgstr "你好，世界！"

#: ../../hello.rst:4
msgid ""
"We introduce the Taichi programming language through a very basic "
"`fractal` example."
msgstr "我们将通过分形的例子来介绍Taichi。"

#: ../../hello.rst:6
msgid "First of all, let's install Taichi via ``pip``:"
msgstr "如果你还没有安装，请先通过 ``pip`` 安装Taichi："

#: ../../hello.rst:8
msgid ""
"# Python 3.6+ needed\n"
"python3 -m pip install taichi"
msgstr ""
"# 需要 Python 3.6 及以上\n"
"python3 -m pip install taichi"

#: ../../hello.rst:13
msgid ""
"Now you are ready to run the Taichi code below (``python3 fractal.py``) "
"to compute a `Julia set <https://en.wikipedia.org/wiki/Julia_set>`_:"
msgstr ""
"现在你可以通过 ``python3 fractal.py`` 运行下面这段Taichi代码了，我们将得到 `Julia 集 "
"<https://baike.baidu.com/item/%E6%9C%B1%E5%88%A9%E4%BA%9A%E9%9B%86%E5%90%88/4140547>`_"
" 的图像："

#: ../../hello.rst:18
#, fuzzy
msgid ""
"# fractal.py\n"
"\n"
"import taichi as ti\n"
"\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"n = 320\n"
"pixels = ti.var(dt=ti.f32, shape=(n * 2, n))\n"
"\n"
"\n"
"@ti.func\n"
"def complex_sqr(z):\n"
"    return ti.Vector([z[0]**2 - z[1]**2, z[1] * z[0] * 2])\n"
"\n"
"\n"
"@ti.kernel\n"
"def paint(t: ti.f32):\n"
"    for i, j in pixels:  # Parallized over all pixels\n"
"        c = ti.Vector([-0.8, ti.cos(t) * 0.2])\n"
"        z = ti.Vector([i / n - 1, j / n - 0.5]) * 2\n"
"        iterations = 0\n"
"        while z.norm() < 20 and iterations < 50:\n"
"            z = complex_sqr(z) + c\n"
"            iterations += 1\n"
"        pixels[i, j] = 1 - iterations * 0.02\n"
"\n"
"\n"
"gui = ti.GUI(\"Julia Set\", res=(n * 2, n))\n"
"\n"
"for i in range(1000000):\n"
"    paint(i * 0.03)\n"
"    gui.set_image(pixels)\n"
"    gui.show()"
msgstr ""
"# fractal.py\n"
"\n"
"import taichi as ti\n"
"\n"
"ti.init(arch=ti.gpu) # 默认在 GPU 上运行\n"
"\n"
"n = 320\n"
"pixels = ti.var(dt=ti.f32, shape=(n * 2, n))\n"
"\n"
"@ti.func\n"
"def complex_sqr(z):\n"
"  return ti.Vector([z[0] ** 2 - z[1] ** 2, z[1] * z[0] * 2])\n"
"\n"
"@ti.kernel\n"
"def paint(t: ti.f32):\n"
"  for i, j in pixels: # 对于所有像素，并行执行\n"
"    c = ti.Vector([-0.8, ti.sin(t) * 0.2])\n"
"    z = ti.Vector([float(i) / n - 1, float(j) / n - 0.5]) * 2\n"
"    iterations = 0\n"
"    while z.norm() < 20 and iterations < 50:\n"
"      z = complex_sqr(z) + c\n"
"      iterations += 1\n"
"    pixels[i, j] = 1 - iterations * 0.02\n"
"\n"
"gui = ti.GUI(\"Fractal\", (n * 2, n))\n"
"\n"
"for i in range(1000000):\n"
"  paint(i * 0.03)\n"
"  gui.set_image(pixels)\n"
"  gui.show()"

#: ../../hello.rst:54
msgid "Let's dive into components of this simple Taichi program."
msgstr "我们来深入剖析一下这段小小的Taichi程序吧。"

#: ../../hello.rst:57
msgid "import taichi as ti"
msgstr "import taichi as ti"

#: ../../hello.rst:58
#, fuzzy
msgid ""
"Taichi is a domain-specific language (DSL) embedded in Python. Heavy "
"engineering has been done to make Taichi as easy to use as a Python "
"package."
msgstr "Taichi是个嵌入Python的领域特定编程语言(DSL)。它看起来像是普通的Python包，然而这离不开大量的程序工程学设计。"

#: ../../hello.rst:61
msgid ""
"After minimal learning efforts, every Python programmer will be capable "
"of writing Taichi programs, You can also reuse the Python package "
"management system, Python IDEs, and existing Python packages."
msgstr ""

#: ../../hello.rst:65
msgid "Portability"
msgstr "可移植性"

#: ../../hello.rst:67
msgid ""
"Taichi code can run on CPUs or GPUs. Initialize Taichi according to your "
"hardware platform:"
msgstr "Taichi既能在CPU，也能在GPU上运行。你只需根据你的平台初始化Taichi："

#: ../../hello.rst:69
msgid ""
"# Run on GPU, automatically detect backend\n"
"ti.init(arch=ti.gpu)\n"
"\n"
"# Run on GPU, with the NVIDIA CUDA backend\n"
"ti.init(arch=ti.cuda)\n"
"# Run on GPU, with the OpenGL backend\n"
"ti.init(arch=ti.opengl)\n"
"# Run on GPU, with the Apple Metal backend, if you are on OS X\n"
"ti.init(arch=ti.metal)\n"
"\n"
"# Run on CPU (default)\n"
"ti.init(arch=ti.cpu)"
msgstr ""

#: ../../hello.rst:85
msgid "Supported backends on different platforms:"
msgstr "不同操作系统所支持的后端："

#: ../../hello.rst:88
msgid "platform"
msgstr "平台"

#: ../../hello.rst:88
msgid "CPU"
msgstr ""

#: ../../hello.rst:88
msgid "CUDA"
msgstr ""

#: ../../hello.rst:88
msgid "OpenGL"
msgstr ""

#: ../../hello.rst:88
msgid "Metal"
msgstr ""

#: ../../hello.rst:90
msgid "Windows"
msgstr ""

#: ../../hello.rst:90 ../../hello.rst:92 ../../hello.rst:94
msgid "OK"
msgstr "可用"

#: ../../hello.rst:90 ../../hello.rst:92 ../../hello.rst:94
msgid "N/A"
msgstr "不可用"

#: ../../hello.rst:92
msgid "Linux"
msgstr ""

#: ../../hello.rst:94
msgid "Mac OS X"
msgstr ""

#: ../../hello.rst:97
#, fuzzy
msgid "(OK: supported; N/A: not available)"
msgstr "（可用: 该系统上有最完整的支持；施工中: 尚未完工，可能存在各种问题；不可用: 由于平台限制，我们无法实现该后端）"

#: ../../hello.rst:99
#, fuzzy
msgid ""
"With ``arch=ti.gpu``, Taichi will try to run on CUDA. If CUDA is not "
"supported on your machine, Taichi will fall back to Metal or OpenGL. If "
"no GPU backend (CUDA, Metal, or OpenGL) is supported, Taichi will fall "
"back to CPUs."
msgstr ""
"当指定 ``arch=ti.gpu`` 时， Taichi 首先会尝试 CUDA。如果你的系统不支持 CUDA，Taichi 会尝试 Metal "
"或者 OpenGL。如果没有任何可用的 GPU 后端 （CUDA，Metal，OpenGL）, Taichi 会用 CPU 运行。"

#: ../../hello.rst:105
msgid ""
"When using the CUDA backend on Windows systems or ARM devices (e.g. "
"NVIDIA Jetson), Taichi will by default allocate 1 GB memory for tensor "
"storage. You can override this by initializing with "
"``ti.init(arch=ti.cuda, device_memory_GB=3.4)`` to allocate ``3.4`` GB "
"GPU memory, or ``ti.init(arch=ti.cuda, device_memory_fraction=0.3)`` to "
"allocate ``30%`` of total available GPU memory."
msgstr ""

#: ../../hello.rst:110
msgid ""
"On other platforms Taichi will make use of its on-demand memory allocator"
" to adaptively allocate memory."
msgstr ""

#: ../../hello.rst:113
#, fuzzy
msgid "(Sparse) tensors"
msgstr "张量"

#: ../../hello.rst:115
msgid ""
"Taichi is a data-oriented programming language, where dense or spatially-"
"sparse tensors are first-class citizens. See :ref:`sparse` for more "
"details on sparse tensors."
msgstr "Taichi是一门面向数据的编程语言，密集/稀疏张量是一等居民。欲了解更多关于稀疏张量的内容，请见 :ref:`sparse`。"

#: ../../hello.rst:118
#, fuzzy
msgid ""
"In the code above, ``pixels = ti.var(dt=ti.f32, shape=(n * 2, n))`` "
"allocates a 2D dense tensor named ``pixel`` of size ``(640, 320)`` and "
"element data type ``ti.f32`` (i.e. ``float`` in C)."
msgstr ""
"``pixels = ti.var(dt=ti.f32, shape=(n * 2, n))`` 分配一个叫做 ``pixel`` "
"的二维张量，大小是 ``(640, 320)`` ，数据类型是 ``ti.f32`` (也即C语言的 ``float``)."

#: ../../hello.rst:122
msgid "Functions and kernels"
msgstr "函数与内核"

#: ../../hello.rst:124
msgid ""
"Computation happens within Taichi **kernels**. Kernel arguments must be "
"type-hinted. The language used in Taichi kernels and functions looks "
"exactly like Python, yet the Taichi frontend compiler converts it into a "
"language that is **compiled, statically-typed, lexically-scoped, "
"parallel, and differentiable**."
msgstr ""
"Taichi的计算是在 **内核** "
"中进行的。内核的参数必须显式指定类型。Taichi内核与函数中所用的语法，看起来和Python的很像，Taichi的前端编译器会将其转换为 "
"**编译型，静态类型，有词法作用域，并行执行，可微分** 的语言。"

#: ../../hello.rst:128
msgid ""
"You can also define Taichi **functions** with ``ti.func``, which can be "
"called and reused by kernels and other functions."
msgstr "除了内核，还可以通过 ``@ti.func`` 来定义 **函数** ，函数可以被内核或函数调用，重用。"

#: ../../hello.rst:132
#, fuzzy
msgid ""
"**Taichi-scope v.s. Python-scope**: everything decorated with "
"``ti.kernel`` and ``ti.func`` is in Taichi-scope, which will be compiled "
"by the Taichi compiler. Code outside the Taichi-scopes is simply normal "
"Python code."
msgstr ""
"**Taichi作用域，Python作用域**：任何带有 ``@ti.kernel`` 和 ``@ti.func`` "
"装饰器的都是Taichi作用域，这些代码会被Taichi编译。而在Taichi作用域之外的就是Python作用域了。"

#: ../../hello.rst:137
msgid ""
"Taichi kernels must be called in the Python-scope. I.e., **nested kernels"
" are not supported**. Nested functions are allowed. **Recursive functions"
" are not supported for now**."
msgstr "Taichi内核只有在Python作用域中才能调用，也就是说，**我们不支持嵌套内核**。嵌套函数支持，但 **递归函数不支持** 。"

#: ../../hello.rst:140
msgid "Taichi functions can only be called in Taichi-scope."
msgstr "Taichi函数只有在Taichi作用域中才能调用。"

#: ../../hello.rst:142
msgid ""
"For those who came from the world of CUDA, ``ti.func`` corresponds to "
"``__device__``, and ``ti.kernel`` corresponds to ``__global__``."
msgstr ""
"用CUDA世界的话说，就是 ``ti.func`` 对应于 ``__device__``，``ti.kernel`` 对应于 "
"``__global__``。"

#: ../../hello.rst:146
msgid "Parallel for-loops"
msgstr "并行执行的for循环"

#: ../../hello.rst:147
#, fuzzy
msgid ""
"For loops at the outermost scope in a Taichi kernel is **automatically "
"parallelized**. For loops can have two forms, i.e. `range-for loops` and "
"`struct-for loops`."
msgstr "最外层作用域的for循环会自动被并行执行。Taichi的for循环具有两种形式，区间for循环，和结构for循环。"

#: ../../hello.rst:150
#, fuzzy
msgid ""
"**Range-for loops** are no different from Python for loops, except that "
"it will be parallelized when used at the outermost scope. Range-for loops"
" can be nested."
msgstr "**区间for循环** 和Python原本的for循环没多大区别，只是Taichi的最外层for的会并行执行而已。区间for循环可以嵌套。"

#: ../../hello.rst:153
#, fuzzy
msgid ""
"@ti.kernel\n"
"def fill():\n"
"    for i in range(10): # Parallelized\n"
"        x[i] += i\n"
"\n"
"        s = 0\n"
"        for j in range(5): # Serialized in each parallel thread\n"
"            s += j\n"
"\n"
"        y[i] = s\n"
"\n"
"@ti.kernel\n"
"def fill_3d():\n"
"    # Parallelized for all 3 <= i < 8, 1 <= j < 6, 0 <= k < 9\n"
"    for i, j, k in ti.ndrange((3, 8), (1, 6), 9):\n"
"        x[i, j, k] = i + j + k"
msgstr ""
"@ti.kernel\n"
"def fill():\n"
"  for i in range(10): # 并行执行\n"
"    x[i] += i\n"
"\n"
"    s = 0\n"
"    for j in range(5): # 在每个并行的线程中顺序执行\n"
"      s += j\n"
"\n"
"    y[i] = s\n"
"\n"
"@ti.kernel\n"
"def fill_3d():\n"
"  # 在区间 3 <= i < 8, 1 <= j < 6, 0 <= k < 9 上展开并行\n"
"  for i, j, k in ti.ndrange((3, 8), (1, 6), 9):\n"
"    x[i, j, k] = i + j + k"

#: ../../hello.rst:174 ../../hello.rst:200
msgid ""
"It is the loop **at the outermost scope** that gets parallelized, not the"
" outermost loop."
msgstr "是最外层 **作用域** 的循环并行执行，而不是最外层的循环。"

#: ../../hello.rst:176
msgid ""
"@ti.kernel\n"
"def foo():\n"
"    for i in range(10): # Parallelized :-)\n"
"        ...\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    if k > 42:\n"
"        for i in range(10): # Serial :-(\n"
"            ..."
msgstr ""

#: ../../hello.rst:189
#, fuzzy
msgid ""
"**Struct-for loops** have are particularly useful when iterating over "
"(sparse) tensor elements. In the code above, ``for i, j in pixels`` loops"
" over all the pixel coordinates, i.e. ``(0, 0), (0, 1), (0, 2), ... , (0,"
" 319), (1, 0), ..., (639, 319)``."
msgstr ""
"**结构for循环** 有着更简洁的语法，特别是遍历张量元素的时候很有用。例如在上述的分形代码中，``for i, j in pixels`` "
"将遍历所有像素坐标点, 即 ``(0, 0), (0, 1), (0, 2), ... , (0, 319), (1, 0), ..., "
"(639, 319)``。"

#: ../../hello.rst:194
msgid ""
"Struct-for is the key to :ref:`sparse` in Taichi, as it will only loop "
"over active elements in a sparse tensor. In dense tensors, all elements "
"are active."
msgstr ""
"结构for循环是 Taichi "
"稀疏张量（:ref:`sparse`）的关键，它只会遍历稀疏张量中的活动元素。对于密集张量而言，所有元素都是活动元素。"

#: ../../hello.rst:198
#, fuzzy
msgid "Struct-for's must live at the outer-most scope of kernels."
msgstr "结构for循环是只能是内核的最外层作用域。"

#: ../../hello.rst:202
msgid ""
"@ti.kernel\n"
"def foo():\n"
"    for i in x:\n"
"        ...\n"
"\n"
"@ti.kernel\n"
"def bar(k: ti.i32):\n"
"    # The outermost scope is a `if` statement\n"
"    if k > 42:\n"
"        for i in x: # Not allowed. Struct-fors must live in the outermost"
" scope.\n"
"            ..."
msgstr ""

#: ../../hello.rst:221
#, fuzzy
msgid "``break`` **is not supported in parallel loops**:"
msgstr "**最外层 (并行的)** 循环不支持  ``break`` 语句："

#: ../../hello.rst:223
#, fuzzy
msgid ""
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      ...\n"
"      break # Error!\n"
"\n"
"  for i in range(10):\n"
"      ...\n"
"      break # Error!\n"
"\n"
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      for j in range(10):\n"
"          ...\n"
"          break # OK!"
msgstr ""
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      ...\n"
"      break # 错误：并行执行的循环不能有break！\n"
"\n"
"@ti.kernel\n"
"def foo():\n"
"  for i in x:\n"
"      for j in y:\n"
"          ...\n"
"          break # 可以"

#: ../../hello.rst:244
msgid "Interacting with Python"
msgstr ""

#: ../../hello.rst:246
msgid ""
"Everything outside Taichi-scopes (``ti.func`` and ``ti.kernel``) is "
"simply Python. You can use your favorite Python packages (e.g. ``numpy``,"
" ``pytorch``, ``matplotlib``) with Taichi."
msgstr ""

#: ../../hello.rst:248
msgid ""
"In Python-scope, you can access Taichi tensors using plain indexing "
"syntax, and helper functions such as ``from_numpy`` and ``to_torch``:"
msgstr ""

#: ../../hello.rst:250
msgid ""
"image[42, 11] = 0.7\n"
"print(image[1, 63])\n"
"\n"
"import numpy as np\n"
"pixels.from_numpy(np.random.rand(n * 2, n))\n"
"\n"
"import matplotlib.pyplot as plt\n"
"plt.imshow(pixels.to_numpy())\n"
"plt.show()"
msgstr ""

#~ msgid ""
#~ "This design decision virtually makes "
#~ "every Python programmer capable of "
#~ "writing Taichi programs, after minimal "
#~ "learning efforts. You can also reuse "
#~ "the package management system, Python "
#~ "IDEs, and existing Python packages."
#~ msgstr ""
#~ "这样的设计使任何已经掌握Python的程序员，无需很多额外的学习，就能编写Taichi程序。从而利用现成的包管理系统，Python "
#~ "IDE和Python包。"

#~ msgid ""
#~ "# Run on GPU, automatically detect backend\n"
#~ "ti.init(arch=ti.gpu)\n"
#~ "# Run on NVIDIA GPU, CUDA required\n"
#~ "ti.init(arch=ti.cuda)\n"
#~ "# Run on GPU, with the OpenGL backend\n"
#~ "ti.init(arch=ti.opengl)\n"
#~ "# Run on GPU, with the Apple Metal backend, if you are on OS X\n"
#~ "ti.init(arch=ti.metal)\n"
#~ "# Run on CPU (default)\n"
#~ "ti.init(arch=ti.cpu)"
#~ msgstr ""
#~ "# 在 GPU 上运行，自动检测可用的后端\n"
#~ "ti.init(arch=ti.gpu)\n"
#~ "# 在 NVIDIA GPU 上运行\n"
#~ "ti.init(arch=ti.cuda)\n"
#~ "# 通过 OpenGL 后端，在 GPU 上运行\n"
#~ "ti.init(arch=ti.opengl)\n"
#~ "# 通过苹果的 Metal 后端，在 GPU 上运行\n"
#~ "ti.init(arch=ti.metal)\n"
#~ "# 在 CPU 上运行（默认）\n"
#~ "ti.init(arch=ti.cpu)"

#~ msgid ""
#~ "When running the CUDA backend on "
#~ "Windows and ARM devices (e.g. NVIDIA "
#~ "Jetson), Taichi will by default allocate"
#~ " 1 GB memory for tensor storage. "
#~ "You can override this by initializing"
#~ " with ``ti.init(arch=ti.cuda, device_memory_GB=3.4)``"
#~ " to allocate ``3.4`` GB GPU memory,"
#~ " or ``ti.init(arch=ti.cuda, "
#~ "device_memory_fraction=0.3)`` to allocate ``30%``"
#~ " of total available GPU memory."
#~ msgstr ""

#~ msgid ""
#~ "# Good kernel\n"
#~ "@ti.func\n"
#~ "def foo():\n"
#~ "  for i in x:\n"
#~ "    ...\n"
#~ "\n"
#~ "# Bad kernel\n"
#~ "@ti.func\n"
#~ "def bar(k: ti.i32):\n"
#~ "  # The outermost scope is a `if` statement, not the struct-for loop!\n"
#~ "  if k > 42:\n"
#~ "    for i in x:\n"
#~ "      ..."
#~ msgstr ""
#~ "# 正面教材\n"
#~ "@ti.func\n"
#~ "def foo():\n"
#~ "  for i in x:\n"
#~ "    ...\n"
#~ "\n"
#~ "# 反面教材\n"
#~ "@ti.func\n"
#~ "def bar(k: ti.i32):\n"
#~ "  # 这里的最外层作用域是 if 语句，而不是 for 循环！\n"
#~ "  if k > 42:\n"
#~ "    for i in x:\n"
#~ "      ..."

#~ msgid ""
#~ "Everything outside Taichi-scope (``ti.func``"
#~ " and ``ti.kernel``) is simply Python. "
#~ "You can use your favorite Python "
#~ "packages (e.g. ``numpy``, ``pytorch``, "
#~ "``matplotlib``) with Taichi."
#~ msgstr ""

